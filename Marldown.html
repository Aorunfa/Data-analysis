<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>Untitled4</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span><span class="c1">#画图基础库</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;font.family&quot;</span><span class="p">]</span><span class="o">=</span><span class="s2">&quot;SimHei&quot;</span>  <span class="c1">#使用支持的黑体中文字体</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;axes.unicode_minus&quot;</span><span class="p">]</span><span class="o">=</span><span class="kc">False</span> <span class="c1"># 用来正常显示负号  &quot;-&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;SimHei&#39;</span><span class="p">]</span> <span class="c1"># 用来正常显示中文标签</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1">#缺失值处理</span>
<span class="kn">import</span> <span class="nn">missingno</span> <span class="k">as</span> <span class="nn">msno</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span> <span class="c1">#统计库</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">date</span><span class="p">,</span> <span class="n">timedelta</span> <span class="c1">#处理时间数据</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[74]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#沿用的函数和数据</span>
<span class="n">oneHot_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;maketype&#39;</span><span class="p">,</span><span class="s1">&#39;carCode&#39;</span><span class="p">,</span><span class="s1">&#39;seatings&#39;</span><span class="p">,</span><span class="s1">&#39;AF10&#39;</span><span class="p">,</span><span class="s1">&#39;cityId&#39;</span><span class="p">,</span><span class="s1">&#39;AF5&#39;</span><span class="p">,</span><span class="s1">&#39;transferCount&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#183;&#29305;&#24449;&#36873;&#25321;">&#183;&#29305;&#24449;&#36873;&#25321;<a class="anchor-link" href="#&#183;&#29305;&#24449;&#36873;&#25321;">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[73]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Train_df = pd.read_excel(&#39;E:/Mather Cup/Coding/dataset/Train_Test_data_before_select.xlsx&#39;,index_col=0)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[77]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># train_ = Train_df.copy()</span>
<span class="c1"># Train_df = train_.copy()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[79]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Train_df</span><span class="o">=</span><span class="n">Train_df</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[81]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#分割训练集和测试集</span>
<span class="n">Test_df</span> <span class="o">=</span> <span class="n">Train_df</span><span class="p">[</span><span class="n">Train_df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Train_df</span> <span class="o">=</span> <span class="n">Train_df</span><span class="p">[</span><span class="n">Train_df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[83]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">org_price</span> <span class="o">=</span> <span class="n">Train_df</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">]</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">Train_df</span><span class="p">[</span><span class="s1">&#39;log_price&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[90]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#从训练集中取出训练特征</span>
<span class="n">num_frature</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">Train_df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">,</span><span class="s1">&#39;price&#39;</span><span class="p">,</span><span class="s1">&#39;log_price&#39;</span><span class="p">]]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">Train_df</span><span class="p">[</span><span class="n">num_frature</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[85]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;price&#39;</span><span class="p">,</span><span class="s1">&#39;log_price&#39;</span><span class="p">],</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[91]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test_ = Test_df.copy()</span>
<span class="c1">#Test_df = test_.copy()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="&#183;&#21076;&#38500;&#19982;&#30446;&#26631;&#21464;&#37327;&#30456;&#20851;&#24615;&#23567;&#20110;0.28&#30340;&#36830;&#32493;&#22411;&#29305;&#24449;&#65306;&#32467;&#26524;&#20445;&#30041;&#20102;186&#20010;&#29305;&#24449;&#65292;&#21253;&#25324;&#20998;&#31867;&#21464;&#37327;">&#183;&#21076;&#38500;&#19982;&#30446;&#26631;&#21464;&#37327;&#30456;&#20851;&#24615;&#23567;&#20110;0.28&#30340;&#36830;&#32493;&#22411;&#29305;&#24449;&#65306;&#32467;&#26524;&#20445;&#30041;&#20102;186&#20010;&#29305;&#24449;&#65292;&#21253;&#25324;&#20998;&#31867;&#21464;&#37327;<a class="anchor-link" href="#&#183;&#21076;&#38500;&#19982;&#30446;&#26631;&#21464;&#37327;&#30456;&#20851;&#24615;&#23567;&#20110;0.28&#30340;&#36830;&#32493;&#22411;&#29305;&#24449;&#65306;&#32467;&#26524;&#20445;&#30041;&#20102;186&#20010;&#29305;&#24449;&#65292;&#21253;&#25324;&#20998;&#31867;&#21464;&#37327;">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[87]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#定义一个函数判断是否为分类函数：</span>
<span class="k">def</span> <span class="nf">cat_judFunct</span><span class="p">(</span><span class="n">cat_name</span><span class="p">,</span><span class="n">List</span><span class="o">=</span><span class="n">oneHot_list</span><span class="p">):</span>
    <span class="n">i</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">List</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">cat_name</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">i</span><span class="o">+=</span><span class="mi">1</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[92]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#相关系数阈值选择0.2</span>
<span class="n">corr_df</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">corrwith</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">dropList</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span><span class="n">val</span> <span class="ow">in</span> <span class="n">corr_df</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">val</span><span class="o">=</span><span class="nb">abs</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">val</span><span class="o">&lt;=</span><span class="mf">0.2</span><span class="p">:</span>
        <span class="c1">#判断是否是分类变量,若是，则不删除，若不是，则删除</span>
        <span class="n">cat_jud</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)</span> 
        <span class="n">cat_jud</span> <span class="o">=</span> <span class="n">cat_jud</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">cat_judFunct</span><span class="p">(</span><span class="n">cat_jud</span><span class="p">):</span>
            <span class="k">continue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">name</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">Test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">name</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">dropList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[93]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[93]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(29574, 351)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#183;&#21024;&#38500;&#33258;&#21464;&#37327;&#29305;&#24449;&#20043;&#38388;&#30456;&#20851;&#24615;&#39640;&#30340;&#29305;&#24449;//&#38408;&#20540;&#36873;&#25321;0.8">&#183;&#21024;&#38500;&#33258;&#21464;&#37327;&#29305;&#24449;&#20043;&#38388;&#30456;&#20851;&#24615;&#39640;&#30340;&#29305;&#24449;//&#38408;&#20540;&#36873;&#25321;0.8<a class="anchor-link" href="#&#183;&#21024;&#38500;&#33258;&#21464;&#37327;&#29305;&#24449;&#20043;&#38388;&#30456;&#20851;&#24615;&#39640;&#30340;&#29305;&#24449;//&#38408;&#20540;&#36873;&#25321;0.8">&#182;</a></h3>
<pre><code>#·思路：筛选出高于相关系数高于阈值的特征组合//根据特征组合得到每个特征与目标变量的相关系数//保留拥有最大的相关系数的特征</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[94]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="p">[</span><span class="s1">&#39;log_price&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y_train</span> <span class="c1">#先将目标变量放进训练集中</span>
<span class="n">corr_all</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;pearson&#39;</span><span class="p">)</span>
<span class="n">corr_all</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s1">&#39;log_price&#39;</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[96]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#返回一个删除信息字典，key表示保留的列，value表示要删除的列//不需要保留分类变量的列</span>
<span class="k">def</span> <span class="nf">drop_self_cor</span><span class="p">(</span><span class="n">corr_df</span><span class="p">,</span><span class="n">targetName</span><span class="p">,</span><span class="n">thr</span><span class="p">):</span>
    <span class="n">rslt_dict</span><span class="o">=</span><span class="p">{}</span>
    <span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="n">corr_df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">colname</span> <span class="o">==</span> <span class="n">targetName</span><span class="p">):</span>
            <span class="k">continue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tmpt</span> <span class="o">=</span> <span class="n">corr_df</span><span class="p">[[</span><span class="n">colname</span><span class="p">,</span><span class="n">targetName</span><span class="p">]][</span><span class="nb">abs</span><span class="p">(</span><span class="n">corr_df</span><span class="p">[</span><span class="n">colname</span><span class="p">])</span><span class="o">&gt;=</span><span class="n">thr</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tmpt</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span><span class="c1">#存在高相关性的变量才进行下面的操作</span>
                <span class="n">drop_List</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tmpt</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
                <span class="n">keep_col</span> <span class="o">=</span> <span class="n">tmpt</span><span class="p">[</span><span class="n">tmpt</span><span class="p">[</span><span class="n">targetName</span><span class="p">]</span><span class="o">==</span><span class="n">tmpt</span><span class="p">[</span><span class="n">targetName</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()]</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">drop_List</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">keep_col</span><span class="p">)</span>
                <span class="n">rslt_dict</span><span class="p">[</span><span class="n">keep_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">drop_List</span>
    <span class="k">return</span> <span class="n">rslt_dict</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[97]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dropList</span> <span class="o">=</span> <span class="n">drop_self_cor</span><span class="p">(</span><span class="n">corr_all</span><span class="p">,</span><span class="s1">&#39;log_price&#39;</span><span class="p">,</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[98]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#删除训练集中的高度相关的冗余变量</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span><span class="n">valList</span> <span class="ow">in</span> <span class="n">dropList</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="n">valList</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">cat_judFunct</span><span class="p">(</span><span class="n">colname</span><span class="p">,</span><span class="n">List</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)):</span>
            <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">colname</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">Test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">colname</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">continue</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[99]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;log_price&#39;</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[100]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[100]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(29574, 126)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[101]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#删除相关系数为空的变量 # 这些变量方差趋近于0</span>
<span class="n">naList</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">corrwith</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">v</span><span class="p">:</span>
        <span class="n">naList</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">naList</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">naList</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[103]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#训练集：存在空值列采用平均数填充，不删除//是重要特征</span>
<span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">X_train</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">mean_val</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">mean_val</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[104]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#测试集：存在空值列采用平均数填充，不删除//是重要特征</span>
<span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">Test_df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">Test_df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">mean_val</span> <span class="o">=</span> <span class="n">Test_df</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">Test_df</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">mean_val</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[105]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[105]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(29574, 125)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#·结论最后筛选出42个特征，特征数目不大，不需要进行特征降维</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#保存一份训练数据</span>
<span class="c1"># X_train.to_excel(&#39;E:/Mather Cup/Coding/dataset/X_train_final.xlsx&#39;)</span>
<span class="c1">#保存一份测试数据</span>
<span class="c1"># Test_df.to_excel(&#39;E:/Mather Cup/Coding/dataset/Test_df_final.xlsx&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[106]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#测试集</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">Test_df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">],</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_carid</span> <span class="o">=</span> <span class="n">Test_df</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#183;&#27169;&#22411;&#24314;&#31435;">&#183;&#27169;&#22411;&#24314;&#31435;<a class="anchor-link" href="#&#183;&#27169;&#22411;&#24314;&#31435;">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#岭回归 Lasso回归 集成学习 lgb catboost xgboost // 损失函数选择Mae</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[107]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#对特征数据进行0-1区间缩放</span>
<span class="k">def</span> <span class="nf">Stander_01</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="n">dataframe</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">colName</span> <span class="ow">in</span> <span class="n">dataframe</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">minval</span><span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">colName</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="n">maxval</span><span class="o">=</span> <span class="n">dataframe</span><span class="p">[</span><span class="n">colName</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="n">gapval</span><span class="o">=</span> <span class="n">maxval</span><span class="o">-</span><span class="n">minval</span>
        <span class="n">dataframe</span><span class="p">[</span><span class="n">colName</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataframe</span><span class="p">[</span><span class="n">colName</span><span class="p">]</span><span class="o">-</span><span class="n">minval</span><span class="p">)</span><span class="o">/</span><span class="n">gapval</span>
    <span class="k">return</span> <span class="n">dataframe</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">Stander_01</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">Stander_01</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[108]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#定义题目评估指标</span>
<span class="k">def</span> <span class="nf">Model_Evaluate</span><span class="p">(</span><span class="n">pred_data</span><span class="p">,</span><span class="n">real_data</span><span class="p">):</span> <span class="c1">#pred_data,real_data为np.array格式，且已经取np.exm1</span>
    <span class="n">Ape_arry</span><span class="o">=</span><span class="nb">abs</span><span class="p">((</span><span class="n">pred_data</span><span class="o">-</span><span class="n">real_data</span><span class="p">)</span><span class="o">/</span><span class="n">real_data</span><span class="p">)</span>
    <span class="n">Mape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Ape_arry</span><span class="p">)</span>
    <span class="n">Accuracy5_count</span><span class="o">=</span><span class="mi">0</span>
    <span class="k">for</span> <span class="n">Ape</span> <span class="ow">in</span> <span class="n">Ape_arry</span><span class="p">:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">Ape</span><span class="o">&lt;=</span><span class="mf">0.05</span><span class="p">):</span>
            <span class="n">Accuracy5_count</span><span class="o">+=</span><span class="mi">1</span>
    <span class="n">Accuracy5</span> <span class="o">=</span> <span class="n">Accuracy5_count</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">Ape_arry</span><span class="p">)</span>
    <span class="n">indicator</span> <span class="o">=</span> <span class="mf">0.2</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">Mape</span><span class="p">)</span><span class="o">+</span><span class="mf">0.8</span><span class="o">*</span><span class="n">Accuracy5</span>
    <span class="k">return</span> <span class="n">indicator</span><span class="p">,</span><span class="n">Accuracy5</span><span class="p">,</span><span class="n">Mape</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[144]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#备份</span>
<span class="c1"># copyX_train = X_train.copy()</span>
<span class="c1"># copyY_train = Y_train</span>
<span class="c1"># copyX_test = X_test.copy</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="01-Ligahtgbm">01 Ligahtgbm<a class="anchor-link" href="#01-Ligahtgbm">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[145]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>
<span class="kn">from</span> <span class="nn">catboost</span> <span class="kn">import</span> <span class="n">CatBoostRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[149]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">Y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">X_data_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[147]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#自定义损失函数:MAE</span>
<span class="k">def</span> <span class="nf">myFeval</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">xgbtrain</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">xgbtrain</span><span class="o">.</span><span class="n">get_label</span><span class="p">()</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">label</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">preds</span><span class="p">))</span>
    <span class="k">return</span> <span class="s1">&#39;myFeval&#39;</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="kc">False</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[150]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">param</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;boosting_type&#39;</span><span class="p">:</span> <span class="s1">&#39;gbdt&#39;</span><span class="p">,</span>
         <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="mi">31</span><span class="p">,</span>
         <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
         <span class="s2">&quot;lambda_l2&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># 防止过拟合</span>
         <span class="s1">&#39;min_data_in_leaf&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>  <span class="c1"># 防止过拟合，好像都不用怎么调</span>
         <span class="s1">&#39;objective&#39;</span><span class="p">:</span> <span class="s1">&#39;regression_l1&#39;</span><span class="p">,</span>
         <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
         <span class="s2">&quot;min_child_samples&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>

         <span class="s2">&quot;feature_fraction&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
         <span class="s2">&quot;bagging_freq&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
         <span class="s2">&quot;bagging_fraction&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
         <span class="s2">&quot;bagging_seed&quot;</span><span class="p">:</span> <span class="mi">11</span><span class="p">,</span>
         <span class="s2">&quot;metric&quot;</span><span class="p">:</span> <span class="s1">&#39;mae&#39;</span><span class="p">,</span>
         <span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[151]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">folds</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2018</span><span class="p">)</span>
<span class="n">oof_lgb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_data</span><span class="p">))</span>
<span class="n">predictions_lgb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_data_test</span><span class="p">))</span>
<span class="n">predictions_train_lgb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_data</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[152]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">fold_</span><span class="p">,</span> <span class="p">(</span><span class="n">trn_idx</span><span class="p">,</span> <span class="n">val_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">folds</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">Y_data</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;fold n°</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fold_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">trn_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">X_data</span><span class="p">[</span><span class="n">trn_idx</span><span class="p">],</span> <span class="n">Y_data</span><span class="p">[</span><span class="n">trn_idx</span><span class="p">])</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">X_data</span><span class="p">[</span><span class="n">val_idx</span><span class="p">],</span> <span class="n">Y_data</span><span class="p">[</span><span class="n">val_idx</span><span class="p">])</span>

    <span class="n">num_round</span> <span class="o">=</span> <span class="mi">100000000</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">trn_data</span><span class="p">,</span> <span class="n">num_round</span><span class="p">,</span> <span class="n">valid_sets</span><span class="o">=</span><span class="p">[</span><span class="n">trn_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">],</span> <span class="n">verbose_eval</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                    <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">feval</span> <span class="o">=</span> <span class="n">myFeval</span><span class="p">)</span>
    <span class="n">oof_lgb</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_data</span><span class="p">[</span><span class="n">val_idx</span><span class="p">],</span> <span class="n">num_iteration</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">best_iteration</span><span class="p">)</span>
    <span class="n">predictions_lgb</span> <span class="o">+=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_data_test</span><span class="p">,</span> <span class="n">num_iteration</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">best_iteration</span><span class="p">)</span> <span class="o">/</span> <span class="n">folds</span><span class="o">.</span><span class="n">n_splits</span>
    <span class="n">predictions_train_lgb</span> <span class="o">+=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">num_iteration</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">best_iteration</span><span class="p">)</span> <span class="o">/</span> <span class="n">folds</span><span class="o">.</span><span class="n">n_splits</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>fold n°1
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012409 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9902
[LightGBM] [Info] Number of data points in the train set: 26616, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.424803
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.1124	training&#39;s myFeval: 2.08585	valid_1&#39;s l1: 0.110137	valid_1&#39;s myFeval: 1.86395
[600]	training&#39;s l1: 0.0795673	training&#39;s myFeval: 1.28357	valid_1&#39;s l1: 0.0807336	valid_1&#39;s myFeval: 1.16363
[900]	training&#39;s l1: 0.0721369	training&#39;s myFeval: 1.08827	valid_1&#39;s l1: 0.0750267	valid_1&#39;s myFeval: 1.03685
[1200]	training&#39;s l1: 0.0682563	training&#39;s myFeval: 1.00699	valid_1&#39;s l1: 0.0726582	valid_1&#39;s myFeval: 0.99575
[1500]	training&#39;s l1: 0.065466	training&#39;s myFeval: 0.959276	valid_1&#39;s l1: 0.0712654	valid_1&#39;s myFeval: 0.974229
[1800]	training&#39;s l1: 0.0632912	training&#39;s myFeval: 0.920499	valid_1&#39;s l1: 0.0702561	valid_1&#39;s myFeval: 0.95833
[2100]	training&#39;s l1: 0.0614164	training&#39;s myFeval: 0.885925	valid_1&#39;s l1: 0.0694126	valid_1&#39;s myFeval: 0.944797
[2400]	training&#39;s l1: 0.0598371	training&#39;s myFeval: 0.859463	valid_1&#39;s l1: 0.0687852	valid_1&#39;s myFeval: 0.934675
[2700]	training&#39;s l1: 0.0584419	training&#39;s myFeval: 0.837943	valid_1&#39;s l1: 0.0682024	valid_1&#39;s myFeval: 0.926024
[3000]	training&#39;s l1: 0.0572364	training&#39;s myFeval: 0.818221	valid_1&#39;s l1: 0.0677399	valid_1&#39;s myFeval: 0.919396
[3300]	training&#39;s l1: 0.0561204	training&#39;s myFeval: 0.800288	valid_1&#39;s l1: 0.0673745	valid_1&#39;s myFeval: 0.913919
[3600]	training&#39;s l1: 0.0551359	training&#39;s myFeval: 0.784257	valid_1&#39;s l1: 0.0670617	valid_1&#39;s myFeval: 0.909545
[3900]	training&#39;s l1: 0.054251	training&#39;s myFeval: 0.770119	valid_1&#39;s l1: 0.0667917	valid_1&#39;s myFeval: 0.906063
[4200]	training&#39;s l1: 0.0534437	training&#39;s myFeval: 0.75745	valid_1&#39;s l1: 0.0665691	valid_1&#39;s myFeval: 0.902822
[4500]	training&#39;s l1: 0.0526804	training&#39;s myFeval: 0.745238	valid_1&#39;s l1: 0.066338	valid_1&#39;s myFeval: 0.899602
[4800]	training&#39;s l1: 0.0519714	training&#39;s myFeval: 0.734504	valid_1&#39;s l1: 0.0661423	valid_1&#39;s myFeval: 0.897026
[5100]	training&#39;s l1: 0.0513245	training&#39;s myFeval: 0.724768	valid_1&#39;s l1: 0.0659666	valid_1&#39;s myFeval: 0.89452
[5400]	training&#39;s l1: 0.0507314	training&#39;s myFeval: 0.715733	valid_1&#39;s l1: 0.0658075	valid_1&#39;s myFeval: 0.892037
[5700]	training&#39;s l1: 0.0501727	training&#39;s myFeval: 0.708168	valid_1&#39;s l1: 0.0656696	valid_1&#39;s myFeval: 0.89018
[6000]	training&#39;s l1: 0.0496622	training&#39;s myFeval: 0.700138	valid_1&#39;s l1: 0.0655199	valid_1&#39;s myFeval: 0.887696
[6300]	training&#39;s l1: 0.0491944	training&#39;s myFeval: 0.692266	valid_1&#39;s l1: 0.065414	valid_1&#39;s myFeval: 0.886052
[6600]	training&#39;s l1: 0.0487304	training&#39;s myFeval: 0.685292	valid_1&#39;s l1: 0.0653068	valid_1&#39;s myFeval: 0.884576
[6900]	training&#39;s l1: 0.0482693	training&#39;s myFeval: 0.678401	valid_1&#39;s l1: 0.0651913	valid_1&#39;s myFeval: 0.88277
[7200]	training&#39;s l1: 0.0478928	training&#39;s myFeval: 0.67266	valid_1&#39;s l1: 0.0651074	valid_1&#39;s myFeval: 0.88158
[7500]	training&#39;s l1: 0.0475374	training&#39;s myFeval: 0.667189	valid_1&#39;s l1: 0.0650388	valid_1&#39;s myFeval: 0.880641
[7800]	training&#39;s l1: 0.047199	training&#39;s myFeval: 0.662648	valid_1&#39;s l1: 0.0649621	valid_1&#39;s myFeval: 0.879755
[8100]	training&#39;s l1: 0.046882	training&#39;s myFeval: 0.658989	valid_1&#39;s l1: 0.0649193	valid_1&#39;s myFeval: 0.879254
[8400]	training&#39;s l1: 0.0465994	training&#39;s myFeval: 0.655842	valid_1&#39;s l1: 0.0648811	valid_1&#39;s myFeval: 0.8788
[8700]	training&#39;s l1: 0.0463285	training&#39;s myFeval: 0.652326	valid_1&#39;s l1: 0.0648315	valid_1&#39;s myFeval: 0.878043
[9000]	training&#39;s l1: 0.0460692	training&#39;s myFeval: 0.648627	valid_1&#39;s l1: 0.0647696	valid_1&#39;s myFeval: 0.877086
[9300]	training&#39;s l1: 0.04579	training&#39;s myFeval: 0.643872	valid_1&#39;s l1: 0.0647168	valid_1&#39;s myFeval: 0.876288
[9600]	training&#39;s l1: 0.0455279	training&#39;s myFeval: 0.63962	valid_1&#39;s l1: 0.0646552	valid_1&#39;s myFeval: 0.875271
[9900]	training&#39;s l1: 0.0452622	training&#39;s myFeval: 0.635258	valid_1&#39;s l1: 0.0646029	valid_1&#39;s myFeval: 0.874566
[10200]	training&#39;s l1: 0.0450099	training&#39;s myFeval: 0.630686	valid_1&#39;s l1: 0.064552	valid_1&#39;s myFeval: 0.873635
[10500]	training&#39;s l1: 0.0447611	training&#39;s myFeval: 0.626685	valid_1&#39;s l1: 0.0645066	valid_1&#39;s myFeval: 0.872749
[10800]	training&#39;s l1: 0.0445378	training&#39;s myFeval: 0.622927	valid_1&#39;s l1: 0.0644612	valid_1&#39;s myFeval: 0.872036
[11100]	training&#39;s l1: 0.0443496	training&#39;s myFeval: 0.619515	valid_1&#39;s l1: 0.0644232	valid_1&#39;s myFeval: 0.871211
[11400]	training&#39;s l1: 0.0441649	training&#39;s myFeval: 0.616467	valid_1&#39;s l1: 0.0643947	valid_1&#39;s myFeval: 0.870812
[11700]	training&#39;s l1: 0.0439763	training&#39;s myFeval: 0.613156	valid_1&#39;s l1: 0.0643492	valid_1&#39;s myFeval: 0.870195
[12000]	training&#39;s l1: 0.043808	training&#39;s myFeval: 0.61052	valid_1&#39;s l1: 0.0643207	valid_1&#39;s myFeval: 0.869752
[12300]	training&#39;s l1: 0.043617	training&#39;s myFeval: 0.607733	valid_1&#39;s l1: 0.0642907	valid_1&#39;s myFeval: 0.869376
[12600]	training&#39;s l1: 0.0434597	training&#39;s myFeval: 0.605645	valid_1&#39;s l1: 0.0642691	valid_1&#39;s myFeval: 0.869037
[12900]	training&#39;s l1: 0.0432832	training&#39;s myFeval: 0.603318	valid_1&#39;s l1: 0.0642396	valid_1&#39;s myFeval: 0.868743
[13200]	training&#39;s l1: 0.0430933	training&#39;s myFeval: 0.600418	valid_1&#39;s l1: 0.0642007	valid_1&#39;s myFeval: 0.868144
[13500]	training&#39;s l1: 0.0429037	training&#39;s myFeval: 0.597392	valid_1&#39;s l1: 0.0641751	valid_1&#39;s myFeval: 0.867811
[13800]	training&#39;s l1: 0.0427263	training&#39;s myFeval: 0.594681	valid_1&#39;s l1: 0.0641583	valid_1&#39;s myFeval: 0.86751
[14100]	training&#39;s l1: 0.0425651	training&#39;s myFeval: 0.592527	valid_1&#39;s l1: 0.0641239	valid_1&#39;s myFeval: 0.867071
[14400]	training&#39;s l1: 0.0423726	training&#39;s myFeval: 0.590102	valid_1&#39;s l1: 0.0640921	valid_1&#39;s myFeval: 0.866647
[14700]	training&#39;s l1: 0.0422094	training&#39;s myFeval: 0.587976	valid_1&#39;s l1: 0.0640664	valid_1&#39;s myFeval: 0.8664
[15000]	training&#39;s l1: 0.042064	training&#39;s myFeval: 0.585555	valid_1&#39;s l1: 0.064043	valid_1&#39;s myFeval: 0.866245
[15300]	training&#39;s l1: 0.0419309	training&#39;s myFeval: 0.58343	valid_1&#39;s l1: 0.064026	valid_1&#39;s myFeval: 0.865876
[15600]	training&#39;s l1: 0.041818	training&#39;s myFeval: 0.581812	valid_1&#39;s l1: 0.0640069	valid_1&#39;s myFeval: 0.865688
[15900]	training&#39;s l1: 0.0417117	training&#39;s myFeval: 0.580366	valid_1&#39;s l1: 0.0639909	valid_1&#39;s myFeval: 0.865501
[16200]	training&#39;s l1: 0.0416065	training&#39;s myFeval: 0.579051	valid_1&#39;s l1: 0.0639823	valid_1&#39;s myFeval: 0.865414
[16500]	training&#39;s l1: 0.0415158	training&#39;s myFeval: 0.577973	valid_1&#39;s l1: 0.0639737	valid_1&#39;s myFeval: 0.865315
[16800]	training&#39;s l1: 0.0414173	training&#39;s myFeval: 0.576674	valid_1&#39;s l1: 0.0639644	valid_1&#39;s myFeval: 0.865225
[17100]	training&#39;s l1: 0.041288	training&#39;s myFeval: 0.574698	valid_1&#39;s l1: 0.0639497	valid_1&#39;s myFeval: 0.864969
[17400]	training&#39;s l1: 0.0411789	training&#39;s myFeval: 0.573112	valid_1&#39;s l1: 0.0639323	valid_1&#39;s myFeval: 0.8647
[17700]	training&#39;s l1: 0.0410864	training&#39;s myFeval: 0.571683	valid_1&#39;s l1: 0.0639214	valid_1&#39;s myFeval: 0.864565
[18000]	training&#39;s l1: 0.0409855	training&#39;s myFeval: 0.570136	valid_1&#39;s l1: 0.0639027	valid_1&#39;s myFeval: 0.864313
[18300]	training&#39;s l1: 0.0408859	training&#39;s myFeval: 0.568625	valid_1&#39;s l1: 0.0638884	valid_1&#39;s myFeval: 0.864049
[18600]	training&#39;s l1: 0.0407861	training&#39;s myFeval: 0.567141	valid_1&#39;s l1: 0.0638758	valid_1&#39;s myFeval: 0.863917
[18900]	training&#39;s l1: 0.040694	training&#39;s myFeval: 0.565855	valid_1&#39;s l1: 0.0638616	valid_1&#39;s myFeval: 0.86373
[19200]	training&#39;s l1: 0.0405776	training&#39;s myFeval: 0.564019	valid_1&#39;s l1: 0.0638483	valid_1&#39;s myFeval: 0.863577
[19500]	training&#39;s l1: 0.0404837	training&#39;s myFeval: 0.562667	valid_1&#39;s l1: 0.0638332	valid_1&#39;s myFeval: 0.863325
[19800]	training&#39;s l1: 0.0403908	training&#39;s myFeval: 0.561196	valid_1&#39;s l1: 0.0638224	valid_1&#39;s myFeval: 0.863027
[20100]	training&#39;s l1: 0.0402887	training&#39;s myFeval: 0.559566	valid_1&#39;s l1: 0.0638074	valid_1&#39;s myFeval: 0.862771
[20400]	training&#39;s l1: 0.040203	training&#39;s myFeval: 0.558259	valid_1&#39;s l1: 0.0637943	valid_1&#39;s myFeval: 0.862548
[20700]	training&#39;s l1: 0.0401299	training&#39;s myFeval: 0.557126	valid_1&#39;s l1: 0.063778	valid_1&#39;s myFeval: 0.862361
[21000]	training&#39;s l1: 0.0400688	training&#39;s myFeval: 0.556118	valid_1&#39;s l1: 0.0637692	valid_1&#39;s myFeval: 0.862247
[21300]	training&#39;s l1: 0.0399887	training&#39;s myFeval: 0.554969	valid_1&#39;s l1: 0.0637564	valid_1&#39;s myFeval: 0.862114
[21600]	training&#39;s l1: 0.0398896	training&#39;s myFeval: 0.553503	valid_1&#39;s l1: 0.0637406	valid_1&#39;s myFeval: 0.861937
[21900]	training&#39;s l1: 0.0398075	training&#39;s myFeval: 0.55221	valid_1&#39;s l1: 0.0637345	valid_1&#39;s myFeval: 0.861724
[22200]	training&#39;s l1: 0.0397107	training&#39;s myFeval: 0.550921	valid_1&#39;s l1: 0.0637277	valid_1&#39;s myFeval: 0.861596
[22500]	training&#39;s l1: 0.0395853	training&#39;s myFeval: 0.549591	valid_1&#39;s l1: 0.063707	valid_1&#39;s myFeval: 0.861388
[22800]	training&#39;s l1: 0.0394723	training&#39;s myFeval: 0.548214	valid_1&#39;s l1: 0.0636886	valid_1&#39;s myFeval: 0.86115
[23100]	training&#39;s l1: 0.0393916	training&#39;s myFeval: 0.547011	valid_1&#39;s l1: 0.0636778	valid_1&#39;s myFeval: 0.860875
[23400]	training&#39;s l1: 0.0393138	training&#39;s myFeval: 0.545919	valid_1&#39;s l1: 0.0636628	valid_1&#39;s myFeval: 0.860716
[23700]	training&#39;s l1: 0.0392415	training&#39;s myFeval: 0.544859	valid_1&#39;s l1: 0.0636498	valid_1&#39;s myFeval: 0.860486
[24000]	training&#39;s l1: 0.0391718	training&#39;s myFeval: 0.543753	valid_1&#39;s l1: 0.0636502	valid_1&#39;s myFeval: 0.860569
[24300]	training&#39;s l1: 0.0390574	training&#39;s myFeval: 0.542287	valid_1&#39;s l1: 0.0636462	valid_1&#39;s myFeval: 0.860572
Early stopping, best iteration is:
[23725]	training&#39;s l1: 0.0392362	training&#39;s myFeval: 0.544791	valid_1&#39;s l1: 0.0636483	valid_1&#39;s myFeval: 0.860468
fold n°2
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009468 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9874
[LightGBM] [Info] Number of data points in the train set: 26616, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.424803
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.111814	training&#39;s myFeval: 2.04727	valid_1&#39;s l1: 0.113493	valid_1&#39;s myFeval: 2.15086
[600]	training&#39;s l1: 0.0790167	training&#39;s myFeval: 1.25161	valid_1&#39;s l1: 0.0835403	valid_1&#39;s myFeval: 1.42446
[900]	training&#39;s l1: 0.0718099	training&#39;s myFeval: 1.07582	valid_1&#39;s l1: 0.0778732	valid_1&#39;s myFeval: 1.26345
[1200]	training&#39;s l1: 0.0680285	training&#39;s myFeval: 0.998844	valid_1&#39;s l1: 0.0755883	valid_1&#39;s myFeval: 1.19781
[1500]	training&#39;s l1: 0.065273	training&#39;s myFeval: 0.952021	valid_1&#39;s l1: 0.0741977	valid_1&#39;s myFeval: 1.16481
[1800]	training&#39;s l1: 0.0629933	training&#39;s myFeval: 0.911155	valid_1&#39;s l1: 0.0731181	valid_1&#39;s myFeval: 1.1367
[2100]	training&#39;s l1: 0.0611312	training&#39;s myFeval: 0.880909	valid_1&#39;s l1: 0.0723036	valid_1&#39;s myFeval: 1.11972
[2400]	training&#39;s l1: 0.0595627	training&#39;s myFeval: 0.854237	valid_1&#39;s l1: 0.0716463	valid_1&#39;s myFeval: 1.10601
[2700]	training&#39;s l1: 0.0581787	training&#39;s myFeval: 0.830658	valid_1&#39;s l1: 0.0711182	valid_1&#39;s myFeval: 1.09351
[3000]	training&#39;s l1: 0.0569493	training&#39;s myFeval: 0.810261	valid_1&#39;s l1: 0.0707045	valid_1&#39;s myFeval: 1.08381
[3300]	training&#39;s l1: 0.0558299	training&#39;s myFeval: 0.791566	valid_1&#39;s l1: 0.070353	valid_1&#39;s myFeval: 1.07564
[3600]	training&#39;s l1: 0.0548626	training&#39;s myFeval: 0.776116	valid_1&#39;s l1: 0.0700774	valid_1&#39;s myFeval: 1.06921
[3900]	training&#39;s l1: 0.053965	training&#39;s myFeval: 0.762303	valid_1&#39;s l1: 0.0698204	valid_1&#39;s myFeval: 1.06407
[4200]	training&#39;s l1: 0.0531773	training&#39;s myFeval: 0.750191	valid_1&#39;s l1: 0.0695675	valid_1&#39;s myFeval: 1.05929
[4500]	training&#39;s l1: 0.0524587	training&#39;s myFeval: 0.73886	valid_1&#39;s l1: 0.0693783	valid_1&#39;s myFeval: 1.05508
[4800]	training&#39;s l1: 0.0517705	training&#39;s myFeval: 0.728153	valid_1&#39;s l1: 0.0692144	valid_1&#39;s myFeval: 1.05132
[5100]	training&#39;s l1: 0.0511221	training&#39;s myFeval: 0.718618	valid_1&#39;s l1: 0.0690347	valid_1&#39;s myFeval: 1.0478
[5400]	training&#39;s l1: 0.0505366	training&#39;s myFeval: 0.709739	valid_1&#39;s l1: 0.0688631	valid_1&#39;s myFeval: 1.04458
[5700]	training&#39;s l1: 0.0499926	training&#39;s myFeval: 0.701369	valid_1&#39;s l1: 0.068732	valid_1&#39;s myFeval: 1.04208
[6000]	training&#39;s l1: 0.0495392	training&#39;s myFeval: 0.69506	valid_1&#39;s l1: 0.0686466	valid_1&#39;s myFeval: 1.04018
[6300]	training&#39;s l1: 0.0491101	training&#39;s myFeval: 0.689362	valid_1&#39;s l1: 0.0685538	valid_1&#39;s myFeval: 1.03849
[6600]	training&#39;s l1: 0.0487277	training&#39;s myFeval: 0.683454	valid_1&#39;s l1: 0.0684789	valid_1&#39;s myFeval: 1.03696
[6900]	training&#39;s l1: 0.0484031	training&#39;s myFeval: 0.677855	valid_1&#39;s l1: 0.0684147	valid_1&#39;s myFeval: 1.0353
[7200]	training&#39;s l1: 0.0480541	training&#39;s myFeval: 0.672114	valid_1&#39;s l1: 0.0683254	valid_1&#39;s myFeval: 1.03371
[7500]	training&#39;s l1: 0.0476592	training&#39;s myFeval: 0.666046	valid_1&#39;s l1: 0.068214	valid_1&#39;s myFeval: 1.03181
[7800]	training&#39;s l1: 0.0472785	training&#39;s myFeval: 0.660513	valid_1&#39;s l1: 0.0681189	valid_1&#39;s myFeval: 1.02989
[8100]	training&#39;s l1: 0.0469383	training&#39;s myFeval: 0.655927	valid_1&#39;s l1: 0.068041	valid_1&#39;s myFeval: 1.02841
[8400]	training&#39;s l1: 0.0466106	training&#39;s myFeval: 0.650341	valid_1&#39;s l1: 0.0679703	valid_1&#39;s myFeval: 1.02726
[8700]	training&#39;s l1: 0.0463261	training&#39;s myFeval: 0.646314	valid_1&#39;s l1: 0.0679125	valid_1&#39;s myFeval: 1.02615
[9000]	training&#39;s l1: 0.0460293	training&#39;s myFeval: 0.641756	valid_1&#39;s l1: 0.0678512	valid_1&#39;s myFeval: 1.02484
[9300]	training&#39;s l1: 0.0457853	training&#39;s myFeval: 0.63821	valid_1&#39;s l1: 0.067805	valid_1&#39;s myFeval: 1.02414
[9600]	training&#39;s l1: 0.0455263	training&#39;s myFeval: 0.634584	valid_1&#39;s l1: 0.0677472	valid_1&#39;s myFeval: 1.02322
[9900]	training&#39;s l1: 0.0452857	training&#39;s myFeval: 0.631137	valid_1&#39;s l1: 0.0676967	valid_1&#39;s myFeval: 1.02254
[10200]	training&#39;s l1: 0.0450665	training&#39;s myFeval: 0.627841	valid_1&#39;s l1: 0.0676664	valid_1&#39;s myFeval: 1.02231
[10500]	training&#39;s l1: 0.0448537	training&#39;s myFeval: 0.624325	valid_1&#39;s l1: 0.0676296	valid_1&#39;s myFeval: 1.02144
[10800]	training&#39;s l1: 0.0446413	training&#39;s myFeval: 0.620913	valid_1&#39;s l1: 0.0675681	valid_1&#39;s myFeval: 1.02016
[11100]	training&#39;s l1: 0.0444375	training&#39;s myFeval: 0.617665	valid_1&#39;s l1: 0.0675344	valid_1&#39;s myFeval: 1.01881
[11400]	training&#39;s l1: 0.0442503	training&#39;s myFeval: 0.615013	valid_1&#39;s l1: 0.0675049	valid_1&#39;s myFeval: 1.01802
[11700]	training&#39;s l1: 0.0440386	training&#39;s myFeval: 0.611877	valid_1&#39;s l1: 0.0674656	valid_1&#39;s myFeval: 1.01713
[12000]	training&#39;s l1: 0.0438381	training&#39;s myFeval: 0.608681	valid_1&#39;s l1: 0.0674189	valid_1&#39;s myFeval: 1.01602
[12300]	training&#39;s l1: 0.0436395	training&#39;s myFeval: 0.605527	valid_1&#39;s l1: 0.0673787	valid_1&#39;s myFeval: 1.01516
[12600]	training&#39;s l1: 0.0434533	training&#39;s myFeval: 0.602565	valid_1&#39;s l1: 0.0673482	valid_1&#39;s myFeval: 1.01458
[12900]	training&#39;s l1: 0.0432838	training&#39;s myFeval: 0.600107	valid_1&#39;s l1: 0.0673122	valid_1&#39;s myFeval: 1.01392
[13200]	training&#39;s l1: 0.0431438	training&#39;s myFeval: 0.598052	valid_1&#39;s l1: 0.0672758	valid_1&#39;s myFeval: 1.01324
[13500]	training&#39;s l1: 0.0430076	training&#39;s myFeval: 0.595807	valid_1&#39;s l1: 0.0672553	valid_1&#39;s myFeval: 1.01278
[13800]	training&#39;s l1: 0.0428786	training&#39;s myFeval: 0.593951	valid_1&#39;s l1: 0.0672402	valid_1&#39;s myFeval: 1.01253
[14100]	training&#39;s l1: 0.0427578	training&#39;s myFeval: 0.591836	valid_1&#39;s l1: 0.0672242	valid_1&#39;s myFeval: 1.01217
[14400]	training&#39;s l1: 0.042622	training&#39;s myFeval: 0.589406	valid_1&#39;s l1: 0.0672011	valid_1&#39;s myFeval: 1.0116
[14700]	training&#39;s l1: 0.0425084	training&#39;s myFeval: 0.587522	valid_1&#39;s l1: 0.0671734	valid_1&#39;s myFeval: 1.01113
[15000]	training&#39;s l1: 0.0423969	training&#39;s myFeval: 0.585738	valid_1&#39;s l1: 0.0671451	valid_1&#39;s myFeval: 1.01059
[15300]	training&#39;s l1: 0.0422643	training&#39;s myFeval: 0.583815	valid_1&#39;s l1: 0.0671117	valid_1&#39;s myFeval: 1.00989
[15600]	training&#39;s l1: 0.0421207	training&#39;s myFeval: 0.581637	valid_1&#39;s l1: 0.0670857	valid_1&#39;s myFeval: 1.00934
[15900]	training&#39;s l1: 0.0420043	training&#39;s myFeval: 0.579812	valid_1&#39;s l1: 0.0670649	valid_1&#39;s myFeval: 1.00894
[16200]	training&#39;s l1: 0.0418754	training&#39;s myFeval: 0.577843	valid_1&#39;s l1: 0.0670465	valid_1&#39;s myFeval: 1.00859
[16500]	training&#39;s l1: 0.0417386	training&#39;s myFeval: 0.575905	valid_1&#39;s l1: 0.0670123	valid_1&#39;s myFeval: 1.00792
[16800]	training&#39;s l1: 0.0416368	training&#39;s myFeval: 0.574386	valid_1&#39;s l1: 0.066996	valid_1&#39;s myFeval: 1.00758
[17100]	training&#39;s l1: 0.0415342	training&#39;s myFeval: 0.573023	valid_1&#39;s l1: 0.0669826	valid_1&#39;s myFeval: 1.00729
[17400]	training&#39;s l1: 0.0414299	training&#39;s myFeval: 0.57158	valid_1&#39;s l1: 0.0669595	valid_1&#39;s myFeval: 1.00694
[17700]	training&#39;s l1: 0.041328	training&#39;s myFeval: 0.570233	valid_1&#39;s l1: 0.0669538	valid_1&#39;s myFeval: 1.00695
[18000]	training&#39;s l1: 0.0412163	training&#39;s myFeval: 0.568806	valid_1&#39;s l1: 0.0669486	valid_1&#39;s myFeval: 1.00701
Early stopping, best iteration is:
[17547]	training&#39;s l1: 0.0413793	training&#39;s myFeval: 0.570893	valid_1&#39;s l1: 0.066955	valid_1&#39;s myFeval: 1.00691
fold n°3
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013317 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9892
[LightGBM] [Info] Number of data points in the train set: 26616, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.424803
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.111687	training&#39;s myFeval: 2.05291	valid_1&#39;s l1: 0.117595	valid_1&#39;s myFeval: 2.22118
[600]	training&#39;s l1: 0.0790634	training&#39;s myFeval: 1.27126	valid_1&#39;s l1: 0.084927	valid_1&#39;s myFeval: 1.37858
[900]	training&#39;s l1: 0.071731	training&#39;s myFeval: 1.08308	valid_1&#39;s l1: 0.0790702	valid_1&#39;s myFeval: 1.19765
[1200]	training&#39;s l1: 0.0678824	training&#39;s myFeval: 1.00075	valid_1&#39;s l1: 0.0766559	valid_1&#39;s myFeval: 1.15507
[1500]	training&#39;s l1: 0.0651824	training&#39;s myFeval: 0.951627	valid_1&#39;s l1: 0.0752371	valid_1&#39;s myFeval: 1.12936
[1800]	training&#39;s l1: 0.0630436	training&#39;s myFeval: 0.912205	valid_1&#39;s l1: 0.0742484	valid_1&#39;s myFeval: 1.10799
[2100]	training&#39;s l1: 0.0612369	training&#39;s myFeval: 0.881266	valid_1&#39;s l1: 0.0735099	valid_1&#39;s myFeval: 1.0937
[2400]	training&#39;s l1: 0.0597121	training&#39;s myFeval: 0.855815	valid_1&#39;s l1: 0.0729821	valid_1&#39;s myFeval: 1.08316
[2700]	training&#39;s l1: 0.0583731	training&#39;s myFeval: 0.832615	valid_1&#39;s l1: 0.0724506	valid_1&#39;s myFeval: 1.0722
[3000]	training&#39;s l1: 0.057173	training&#39;s myFeval: 0.813851	valid_1&#39;s l1: 0.0720099	valid_1&#39;s myFeval: 1.06378
[3300]	training&#39;s l1: 0.0561073	training&#39;s myFeval: 0.796528	valid_1&#39;s l1: 0.0716191	valid_1&#39;s myFeval: 1.05648
[3600]	training&#39;s l1: 0.0551554	training&#39;s myFeval: 0.781812	valid_1&#39;s l1: 0.0713086	valid_1&#39;s myFeval: 1.05132
[3900]	training&#39;s l1: 0.054264	training&#39;s myFeval: 0.767974	valid_1&#39;s l1: 0.0710102	valid_1&#39;s myFeval: 1.04604
[4200]	training&#39;s l1: 0.0534357	training&#39;s myFeval: 0.754657	valid_1&#39;s l1: 0.0707605	valid_1&#39;s myFeval: 1.04129
[4500]	training&#39;s l1: 0.0526986	training&#39;s myFeval: 0.742499	valid_1&#39;s l1: 0.0705237	valid_1&#39;s myFeval: 1.03659
[4800]	training&#39;s l1: 0.0520079	training&#39;s myFeval: 0.731046	valid_1&#39;s l1: 0.0702975	valid_1&#39;s myFeval: 1.03156
[5100]	training&#39;s l1: 0.051389	training&#39;s myFeval: 0.720873	valid_1&#39;s l1: 0.0700897	valid_1&#39;s myFeval: 1.02801
[5400]	training&#39;s l1: 0.0507823	training&#39;s myFeval: 0.710759	valid_1&#39;s l1: 0.0699093	valid_1&#39;s myFeval: 1.02453
[5700]	training&#39;s l1: 0.0502278	training&#39;s myFeval: 0.701922	valid_1&#39;s l1: 0.0697619	valid_1&#39;s myFeval: 1.02177
[6000]	training&#39;s l1: 0.0497635	training&#39;s myFeval: 0.694126	valid_1&#39;s l1: 0.0696263	valid_1&#39;s myFeval: 1.01924
[6300]	training&#39;s l1: 0.0493062	training&#39;s myFeval: 0.68657	valid_1&#39;s l1: 0.0694831	valid_1&#39;s myFeval: 1.01676
[6600]	training&#39;s l1: 0.0488502	training&#39;s myFeval: 0.679394	valid_1&#39;s l1: 0.06935	valid_1&#39;s myFeval: 1.01414
[6900]	training&#39;s l1: 0.0484114	training&#39;s myFeval: 0.672553	valid_1&#39;s l1: 0.0692173	valid_1&#39;s myFeval: 1.01163
[7200]	training&#39;s l1: 0.0480066	training&#39;s myFeval: 0.666691	valid_1&#39;s l1: 0.0691095	valid_1&#39;s myFeval: 1.00974
[7500]	training&#39;s l1: 0.0476473	training&#39;s myFeval: 0.661701	valid_1&#39;s l1: 0.0690166	valid_1&#39;s myFeval: 1.00827
[7800]	training&#39;s l1: 0.0472949	training&#39;s myFeval: 0.656562	valid_1&#39;s l1: 0.0689291	valid_1&#39;s myFeval: 1.00677
[8100]	training&#39;s l1: 0.0470156	training&#39;s myFeval: 0.651626	valid_1&#39;s l1: 0.0688539	valid_1&#39;s myFeval: 1.00495
[8400]	training&#39;s l1: 0.0467746	training&#39;s myFeval: 0.647644	valid_1&#39;s l1: 0.06879	valid_1&#39;s myFeval: 1.00352
[8700]	training&#39;s l1: 0.0464836	training&#39;s myFeval: 0.643189	valid_1&#39;s l1: 0.0687139	valid_1&#39;s myFeval: 1.00223
[9000]	training&#39;s l1: 0.046179	training&#39;s myFeval: 0.63883	valid_1&#39;s l1: 0.0686329	valid_1&#39;s myFeval: 1.00073
[9300]	training&#39;s l1: 0.0458935	training&#39;s myFeval: 0.634583	valid_1&#39;s l1: 0.0685695	valid_1&#39;s myFeval: 0.999727
[9600]	training&#39;s l1: 0.0456137	training&#39;s myFeval: 0.630072	valid_1&#39;s l1: 0.0685008	valid_1&#39;s myFeval: 0.998489
[9900]	training&#39;s l1: 0.0453389	training&#39;s myFeval: 0.626387	valid_1&#39;s l1: 0.0684344	valid_1&#39;s myFeval: 0.997475
[10200]	training&#39;s l1: 0.0450883	training&#39;s myFeval: 0.623048	valid_1&#39;s l1: 0.0683827	valid_1&#39;s myFeval: 0.996734
[10500]	training&#39;s l1: 0.0448791	training&#39;s myFeval: 0.620365	valid_1&#39;s l1: 0.0683437	valid_1&#39;s myFeval: 0.996085
[10800]	training&#39;s l1: 0.0446568	training&#39;s myFeval: 0.617399	valid_1&#39;s l1: 0.0683067	valid_1&#39;s myFeval: 0.995633
[11100]	training&#39;s l1: 0.0444306	training&#39;s myFeval: 0.614388	valid_1&#39;s l1: 0.0682473	valid_1&#39;s myFeval: 0.995011
[11400]	training&#39;s l1: 0.0442157	training&#39;s myFeval: 0.611309	valid_1&#39;s l1: 0.0681907	valid_1&#39;s myFeval: 0.994152
[11700]	training&#39;s l1: 0.0440143	training&#39;s myFeval: 0.608424	valid_1&#39;s l1: 0.068154	valid_1&#39;s myFeval: 0.99331
[12000]	training&#39;s l1: 0.0438533	training&#39;s myFeval: 0.606177	valid_1&#39;s l1: 0.0681232	valid_1&#39;s myFeval: 0.992946
[12300]	training&#39;s l1: 0.0436925	training&#39;s myFeval: 0.6042	valid_1&#39;s l1: 0.0680904	valid_1&#39;s myFeval: 0.992554
[12600]	training&#39;s l1: 0.0435019	training&#39;s myFeval: 0.601434	valid_1&#39;s l1: 0.0680297	valid_1&#39;s myFeval: 0.991694
[12900]	training&#39;s l1: 0.0433272	training&#39;s myFeval: 0.598961	valid_1&#39;s l1: 0.0679947	valid_1&#39;s myFeval: 0.991068
[13200]	training&#39;s l1: 0.0431667	training&#39;s myFeval: 0.596729	valid_1&#39;s l1: 0.0679697	valid_1&#39;s myFeval: 0.990535
[13500]	training&#39;s l1: 0.0430153	training&#39;s myFeval: 0.594528	valid_1&#39;s l1: 0.0679253	valid_1&#39;s myFeval: 0.989902
[13800]	training&#39;s l1: 0.0428552	training&#39;s myFeval: 0.592101	valid_1&#39;s l1: 0.0678886	valid_1&#39;s myFeval: 0.989201
[14100]	training&#39;s l1: 0.0427002	training&#39;s myFeval: 0.589846	valid_1&#39;s l1: 0.0678533	valid_1&#39;s myFeval: 0.988821
[14400]	training&#39;s l1: 0.0425354	training&#39;s myFeval: 0.587205	valid_1&#39;s l1: 0.0678099	valid_1&#39;s myFeval: 0.988103
[14700]	training&#39;s l1: 0.0423844	training&#39;s myFeval: 0.58481	valid_1&#39;s l1: 0.067772	valid_1&#39;s myFeval: 0.987502
[15000]	training&#39;s l1: 0.0422443	training&#39;s myFeval: 0.582422	valid_1&#39;s l1: 0.0677559	valid_1&#39;s myFeval: 0.987476
[15300]	training&#39;s l1: 0.0421127	training&#39;s myFeval: 0.580511	valid_1&#39;s l1: 0.0677142	valid_1&#39;s myFeval: 0.987041
[15600]	training&#39;s l1: 0.0419769	training&#39;s myFeval: 0.578609	valid_1&#39;s l1: 0.0676789	valid_1&#39;s myFeval: 0.986684
[15900]	training&#39;s l1: 0.0418695	training&#39;s myFeval: 0.576736	valid_1&#39;s l1: 0.0676478	valid_1&#39;s myFeval: 0.986306
[16200]	training&#39;s l1: 0.0417584	training&#39;s myFeval: 0.575079	valid_1&#39;s l1: 0.0676148	valid_1&#39;s myFeval: 0.985859
[16500]	training&#39;s l1: 0.0416368	training&#39;s myFeval: 0.573391	valid_1&#39;s l1: 0.0675899	valid_1&#39;s myFeval: 0.985513
[16800]	training&#39;s l1: 0.0415242	training&#39;s myFeval: 0.571743	valid_1&#39;s l1: 0.0675661	valid_1&#39;s myFeval: 0.985083
[17100]	training&#39;s l1: 0.0413972	training&#39;s myFeval: 0.569971	valid_1&#39;s l1: 0.0675379	valid_1&#39;s myFeval: 0.984719
[17400]	training&#39;s l1: 0.0412814	training&#39;s myFeval: 0.568311	valid_1&#39;s l1: 0.0675192	valid_1&#39;s myFeval: 0.984476
[17700]	training&#39;s l1: 0.041173	training&#39;s myFeval: 0.566718	valid_1&#39;s l1: 0.0674964	valid_1&#39;s myFeval: 0.984086
[18000]	training&#39;s l1: 0.0410958	training&#39;s myFeval: 0.565543	valid_1&#39;s l1: 0.067486	valid_1&#39;s myFeval: 0.983892
[18300]	training&#39;s l1: 0.0410136	training&#39;s myFeval: 0.564411	valid_1&#39;s l1: 0.0674666	valid_1&#39;s myFeval: 0.983603
[18600]	training&#39;s l1: 0.0409306	training&#39;s myFeval: 0.56328	valid_1&#39;s l1: 0.0674474	valid_1&#39;s myFeval: 0.983358
[18900]	training&#39;s l1: 0.0408381	training&#39;s myFeval: 0.562085	valid_1&#39;s l1: 0.0674222	valid_1&#39;s myFeval: 0.982949
[19200]	training&#39;s l1: 0.0407346	training&#39;s myFeval: 0.560578	valid_1&#39;s l1: 0.0673931	valid_1&#39;s myFeval: 0.982552
[19500]	training&#39;s l1: 0.0406281	training&#39;s myFeval: 0.558834	valid_1&#39;s l1: 0.0673765	valid_1&#39;s myFeval: 0.982401
[19800]	training&#39;s l1: 0.0404994	training&#39;s myFeval: 0.557033	valid_1&#39;s l1: 0.0673397	valid_1&#39;s myFeval: 0.981902
[20100]	training&#39;s l1: 0.0403797	training&#39;s myFeval: 0.55554	valid_1&#39;s l1: 0.067315	valid_1&#39;s myFeval: 0.981455
[20400]	training&#39;s l1: 0.0402823	training&#39;s myFeval: 0.554134	valid_1&#39;s l1: 0.0672875	valid_1&#39;s myFeval: 0.981043
[20700]	training&#39;s l1: 0.0401839	training&#39;s myFeval: 0.55246	valid_1&#39;s l1: 0.0672668	valid_1&#39;s myFeval: 0.980681
[21000]	training&#39;s l1: 0.0400827	training&#39;s myFeval: 0.551036	valid_1&#39;s l1: 0.0672385	valid_1&#39;s myFeval: 0.980261
[21300]	training&#39;s l1: 0.039986	training&#39;s myFeval: 0.549602	valid_1&#39;s l1: 0.0672183	valid_1&#39;s myFeval: 0.980016
[21600]	training&#39;s l1: 0.0398912	training&#39;s myFeval: 0.548262	valid_1&#39;s l1: 0.0671975	valid_1&#39;s myFeval: 0.979677
[21900]	training&#39;s l1: 0.0398202	training&#39;s myFeval: 0.547269	valid_1&#39;s l1: 0.0671815	valid_1&#39;s myFeval: 0.979511
[22200]	training&#39;s l1: 0.0397225	training&#39;s myFeval: 0.545831	valid_1&#39;s l1: 0.0671675	valid_1&#39;s myFeval: 0.979346
[22500]	training&#39;s l1: 0.0396333	training&#39;s myFeval: 0.544454	valid_1&#39;s l1: 0.067145	valid_1&#39;s myFeval: 0.978946
[22800]	training&#39;s l1: 0.0395428	training&#39;s myFeval: 0.543093	valid_1&#39;s l1: 0.0671225	valid_1&#39;s myFeval: 0.978494
[23100]	training&#39;s l1: 0.0394608	training&#39;s myFeval: 0.542001	valid_1&#39;s l1: 0.0671073	valid_1&#39;s myFeval: 0.978181
[23400]	training&#39;s l1: 0.0393786	training&#39;s myFeval: 0.54105	valid_1&#39;s l1: 0.0670981	valid_1&#39;s myFeval: 0.978013
[23700]	training&#39;s l1: 0.0393018	training&#39;s myFeval: 0.540078	valid_1&#39;s l1: 0.0670894	valid_1&#39;s myFeval: 0.977772
[24000]	training&#39;s l1: 0.0392269	training&#39;s myFeval: 0.539244	valid_1&#39;s l1: 0.067083	valid_1&#39;s myFeval: 0.977613
[24300]	training&#39;s l1: 0.0391518	training&#39;s myFeval: 0.538155	valid_1&#39;s l1: 0.0670702	valid_1&#39;s myFeval: 0.977371
[24600]	training&#39;s l1: 0.039067	training&#39;s myFeval: 0.536878	valid_1&#39;s l1: 0.0670529	valid_1&#39;s myFeval: 0.97709
[24900]	training&#39;s l1: 0.0389837	training&#39;s myFeval: 0.535681	valid_1&#39;s l1: 0.0670336	valid_1&#39;s myFeval: 0.976825
[25200]	training&#39;s l1: 0.0389166	training&#39;s myFeval: 0.534666	valid_1&#39;s l1: 0.0670149	valid_1&#39;s myFeval: 0.976487
[25500]	training&#39;s l1: 0.0388628	training&#39;s myFeval: 0.533416	valid_1&#39;s l1: 0.0670033	valid_1&#39;s myFeval: 0.975932
[25800]	training&#39;s l1: 0.0387958	training&#39;s myFeval: 0.531969	valid_1&#39;s l1: 0.066991	valid_1&#39;s myFeval: 0.975526
[26100]	training&#39;s l1: 0.03872	training&#39;s myFeval: 0.530649	valid_1&#39;s l1: 0.0669781	valid_1&#39;s myFeval: 0.975316
[26400]	training&#39;s l1: 0.0386467	training&#39;s myFeval: 0.529549	valid_1&#39;s l1: 0.0669686	valid_1&#39;s myFeval: 0.975158
[26700]	training&#39;s l1: 0.0385686	training&#39;s myFeval: 0.528421	valid_1&#39;s l1: 0.0669494	valid_1&#39;s myFeval: 0.97483
[27000]	training&#39;s l1: 0.0384985	training&#39;s myFeval: 0.527542	valid_1&#39;s l1: 0.0669408	valid_1&#39;s myFeval: 0.97467
[27300]	training&#39;s l1: 0.038441	training&#39;s myFeval: 0.526683	valid_1&#39;s l1: 0.0669313	valid_1&#39;s myFeval: 0.97451
[27600]	training&#39;s l1: 0.0383812	training&#39;s myFeval: 0.525934	valid_1&#39;s l1: 0.0669172	valid_1&#39;s myFeval: 0.974276
[27900]	training&#39;s l1: 0.0383224	training&#39;s myFeval: 0.525241	valid_1&#39;s l1: 0.06691	valid_1&#39;s myFeval: 0.9742
[28200]	training&#39;s l1: 0.0382707	training&#39;s myFeval: 0.524635	valid_1&#39;s l1: 0.0669043	valid_1&#39;s myFeval: 0.974153
[28500]	training&#39;s l1: 0.0382083	training&#39;s myFeval: 0.523823	valid_1&#39;s l1: 0.0668879	valid_1&#39;s myFeval: 0.973869
[28800]	training&#39;s l1: 0.0381479	training&#39;s myFeval: 0.523036	valid_1&#39;s l1: 0.0668763	valid_1&#39;s myFeval: 0.973611
[29100]	training&#39;s l1: 0.0380901	training&#39;s myFeval: 0.522241	valid_1&#39;s l1: 0.0668637	valid_1&#39;s myFeval: 0.973391
[29400]	training&#39;s l1: 0.0380166	training&#39;s myFeval: 0.521348	valid_1&#39;s l1: 0.06685	valid_1&#39;s myFeval: 0.973185
[29700]	training&#39;s l1: 0.0379257	training&#39;s myFeval: 0.520221	valid_1&#39;s l1: 0.0668475	valid_1&#39;s myFeval: 0.973097
[30000]	training&#39;s l1: 0.0378487	training&#39;s myFeval: 0.519218	valid_1&#39;s l1: 0.0668409	valid_1&#39;s myFeval: 0.972913
[30300]	training&#39;s l1: 0.0377831	training&#39;s myFeval: 0.518242	valid_1&#39;s l1: 0.0668314	valid_1&#39;s myFeval: 0.972761
[30600]	training&#39;s l1: 0.0377173	training&#39;s myFeval: 0.517377	valid_1&#39;s l1: 0.0668165	valid_1&#39;s myFeval: 0.972548
[30900]	training&#39;s l1: 0.0376598	training&#39;s myFeval: 0.516572	valid_1&#39;s l1: 0.0668064	valid_1&#39;s myFeval: 0.972434
[31200]	training&#39;s l1: 0.0376032	training&#39;s myFeval: 0.515768	valid_1&#39;s l1: 0.0668046	valid_1&#39;s myFeval: 0.97245
Early stopping, best iteration is:
[30884]	training&#39;s l1: 0.0376625	training&#39;s myFeval: 0.516625	valid_1&#39;s l1: 0.0668064	valid_1&#39;s myFeval: 0.972418
fold n°4
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008617 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9846
[LightGBM] [Info] Number of data points in the train set: 26616, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.424803
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.111289	training&#39;s myFeval: 2.01084	valid_1&#39;s l1: 0.121227	valid_1&#39;s myFeval: 2.60748
[600]	training&#39;s l1: 0.0791077	training&#39;s myFeval: 1.24454	valid_1&#39;s l1: 0.0877173	valid_1&#39;s myFeval: 1.71531
[900]	training&#39;s l1: 0.0718613	training&#39;s myFeval: 1.07197	valid_1&#39;s l1: 0.0804709	valid_1&#39;s myFeval: 1.45723
[1200]	training&#39;s l1: 0.068049	training&#39;s myFeval: 0.996942	valid_1&#39;s l1: 0.0775328	valid_1&#39;s myFeval: 1.35803
[1500]	training&#39;s l1: 0.0652957	training&#39;s myFeval: 0.945245	valid_1&#39;s l1: 0.075823	valid_1&#39;s myFeval: 1.30537
[1800]	training&#39;s l1: 0.0631231	training&#39;s myFeval: 0.909821	valid_1&#39;s l1: 0.0747364	valid_1&#39;s myFeval: 1.27601
[2100]	training&#39;s l1: 0.0612802	training&#39;s myFeval: 0.880365	valid_1&#39;s l1: 0.0738705	valid_1&#39;s myFeval: 1.25407
[2400]	training&#39;s l1: 0.0596767	training&#39;s myFeval: 0.853145	valid_1&#39;s l1: 0.0731351	valid_1&#39;s myFeval: 1.23334
[2700]	training&#39;s l1: 0.0582851	training&#39;s myFeval: 0.830603	valid_1&#39;s l1: 0.0725652	valid_1&#39;s myFeval: 1.21909
[3000]	training&#39;s l1: 0.0570696	training&#39;s myFeval: 0.812353	valid_1&#39;s l1: 0.0721139	valid_1&#39;s myFeval: 1.20855
[3300]	training&#39;s l1: 0.0559773	training&#39;s myFeval: 0.795066	valid_1&#39;s l1: 0.0717251	valid_1&#39;s myFeval: 1.19886
[3600]	training&#39;s l1: 0.054996	training&#39;s myFeval: 0.779855	valid_1&#39;s l1: 0.0714258	valid_1&#39;s myFeval: 1.19105
[3900]	training&#39;s l1: 0.0540717	training&#39;s myFeval: 0.765655	valid_1&#39;s l1: 0.0711111	valid_1&#39;s myFeval: 1.18383
[4200]	training&#39;s l1: 0.0532368	training&#39;s myFeval: 0.752956	valid_1&#39;s l1: 0.0708155	valid_1&#39;s myFeval: 1.17615
[4500]	training&#39;s l1: 0.0524819	training&#39;s myFeval: 0.740982	valid_1&#39;s l1: 0.0705806	valid_1&#39;s myFeval: 1.17004
[4800]	training&#39;s l1: 0.0517882	training&#39;s myFeval: 0.730779	valid_1&#39;s l1: 0.0703484	valid_1&#39;s myFeval: 1.1644
[5100]	training&#39;s l1: 0.0511542	training&#39;s myFeval: 0.720701	valid_1&#39;s l1: 0.0701581	valid_1&#39;s myFeval: 1.15936
[5400]	training&#39;s l1: 0.0505464	training&#39;s myFeval: 0.71117	valid_1&#39;s l1: 0.0699868	valid_1&#39;s myFeval: 1.15459
[5700]	training&#39;s l1: 0.0500148	training&#39;s myFeval: 0.702857	valid_1&#39;s l1: 0.0698444	valid_1&#39;s myFeval: 1.15038
[6000]	training&#39;s l1: 0.0495135	training&#39;s myFeval: 0.695534	valid_1&#39;s l1: 0.0696983	valid_1&#39;s myFeval: 1.1463
[6300]	training&#39;s l1: 0.0490165	training&#39;s myFeval: 0.688444	valid_1&#39;s l1: 0.0695589	valid_1&#39;s myFeval: 1.14326
[6600]	training&#39;s l1: 0.0485792	training&#39;s myFeval: 0.682019	valid_1&#39;s l1: 0.0694183	valid_1&#39;s myFeval: 1.14025
[6900]	training&#39;s l1: 0.0481679	training&#39;s myFeval: 0.676534	valid_1&#39;s l1: 0.0692905	valid_1&#39;s myFeval: 1.1379
[7200]	training&#39;s l1: 0.0477796	training&#39;s myFeval: 0.67046	valid_1&#39;s l1: 0.0691814	valid_1&#39;s myFeval: 1.13518
[7500]	training&#39;s l1: 0.0474254	training&#39;s myFeval: 0.665386	valid_1&#39;s l1: 0.0690843	valid_1&#39;s myFeval: 1.13353
[7800]	training&#39;s l1: 0.0470492	training&#39;s myFeval: 0.65991	valid_1&#39;s l1: 0.0689901	valid_1&#39;s myFeval: 1.13178
[8100]	training&#39;s l1: 0.0467066	training&#39;s myFeval: 0.654833	valid_1&#39;s l1: 0.0688849	valid_1&#39;s myFeval: 1.12963
[8400]	training&#39;s l1: 0.0463913	training&#39;s myFeval: 0.650586	valid_1&#39;s l1: 0.068802	valid_1&#39;s myFeval: 1.12786
[8700]	training&#39;s l1: 0.0460947	training&#39;s myFeval: 0.646286	valid_1&#39;s l1: 0.0687278	valid_1&#39;s myFeval: 1.12621
[9000]	training&#39;s l1: 0.0458007	training&#39;s myFeval: 0.642431	valid_1&#39;s l1: 0.0686488	valid_1&#39;s myFeval: 1.12493
[9300]	training&#39;s l1: 0.0455128	training&#39;s myFeval: 0.638441	valid_1&#39;s l1: 0.068591	valid_1&#39;s myFeval: 1.12389
[9600]	training&#39;s l1: 0.0452544	training&#39;s myFeval: 0.634818	valid_1&#39;s l1: 0.0685252	valid_1&#39;s myFeval: 1.12251
[9900]	training&#39;s l1: 0.0450271	training&#39;s myFeval: 0.631605	valid_1&#39;s l1: 0.0684509	valid_1&#39;s myFeval: 1.12106
[10200]	training&#39;s l1: 0.0448092	training&#39;s myFeval: 0.628856	valid_1&#39;s l1: 0.068404	valid_1&#39;s myFeval: 1.1202
[10500]	training&#39;s l1: 0.0446001	training&#39;s myFeval: 0.6259	valid_1&#39;s l1: 0.0683632	valid_1&#39;s myFeval: 1.11892
[10800]	training&#39;s l1: 0.0443991	training&#39;s myFeval: 0.623199	valid_1&#39;s l1: 0.0683155	valid_1&#39;s myFeval: 1.11793
[11100]	training&#39;s l1: 0.0441908	training&#39;s myFeval: 0.619967	valid_1&#39;s l1: 0.0682685	valid_1&#39;s myFeval: 1.11664
[11400]	training&#39;s l1: 0.0440013	training&#39;s myFeval: 0.617173	valid_1&#39;s l1: 0.0682289	valid_1&#39;s myFeval: 1.11607
[11700]	training&#39;s l1: 0.0438284	training&#39;s myFeval: 0.614531	valid_1&#39;s l1: 0.0681925	valid_1&#39;s myFeval: 1.11521
[12000]	training&#39;s l1: 0.0436229	training&#39;s myFeval: 0.611565	valid_1&#39;s l1: 0.0681358	valid_1&#39;s myFeval: 1.11389
[12300]	training&#39;s l1: 0.0434413	training&#39;s myFeval: 0.608677	valid_1&#39;s l1: 0.068084	valid_1&#39;s myFeval: 1.11253
[12600]	training&#39;s l1: 0.0432429	training&#39;s myFeval: 0.605917	valid_1&#39;s l1: 0.0680363	valid_1&#39;s myFeval: 1.11143
[12900]	training&#39;s l1: 0.0430497	training&#39;s myFeval: 0.603396	valid_1&#39;s l1: 0.0679813	valid_1&#39;s myFeval: 1.11034
[13200]	training&#39;s l1: 0.0429246	training&#39;s myFeval: 0.601191	valid_1&#39;s l1: 0.0679693	valid_1&#39;s myFeval: 1.10961
[13500]	training&#39;s l1: 0.0428048	training&#39;s myFeval: 0.599076	valid_1&#39;s l1: 0.0679553	valid_1&#39;s myFeval: 1.10899
[13800]	training&#39;s l1: 0.0426621	training&#39;s myFeval: 0.596799	valid_1&#39;s l1: 0.0679295	valid_1&#39;s myFeval: 1.1082
[14100]	training&#39;s l1: 0.042495	training&#39;s myFeval: 0.594531	valid_1&#39;s l1: 0.0678922	valid_1&#39;s myFeval: 1.10761
[14400]	training&#39;s l1: 0.0423294	training&#39;s myFeval: 0.592152	valid_1&#39;s l1: 0.0678428	valid_1&#39;s myFeval: 1.10658
[14700]	training&#39;s l1: 0.0421442	training&#39;s myFeval: 0.589603	valid_1&#39;s l1: 0.0678184	valid_1&#39;s myFeval: 1.10596
[15000]	training&#39;s l1: 0.0419891	training&#39;s myFeval: 0.58737	valid_1&#39;s l1: 0.0677815	valid_1&#39;s myFeval: 1.10534
[15300]	training&#39;s l1: 0.0418465	training&#39;s myFeval: 0.585174	valid_1&#39;s l1: 0.0677548	valid_1&#39;s myFeval: 1.10438
[15600]	training&#39;s l1: 0.0417044	training&#39;s myFeval: 0.583148	valid_1&#39;s l1: 0.0677302	valid_1&#39;s myFeval: 1.10365
[15900]	training&#39;s l1: 0.0415693	training&#39;s myFeval: 0.581218	valid_1&#39;s l1: 0.067709	valid_1&#39;s myFeval: 1.10273
[16200]	training&#39;s l1: 0.0414146	training&#39;s myFeval: 0.579432	valid_1&#39;s l1: 0.0676934	valid_1&#39;s myFeval: 1.10211
[16500]	training&#39;s l1: 0.0413053	training&#39;s myFeval: 0.577461	valid_1&#39;s l1: 0.0676574	valid_1&#39;s myFeval: 1.10013
[16800]	training&#39;s l1: 0.0411865	training&#39;s myFeval: 0.575639	valid_1&#39;s l1: 0.0676428	valid_1&#39;s myFeval: 1.0996
[17100]	training&#39;s l1: 0.0410615	training&#39;s myFeval: 0.573806	valid_1&#39;s l1: 0.0676149	valid_1&#39;s myFeval: 1.09925
[17400]	training&#39;s l1: 0.0409349	training&#39;s myFeval: 0.572023	valid_1&#39;s l1: 0.0675834	valid_1&#39;s myFeval: 1.09808
[17700]	training&#39;s l1: 0.040821	training&#39;s myFeval: 0.570305	valid_1&#39;s l1: 0.0675597	valid_1&#39;s myFeval: 1.09713
[18000]	training&#39;s l1: 0.0407127	training&#39;s myFeval: 0.568729	valid_1&#39;s l1: 0.0675403	valid_1&#39;s myFeval: 1.096
[18300]	training&#39;s l1: 0.0405905	training&#39;s myFeval: 0.567083	valid_1&#39;s l1: 0.067516	valid_1&#39;s myFeval: 1.09545
[18600]	training&#39;s l1: 0.0404749	training&#39;s myFeval: 0.565472	valid_1&#39;s l1: 0.0674929	valid_1&#39;s myFeval: 1.09473
[18900]	training&#39;s l1: 0.0403697	training&#39;s myFeval: 0.56393	valid_1&#39;s l1: 0.0674791	valid_1&#39;s myFeval: 1.09427
[19200]	training&#39;s l1: 0.0402681	training&#39;s myFeval: 0.562577	valid_1&#39;s l1: 0.0674733	valid_1&#39;s myFeval: 1.09378
[19500]	training&#39;s l1: 0.0401725	training&#39;s myFeval: 0.561431	valid_1&#39;s l1: 0.0674614	valid_1&#39;s myFeval: 1.09359
[19800]	training&#39;s l1: 0.0400709	training&#39;s myFeval: 0.560118	valid_1&#39;s l1: 0.0674432	valid_1&#39;s myFeval: 1.09308
[20100]	training&#39;s l1: 0.0399867	training&#39;s myFeval: 0.558846	valid_1&#39;s l1: 0.0674358	valid_1&#39;s myFeval: 1.0928
[20400]	training&#39;s l1: 0.0398758	training&#39;s myFeval: 0.55765	valid_1&#39;s l1: 0.0674276	valid_1&#39;s myFeval: 1.09259
[20700]	training&#39;s l1: 0.0397769	training&#39;s myFeval: 0.556233	valid_1&#39;s l1: 0.0674135	valid_1&#39;s myFeval: 1.09221
[21000]	training&#39;s l1: 0.0396823	training&#39;s myFeval: 0.554691	valid_1&#39;s l1: 0.0674021	valid_1&#39;s myFeval: 1.09169
[21300]	training&#39;s l1: 0.0395864	training&#39;s myFeval: 0.553256	valid_1&#39;s l1: 0.067384	valid_1&#39;s myFeval: 1.09119
[21600]	training&#39;s l1: 0.0394987	training&#39;s myFeval: 0.551923	valid_1&#39;s l1: 0.0673737	valid_1&#39;s myFeval: 1.09081
[21900]	training&#39;s l1: 0.0394305	training&#39;s myFeval: 0.550876	valid_1&#39;s l1: 0.0673694	valid_1&#39;s myFeval: 1.09059
[22200]	training&#39;s l1: 0.039359	training&#39;s myFeval: 0.549957	valid_1&#39;s l1: 0.0673606	valid_1&#39;s myFeval: 1.09043
[22500]	training&#39;s l1: 0.0392911	training&#39;s myFeval: 0.548949	valid_1&#39;s l1: 0.0673509	valid_1&#39;s myFeval: 1.08993
[22800]	training&#39;s l1: 0.039225	training&#39;s myFeval: 0.54762	valid_1&#39;s l1: 0.067343	valid_1&#39;s myFeval: 1.0895
[23100]	training&#39;s l1: 0.0391635	training&#39;s myFeval: 0.546426	valid_1&#39;s l1: 0.067332	valid_1&#39;s myFeval: 1.08892
[23400]	training&#39;s l1: 0.0391039	training&#39;s myFeval: 0.545445	valid_1&#39;s l1: 0.0673232	valid_1&#39;s myFeval: 1.08865
[23700]	training&#39;s l1: 0.0390441	training&#39;s myFeval: 0.54444	valid_1&#39;s l1: 0.0673187	valid_1&#39;s myFeval: 1.08846
[24000]	training&#39;s l1: 0.0389848	training&#39;s myFeval: 0.543427	valid_1&#39;s l1: 0.067304	valid_1&#39;s myFeval: 1.08808
[24300]	training&#39;s l1: 0.0389193	training&#39;s myFeval: 0.542341	valid_1&#39;s l1: 0.0672932	valid_1&#39;s myFeval: 1.08788
[24600]	training&#39;s l1: 0.038856	training&#39;s myFeval: 0.541317	valid_1&#39;s l1: 0.0672831	valid_1&#39;s myFeval: 1.08787
[24900]	training&#39;s l1: 0.0387828	training&#39;s myFeval: 0.540168	valid_1&#39;s l1: 0.0672667	valid_1&#39;s myFeval: 1.08748
[25200]	training&#39;s l1: 0.0387052	training&#39;s myFeval: 0.539112	valid_1&#39;s l1: 0.0672551	valid_1&#39;s myFeval: 1.08728
[25500]	training&#39;s l1: 0.0386255	training&#39;s myFeval: 0.538112	valid_1&#39;s l1: 0.067245	valid_1&#39;s myFeval: 1.0869
[25800]	training&#39;s l1: 0.0385499	training&#39;s myFeval: 0.536968	valid_1&#39;s l1: 0.0672309	valid_1&#39;s myFeval: 1.08637
[26100]	training&#39;s l1: 0.0384773	training&#39;s myFeval: 0.535824	valid_1&#39;s l1: 0.0672216	valid_1&#39;s myFeval: 1.08601
[26400]	training&#39;s l1: 0.0384078	training&#39;s myFeval: 0.534825	valid_1&#39;s l1: 0.0672065	valid_1&#39;s myFeval: 1.08564
[26700]	training&#39;s l1: 0.0383415	training&#39;s myFeval: 0.533869	valid_1&#39;s l1: 0.0671931	valid_1&#39;s myFeval: 1.08534
[27000]	training&#39;s l1: 0.0382824	training&#39;s myFeval: 0.533076	valid_1&#39;s l1: 0.0671786	valid_1&#39;s myFeval: 1.08509
[27300]	training&#39;s l1: 0.038204	training&#39;s myFeval: 0.532088	valid_1&#39;s l1: 0.0671633	valid_1&#39;s myFeval: 1.08476
[27600]	training&#39;s l1: 0.0381018	training&#39;s myFeval: 0.530752	valid_1&#39;s l1: 0.0671429	valid_1&#39;s myFeval: 1.0843
[27900]	training&#39;s l1: 0.0380119	training&#39;s myFeval: 0.5296	valid_1&#39;s l1: 0.0671271	valid_1&#39;s myFeval: 1.08403
[28200]	training&#39;s l1: 0.0379302	training&#39;s myFeval: 0.528541	valid_1&#39;s l1: 0.0671078	valid_1&#39;s myFeval: 1.0837
[28500]	training&#39;s l1: 0.0378573	training&#39;s myFeval: 0.527529	valid_1&#39;s l1: 0.067095	valid_1&#39;s myFeval: 1.08337
[28800]	training&#39;s l1: 0.0377981	training&#39;s myFeval: 0.526666	valid_1&#39;s l1: 0.0670889	valid_1&#39;s myFeval: 1.08314
[29100]	training&#39;s l1: 0.03774	training&#39;s myFeval: 0.525732	valid_1&#39;s l1: 0.067084	valid_1&#39;s myFeval: 1.08296
[29400]	training&#39;s l1: 0.0376811	training&#39;s myFeval: 0.5249	valid_1&#39;s l1: 0.0670803	valid_1&#39;s myFeval: 1.08295
[29700]	training&#39;s l1: 0.0376224	training&#39;s myFeval: 0.524032	valid_1&#39;s l1: 0.0670678	valid_1&#39;s myFeval: 1.08269
[30000]	training&#39;s l1: 0.0375545	training&#39;s myFeval: 0.522808	valid_1&#39;s l1: 0.0670464	valid_1&#39;s myFeval: 1.0821
[30300]	training&#39;s l1: 0.0374929	training&#39;s myFeval: 0.521839	valid_1&#39;s l1: 0.0670306	valid_1&#39;s myFeval: 1.08144
[30600]	training&#39;s l1: 0.037432	training&#39;s myFeval: 0.520952	valid_1&#39;s l1: 0.067024	valid_1&#39;s myFeval: 1.08141
[30900]	training&#39;s l1: 0.0373816	training&#39;s myFeval: 0.520171	valid_1&#39;s l1: 0.0670147	valid_1&#39;s myFeval: 1.08107
[31200]	training&#39;s l1: 0.0373235	training&#39;s myFeval: 0.519311	valid_1&#39;s l1: 0.0670068	valid_1&#39;s myFeval: 1.08098
[31500]	training&#39;s l1: 0.0372664	training&#39;s myFeval: 0.518457	valid_1&#39;s l1: 0.0669964	valid_1&#39;s myFeval: 1.0808
[31800]	training&#39;s l1: 0.0372075	training&#39;s myFeval: 0.51756	valid_1&#39;s l1: 0.0669942	valid_1&#39;s myFeval: 1.08083
[32100]	training&#39;s l1: 0.0371477	training&#39;s myFeval: 0.516663	valid_1&#39;s l1: 0.0669878	valid_1&#39;s myFeval: 1.08062
[32400]	training&#39;s l1: 0.0370909	training&#39;s myFeval: 0.515869	valid_1&#39;s l1: 0.0669781	valid_1&#39;s myFeval: 1.08045
[32700]	training&#39;s l1: 0.03704	training&#39;s myFeval: 0.515131	valid_1&#39;s l1: 0.0669709	valid_1&#39;s myFeval: 1.08012
[33000]	training&#39;s l1: 0.0369876	training&#39;s myFeval: 0.514403	valid_1&#39;s l1: 0.0669572	valid_1&#39;s myFeval: 1.07991
[33300]	training&#39;s l1: 0.0369342	training&#39;s myFeval: 0.513621	valid_1&#39;s l1: 0.0669467	valid_1&#39;s myFeval: 1.07964
[33600]	training&#39;s l1: 0.0368835	training&#39;s myFeval: 0.512941	valid_1&#39;s l1: 0.0669376	valid_1&#39;s myFeval: 1.07945
[33900]	training&#39;s l1: 0.0368342	training&#39;s myFeval: 0.512297	valid_1&#39;s l1: 0.0669264	valid_1&#39;s myFeval: 1.07927
[34200]	training&#39;s l1: 0.036776	training&#39;s myFeval: 0.511546	valid_1&#39;s l1: 0.0669155	valid_1&#39;s myFeval: 1.07904
[34500]	training&#39;s l1: 0.0367248	training&#39;s myFeval: 0.510734	valid_1&#39;s l1: 0.0669065	valid_1&#39;s myFeval: 1.07874
[34800]	training&#39;s l1: 0.0366771	training&#39;s myFeval: 0.510034	valid_1&#39;s l1: 0.0669037	valid_1&#39;s myFeval: 1.07847
[35100]	training&#39;s l1: 0.036628	training&#39;s myFeval: 0.509277	valid_1&#39;s l1: 0.0669017	valid_1&#39;s myFeval: 1.07838
[35400]	training&#39;s l1: 0.0365772	training&#39;s myFeval: 0.508553	valid_1&#39;s l1: 0.0668946	valid_1&#39;s myFeval: 1.07821
[35700]	training&#39;s l1: 0.0365264	training&#39;s myFeval: 0.507851	valid_1&#39;s l1: 0.0668891	valid_1&#39;s myFeval: 1.07811
[36000]	training&#39;s l1: 0.0364783	training&#39;s myFeval: 0.507145	valid_1&#39;s l1: 0.0668752	valid_1&#39;s myFeval: 1.0778
[36300]	training&#39;s l1: 0.0364096	training&#39;s myFeval: 0.50625	valid_1&#39;s l1: 0.0668801	valid_1&#39;s myFeval: 1.07793
[36600]	training&#39;s l1: 0.0363395	training&#39;s myFeval: 0.50536	valid_1&#39;s l1: 0.0668822	valid_1&#39;s myFeval: 1.07804
Early stopping, best iteration is:
[36084]	training&#39;s l1: 0.0364625	training&#39;s myFeval: 0.506942	valid_1&#39;s l1: 0.0668714	valid_1&#39;s myFeval: 1.07774
fold n°5
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013934 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9893
[LightGBM] [Info] Number of data points in the train set: 26617, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.424803
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.11225	training&#39;s myFeval: 2.07701	valid_1&#39;s l1: 0.111989	valid_1&#39;s myFeval: 1.97776
[600]	training&#39;s l1: 0.0792612	training&#39;s myFeval: 1.27344	valid_1&#39;s l1: 0.0820713	valid_1&#39;s myFeval: 1.24811
[900]	training&#39;s l1: 0.0720212	training&#39;s myFeval: 1.08922	valid_1&#39;s l1: 0.0765217	valid_1&#39;s myFeval: 1.10551
[1200]	training&#39;s l1: 0.0682449	training&#39;s myFeval: 1.01006	valid_1&#39;s l1: 0.0740471	valid_1&#39;s myFeval: 1.04359
[1500]	training&#39;s l1: 0.0654663	training&#39;s myFeval: 0.95803	valid_1&#39;s l1: 0.0724847	valid_1&#39;s myFeval: 1.00933
[1800]	training&#39;s l1: 0.0633392	training&#39;s myFeval: 0.920399	valid_1&#39;s l1: 0.071514	valid_1&#39;s myFeval: 0.994602
[2100]	training&#39;s l1: 0.061503	training&#39;s myFeval: 0.88794	valid_1&#39;s l1: 0.0707184	valid_1&#39;s myFeval: 0.983025
[2400]	training&#39;s l1: 0.0598838	training&#39;s myFeval: 0.860776	valid_1&#39;s l1: 0.0701157	valid_1&#39;s myFeval: 0.975201
[2700]	training&#39;s l1: 0.0585113	training&#39;s myFeval: 0.836642	valid_1&#39;s l1: 0.0696044	valid_1&#39;s myFeval: 0.967231
[3000]	training&#39;s l1: 0.0572695	training&#39;s myFeval: 0.81682	valid_1&#39;s l1: 0.0691561	valid_1&#39;s myFeval: 0.96078
[3300]	training&#39;s l1: 0.0561615	training&#39;s myFeval: 0.798407	valid_1&#39;s l1: 0.0687774	valid_1&#39;s myFeval: 0.955373
[3600]	training&#39;s l1: 0.0551556	training&#39;s myFeval: 0.782127	valid_1&#39;s l1: 0.0684828	valid_1&#39;s myFeval: 0.951546
[3900]	training&#39;s l1: 0.0542554	training&#39;s myFeval: 0.7682	valid_1&#39;s l1: 0.0682032	valid_1&#39;s myFeval: 0.947984
[4200]	training&#39;s l1: 0.0534063	training&#39;s myFeval: 0.75506	valid_1&#39;s l1: 0.0679419	valid_1&#39;s myFeval: 0.944702
[4500]	training&#39;s l1: 0.0526226	training&#39;s myFeval: 0.742867	valid_1&#39;s l1: 0.0677134	valid_1&#39;s myFeval: 0.941619
[4800]	training&#39;s l1: 0.0519457	training&#39;s myFeval: 0.732254	valid_1&#39;s l1: 0.0675284	valid_1&#39;s myFeval: 0.939151
[5100]	training&#39;s l1: 0.0513163	training&#39;s myFeval: 0.721931	valid_1&#39;s l1: 0.0673712	valid_1&#39;s myFeval: 0.936907
[5400]	training&#39;s l1: 0.0507288	training&#39;s myFeval: 0.712872	valid_1&#39;s l1: 0.067208	valid_1&#39;s myFeval: 0.934421
[5700]	training&#39;s l1: 0.0501749	training&#39;s myFeval: 0.704233	valid_1&#39;s l1: 0.0670801	valid_1&#39;s myFeval: 0.93255
[6000]	training&#39;s l1: 0.0496554	training&#39;s myFeval: 0.696317	valid_1&#39;s l1: 0.0669576	valid_1&#39;s myFeval: 0.931014
[6300]	training&#39;s l1: 0.0491794	training&#39;s myFeval: 0.689089	valid_1&#39;s l1: 0.0668453	valid_1&#39;s myFeval: 0.929385
[6600]	training&#39;s l1: 0.0487033	training&#39;s myFeval: 0.681701	valid_1&#39;s l1: 0.0667385	valid_1&#39;s myFeval: 0.928004
[6900]	training&#39;s l1: 0.0482599	training&#39;s myFeval: 0.674824	valid_1&#39;s l1: 0.0666294	valid_1&#39;s myFeval: 0.926681
[7200]	training&#39;s l1: 0.0478524	training&#39;s myFeval: 0.669104	valid_1&#39;s l1: 0.0665432	valid_1&#39;s myFeval: 0.925617
[7500]	training&#39;s l1: 0.0474668	training&#39;s myFeval: 0.663349	valid_1&#39;s l1: 0.0664503	valid_1&#39;s myFeval: 0.924344
[7800]	training&#39;s l1: 0.0471318	training&#39;s myFeval: 0.657943	valid_1&#39;s l1: 0.0663674	valid_1&#39;s myFeval: 0.922394
[8100]	training&#39;s l1: 0.0468425	training&#39;s myFeval: 0.654061	valid_1&#39;s l1: 0.0663145	valid_1&#39;s myFeval: 0.921465
[8400]	training&#39;s l1: 0.0464996	training&#39;s myFeval: 0.648646	valid_1&#39;s l1: 0.0662336	valid_1&#39;s myFeval: 0.920388
[8700]	training&#39;s l1: 0.046192	training&#39;s myFeval: 0.644064	valid_1&#39;s l1: 0.0661721	valid_1&#39;s myFeval: 0.919825
[9000]	training&#39;s l1: 0.0458877	training&#39;s myFeval: 0.639455	valid_1&#39;s l1: 0.066099	valid_1&#39;s myFeval: 0.918938
[9300]	training&#39;s l1: 0.0456082	training&#39;s myFeval: 0.635163	valid_1&#39;s l1: 0.0660361	valid_1&#39;s myFeval: 0.918313
[9600]	training&#39;s l1: 0.0453368	training&#39;s myFeval: 0.631096	valid_1&#39;s l1: 0.065987	valid_1&#39;s myFeval: 0.917616
[9900]	training&#39;s l1: 0.0450916	training&#39;s myFeval: 0.627047	valid_1&#39;s l1: 0.0659445	valid_1&#39;s myFeval: 0.917049
[10200]	training&#39;s l1: 0.044873	training&#39;s myFeval: 0.623975	valid_1&#39;s l1: 0.0658914	valid_1&#39;s myFeval: 0.916211
[10500]	training&#39;s l1: 0.0446619	training&#39;s myFeval: 0.6209	valid_1&#39;s l1: 0.0658541	valid_1&#39;s myFeval: 0.915492
[10800]	training&#39;s l1: 0.0444826	training&#39;s myFeval: 0.61831	valid_1&#39;s l1: 0.0658207	valid_1&#39;s myFeval: 0.914818
[11100]	training&#39;s l1: 0.0443117	training&#39;s myFeval: 0.615991	valid_1&#39;s l1: 0.0658122	valid_1&#39;s myFeval: 0.914591
[11400]	training&#39;s l1: 0.0441181	training&#39;s myFeval: 0.613197	valid_1&#39;s l1: 0.0657774	valid_1&#39;s myFeval: 0.914142
[11700]	training&#39;s l1: 0.0438964	training&#39;s myFeval: 0.610108	valid_1&#39;s l1: 0.0657239	valid_1&#39;s myFeval: 0.913306
[12000]	training&#39;s l1: 0.0436774	training&#39;s myFeval: 0.606939	valid_1&#39;s l1: 0.0656773	valid_1&#39;s myFeval: 0.912635
[12300]	training&#39;s l1: 0.0434845	training&#39;s myFeval: 0.603906	valid_1&#39;s l1: 0.0656455	valid_1&#39;s myFeval: 0.912142
[12600]	training&#39;s l1: 0.0432845	training&#39;s myFeval: 0.600923	valid_1&#39;s l1: 0.0656172	valid_1&#39;s myFeval: 0.91182
[12900]	training&#39;s l1: 0.0430869	training&#39;s myFeval: 0.598333	valid_1&#39;s l1: 0.0655906	valid_1&#39;s myFeval: 0.91148
[13200]	training&#39;s l1: 0.0428896	training&#39;s myFeval: 0.595594	valid_1&#39;s l1: 0.0655593	valid_1&#39;s myFeval: 0.911064
[13500]	training&#39;s l1: 0.0427238	training&#39;s myFeval: 0.593038	valid_1&#39;s l1: 0.0655257	valid_1&#39;s myFeval: 0.910615
[13800]	training&#39;s l1: 0.0425621	training&#39;s myFeval: 0.591015	valid_1&#39;s l1: 0.0655166	valid_1&#39;s myFeval: 0.910407
[14100]	training&#39;s l1: 0.0424094	training&#39;s myFeval: 0.588929	valid_1&#39;s l1: 0.0654958	valid_1&#39;s myFeval: 0.910025
[14400]	training&#39;s l1: 0.0422644	training&#39;s myFeval: 0.58672	valid_1&#39;s l1: 0.0654608	valid_1&#39;s myFeval: 0.909476
[14700]	training&#39;s l1: 0.0421434	training&#39;s myFeval: 0.584845	valid_1&#39;s l1: 0.0654461	valid_1&#39;s myFeval: 0.909414
[15000]	training&#39;s l1: 0.0420113	training&#39;s myFeval: 0.582966	valid_1&#39;s l1: 0.0654221	valid_1&#39;s myFeval: 0.909124
[15300]	training&#39;s l1: 0.0418781	training&#39;s myFeval: 0.581134	valid_1&#39;s l1: 0.0654062	valid_1&#39;s myFeval: 0.9089
[15600]	training&#39;s l1: 0.0417556	training&#39;s myFeval: 0.579225	valid_1&#39;s l1: 0.0653869	valid_1&#39;s myFeval: 0.908627
[15900]	training&#39;s l1: 0.0416156	training&#39;s myFeval: 0.577154	valid_1&#39;s l1: 0.0653558	valid_1&#39;s myFeval: 0.908132
[16200]	training&#39;s l1: 0.0414811	training&#39;s myFeval: 0.575066	valid_1&#39;s l1: 0.0653272	valid_1&#39;s myFeval: 0.907775
[16500]	training&#39;s l1: 0.0413505	training&#39;s myFeval: 0.573339	valid_1&#39;s l1: 0.0653025	valid_1&#39;s myFeval: 0.907407
[16800]	training&#39;s l1: 0.041218	training&#39;s myFeval: 0.571431	valid_1&#39;s l1: 0.0652738	valid_1&#39;s myFeval: 0.906998
[17100]	training&#39;s l1: 0.0410996	training&#39;s myFeval: 0.569664	valid_1&#39;s l1: 0.0652535	valid_1&#39;s myFeval: 0.906734
[17400]	training&#39;s l1: 0.0409774	training&#39;s myFeval: 0.56798	valid_1&#39;s l1: 0.0652283	valid_1&#39;s myFeval: 0.906374
[17700]	training&#39;s l1: 0.0408555	training&#39;s myFeval: 0.566431	valid_1&#39;s l1: 0.0652011	valid_1&#39;s myFeval: 0.906063
[18000]	training&#39;s l1: 0.0407418	training&#39;s myFeval: 0.56502	valid_1&#39;s l1: 0.0651803	valid_1&#39;s myFeval: 0.905778
[18300]	training&#39;s l1: 0.0406285	training&#39;s myFeval: 0.563466	valid_1&#39;s l1: 0.065161	valid_1&#39;s myFeval: 0.905604
[18600]	training&#39;s l1: 0.0405112	training&#39;s myFeval: 0.561795	valid_1&#39;s l1: 0.0651416	valid_1&#39;s myFeval: 0.905228
[18900]	training&#39;s l1: 0.0404068	training&#39;s myFeval: 0.560254	valid_1&#39;s l1: 0.0651244	valid_1&#39;s myFeval: 0.904923
[19200]	training&#39;s l1: 0.0403235	training&#39;s myFeval: 0.558868	valid_1&#39;s l1: 0.0651014	valid_1&#39;s myFeval: 0.904612
[19500]	training&#39;s l1: 0.0402059	training&#39;s myFeval: 0.5573	valid_1&#39;s l1: 0.0650727	valid_1&#39;s myFeval: 0.904369
[19800]	training&#39;s l1: 0.0400834	training&#39;s myFeval: 0.555997	valid_1&#39;s l1: 0.0650475	valid_1&#39;s myFeval: 0.904125
[20100]	training&#39;s l1: 0.0399755	training&#39;s myFeval: 0.554735	valid_1&#39;s l1: 0.0650346	valid_1&#39;s myFeval: 0.904017
[20400]	training&#39;s l1: 0.039875	training&#39;s myFeval: 0.553453	valid_1&#39;s l1: 0.0650164	valid_1&#39;s myFeval: 0.903833
[20700]	training&#39;s l1: 0.0397594	training&#39;s myFeval: 0.551968	valid_1&#39;s l1: 0.0650226	valid_1&#39;s myFeval: 0.90393
[21000]	training&#39;s l1: 0.0396463	training&#39;s myFeval: 0.550552	valid_1&#39;s l1: 0.0650154	valid_1&#39;s myFeval: 0.903851
Early stopping, best iteration is:
[20457]	training&#39;s l1: 0.0398594	training&#39;s myFeval: 0.553223	valid_1&#39;s l1: 0.0650127	valid_1&#39;s myFeval: 0.903746
fold n°6
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003028 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 9917
[LightGBM] [Info] Number of data points in the train set: 26617, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.425687
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.111823	training&#39;s myFeval: 2.06907	valid_1&#39;s l1: 0.114554	valid_1&#39;s myFeval: 2.00377
[600]	training&#39;s l1: 0.0791136	training&#39;s myFeval: 1.27268	valid_1&#39;s l1: 0.0849735	valid_1&#39;s myFeval: 1.28799
[900]	training&#39;s l1: 0.0718193	training&#39;s myFeval: 1.08474	valid_1&#39;s l1: 0.0792399	valid_1&#39;s myFeval: 1.15573
[1200]	training&#39;s l1: 0.0680403	training&#39;s myFeval: 1.0073	valid_1&#39;s l1: 0.0767567	valid_1&#39;s myFeval: 1.10255
[1500]	training&#39;s l1: 0.0652368	training&#39;s myFeval: 0.954756	valid_1&#39;s l1: 0.0751774	valid_1&#39;s myFeval: 1.06836
[1800]	training&#39;s l1: 0.0630264	training&#39;s myFeval: 0.91666	valid_1&#39;s l1: 0.0740732	valid_1&#39;s myFeval: 1.04543
[2100]	training&#39;s l1: 0.0611333	training&#39;s myFeval: 0.884793	valid_1&#39;s l1: 0.0732806	valid_1&#39;s myFeval: 1.03021
[2400]	training&#39;s l1: 0.0594936	training&#39;s myFeval: 0.856283	valid_1&#39;s l1: 0.0725932	valid_1&#39;s myFeval: 1.01595
[2700]	training&#39;s l1: 0.0580905	training&#39;s myFeval: 0.83289	valid_1&#39;s l1: 0.0720671	valid_1&#39;s myFeval: 1.00681
[3000]	training&#39;s l1: 0.0568667	training&#39;s myFeval: 0.813077	valid_1&#39;s l1: 0.0716546	valid_1&#39;s myFeval: 1.00061
[3300]	training&#39;s l1: 0.0557613	training&#39;s myFeval: 0.796447	valid_1&#39;s l1: 0.0712484	valid_1&#39;s myFeval: 0.994406
[3600]	training&#39;s l1: 0.0547783	training&#39;s myFeval: 0.781043	valid_1&#39;s l1: 0.0709161	valid_1&#39;s myFeval: 0.988745
[3900]	training&#39;s l1: 0.0538749	training&#39;s myFeval: 0.766494	valid_1&#39;s l1: 0.0706475	valid_1&#39;s myFeval: 0.984409
[4200]	training&#39;s l1: 0.0530743	training&#39;s myFeval: 0.754036	valid_1&#39;s l1: 0.0704246	valid_1&#39;s myFeval: 0.980753
[4500]	training&#39;s l1: 0.0523323	training&#39;s myFeval: 0.742464	valid_1&#39;s l1: 0.0701981	valid_1&#39;s myFeval: 0.97748
[4800]	training&#39;s l1: 0.0516584	training&#39;s myFeval: 0.731867	valid_1&#39;s l1: 0.0700135	valid_1&#39;s myFeval: 0.974421
[5100]	training&#39;s l1: 0.0510205	training&#39;s myFeval: 0.721474	valid_1&#39;s l1: 0.06982	valid_1&#39;s myFeval: 0.970999
[5400]	training&#39;s l1: 0.0504216	training&#39;s myFeval: 0.711964	valid_1&#39;s l1: 0.0696896	valid_1&#39;s myFeval: 0.968944
[5700]	training&#39;s l1: 0.0498692	training&#39;s myFeval: 0.703327	valid_1&#39;s l1: 0.0695662	valid_1&#39;s myFeval: 0.966811
[6000]	training&#39;s l1: 0.0493706	training&#39;s myFeval: 0.695185	valid_1&#39;s l1: 0.0694475	valid_1&#39;s myFeval: 0.964704
[6300]	training&#39;s l1: 0.0489288	training&#39;s myFeval: 0.687842	valid_1&#39;s l1: 0.0693419	valid_1&#39;s myFeval: 0.962898
[6600]	training&#39;s l1: 0.0485633	training&#39;s myFeval: 0.680849	valid_1&#39;s l1: 0.0692492	valid_1&#39;s myFeval: 0.960514
[6900]	training&#39;s l1: 0.0482348	training&#39;s myFeval: 0.674901	valid_1&#39;s l1: 0.0691855	valid_1&#39;s myFeval: 0.958937
[7200]	training&#39;s l1: 0.0479127	training&#39;s myFeval: 0.669756	valid_1&#39;s l1: 0.0691125	valid_1&#39;s myFeval: 0.957646
[7500]	training&#39;s l1: 0.0475255	training&#39;s myFeval: 0.663939	valid_1&#39;s l1: 0.0690293	valid_1&#39;s myFeval: 0.956157
[7800]	training&#39;s l1: 0.0471673	training&#39;s myFeval: 0.658967	valid_1&#39;s l1: 0.06896	valid_1&#39;s myFeval: 0.955074
[8100]	training&#39;s l1: 0.0468242	training&#39;s myFeval: 0.653732	valid_1&#39;s l1: 0.0688767	valid_1&#39;s myFeval: 0.953713
[8400]	training&#39;s l1: 0.0464743	training&#39;s myFeval: 0.647983	valid_1&#39;s l1: 0.0688168	valid_1&#39;s myFeval: 0.952434
[8700]	training&#39;s l1: 0.0461686	training&#39;s myFeval: 0.643626	valid_1&#39;s l1: 0.0687561	valid_1&#39;s myFeval: 0.951372
[9000]	training&#39;s l1: 0.0458906	training&#39;s myFeval: 0.639849	valid_1&#39;s l1: 0.0687261	valid_1&#39;s myFeval: 0.950809
[9300]	training&#39;s l1: 0.0456068	training&#39;s myFeval: 0.63605	valid_1&#39;s l1: 0.0686644	valid_1&#39;s myFeval: 0.950021
[9600]	training&#39;s l1: 0.0453274	training&#39;s myFeval: 0.631981	valid_1&#39;s l1: 0.0686083	valid_1&#39;s myFeval: 0.949204
[9900]	training&#39;s l1: 0.0450508	training&#39;s myFeval: 0.628168	valid_1&#39;s l1: 0.0685384	valid_1&#39;s myFeval: 0.948206
[10200]	training&#39;s l1: 0.044785	training&#39;s myFeval: 0.624053	valid_1&#39;s l1: 0.0684834	valid_1&#39;s myFeval: 0.947288
[10500]	training&#39;s l1: 0.0445355	training&#39;s myFeval: 0.620189	valid_1&#39;s l1: 0.0684226	valid_1&#39;s myFeval: 0.946302
[10800]	training&#39;s l1: 0.0443011	training&#39;s myFeval: 0.616928	valid_1&#39;s l1: 0.0683627	valid_1&#39;s myFeval: 0.945384
[11100]	training&#39;s l1: 0.044067	training&#39;s myFeval: 0.613637	valid_1&#39;s l1: 0.0683264	valid_1&#39;s myFeval: 0.944685
[11400]	training&#39;s l1: 0.0438546	training&#39;s myFeval: 0.610421	valid_1&#39;s l1: 0.0682779	valid_1&#39;s myFeval: 0.943852
[11700]	training&#39;s l1: 0.0436409	training&#39;s myFeval: 0.607226	valid_1&#39;s l1: 0.0682383	valid_1&#39;s myFeval: 0.943168
[12000]	training&#39;s l1: 0.0434608	training&#39;s myFeval: 0.604205	valid_1&#39;s l1: 0.068206	valid_1&#39;s myFeval: 0.942514
[12300]	training&#39;s l1: 0.043316	training&#39;s myFeval: 0.602017	valid_1&#39;s l1: 0.0681716	valid_1&#39;s myFeval: 0.941998
[12600]	training&#39;s l1: 0.0431708	training&#39;s myFeval: 0.599915	valid_1&#39;s l1: 0.0681438	valid_1&#39;s myFeval: 0.941611
[12900]	training&#39;s l1: 0.0429891	training&#39;s myFeval: 0.597183	valid_1&#39;s l1: 0.0681171	valid_1&#39;s myFeval: 0.941166
[13200]	training&#39;s l1: 0.0428026	training&#39;s myFeval: 0.594501	valid_1&#39;s l1: 0.0680742	valid_1&#39;s myFeval: 0.940473
[13500]	training&#39;s l1: 0.042628	training&#39;s myFeval: 0.592011	valid_1&#39;s l1: 0.0680341	valid_1&#39;s myFeval: 0.9398
[13800]	training&#39;s l1: 0.0424804	training&#39;s myFeval: 0.589817	valid_1&#39;s l1: 0.068007	valid_1&#39;s myFeval: 0.939271
[14100]	training&#39;s l1: 0.0423536	training&#39;s myFeval: 0.587948	valid_1&#39;s l1: 0.0679753	valid_1&#39;s myFeval: 0.938748
[14400]	training&#39;s l1: 0.0422116	training&#39;s myFeval: 0.585772	valid_1&#39;s l1: 0.0679515	valid_1&#39;s myFeval: 0.938351
[14700]	training&#39;s l1: 0.0420568	training&#39;s myFeval: 0.58375	valid_1&#39;s l1: 0.0679234	valid_1&#39;s myFeval: 0.937848
[15000]	training&#39;s l1: 0.0419101	training&#39;s myFeval: 0.581804	valid_1&#39;s l1: 0.0678922	valid_1&#39;s myFeval: 0.937325
[15300]	training&#39;s l1: 0.0417698	training&#39;s myFeval: 0.579795	valid_1&#39;s l1: 0.0678691	valid_1&#39;s myFeval: 0.936926
[15600]	training&#39;s l1: 0.0416291	training&#39;s myFeval: 0.577813	valid_1&#39;s l1: 0.0678398	valid_1&#39;s myFeval: 0.936496
[15900]	training&#39;s l1: 0.0414943	training&#39;s myFeval: 0.575716	valid_1&#39;s l1: 0.0678118	valid_1&#39;s myFeval: 0.936051
[16200]	training&#39;s l1: 0.0414014	training&#39;s myFeval: 0.574231	valid_1&#39;s l1: 0.0678049	valid_1&#39;s myFeval: 0.936017
[16500]	training&#39;s l1: 0.0412922	training&#39;s myFeval: 0.572474	valid_1&#39;s l1: 0.067789	valid_1&#39;s myFeval: 0.935722
[16800]	training&#39;s l1: 0.0411923	training&#39;s myFeval: 0.570709	valid_1&#39;s l1: 0.0677653	valid_1&#39;s myFeval: 0.935273
[17100]	training&#39;s l1: 0.0410919	training&#39;s myFeval: 0.568914	valid_1&#39;s l1: 0.0677456	valid_1&#39;s myFeval: 0.934926
[17400]	training&#39;s l1: 0.0409965	training&#39;s myFeval: 0.566972	valid_1&#39;s l1: 0.0677238	valid_1&#39;s myFeval: 0.93437
[17700]	training&#39;s l1: 0.0408904	training&#39;s myFeval: 0.565078	valid_1&#39;s l1: 0.0677003	valid_1&#39;s myFeval: 0.933865
[18000]	training&#39;s l1: 0.040771	training&#39;s myFeval: 0.563329	valid_1&#39;s l1: 0.067691	valid_1&#39;s myFeval: 0.933768
[18300]	training&#39;s l1: 0.0406465	training&#39;s myFeval: 0.561617	valid_1&#39;s l1: 0.0676648	valid_1&#39;s myFeval: 0.93341
[18600]	training&#39;s l1: 0.0405316	training&#39;s myFeval: 0.559959	valid_1&#39;s l1: 0.0676379	valid_1&#39;s myFeval: 0.933038
[18900]	training&#39;s l1: 0.0404038	training&#39;s myFeval: 0.558345	valid_1&#39;s l1: 0.067613	valid_1&#39;s myFeval: 0.932725
[19200]	training&#39;s l1: 0.0402703	training&#39;s myFeval: 0.556643	valid_1&#39;s l1: 0.0675805	valid_1&#39;s myFeval: 0.932269
[19500]	training&#39;s l1: 0.0401491	training&#39;s myFeval: 0.555004	valid_1&#39;s l1: 0.0675484	valid_1&#39;s myFeval: 0.931805
[19800]	training&#39;s l1: 0.0400529	training&#39;s myFeval: 0.553428	valid_1&#39;s l1: 0.0675279	valid_1&#39;s myFeval: 0.931463
[20100]	training&#39;s l1: 0.0399547	training&#39;s myFeval: 0.551974	valid_1&#39;s l1: 0.0675031	valid_1&#39;s myFeval: 0.931165
[20400]	training&#39;s l1: 0.0398754	training&#39;s myFeval: 0.550973	valid_1&#39;s l1: 0.0674871	valid_1&#39;s myFeval: 0.931015
[20700]	training&#39;s l1: 0.0397896	training&#39;s myFeval: 0.549877	valid_1&#39;s l1: 0.0674747	valid_1&#39;s myFeval: 0.930937
[21000]	training&#39;s l1: 0.039693	training&#39;s myFeval: 0.548532	valid_1&#39;s l1: 0.0674659	valid_1&#39;s myFeval: 0.930828
[21300]	training&#39;s l1: 0.0395937	training&#39;s myFeval: 0.546998	valid_1&#39;s l1: 0.0674493	valid_1&#39;s myFeval: 0.930491
[21600]	training&#39;s l1: 0.0394996	training&#39;s myFeval: 0.545815	valid_1&#39;s l1: 0.0674324	valid_1&#39;s myFeval: 0.930279
[21900]	training&#39;s l1: 0.0394076	training&#39;s myFeval: 0.54462	valid_1&#39;s l1: 0.067422	valid_1&#39;s myFeval: 0.930104
[22200]	training&#39;s l1: 0.0393214	training&#39;s myFeval: 0.543459	valid_1&#39;s l1: 0.0673989	valid_1&#39;s myFeval: 0.929742
[22500]	training&#39;s l1: 0.0392288	training&#39;s myFeval: 0.54238	valid_1&#39;s l1: 0.067383	valid_1&#39;s myFeval: 0.929648
[22800]	training&#39;s l1: 0.0391208	training&#39;s myFeval: 0.54117	valid_1&#39;s l1: 0.0673692	valid_1&#39;s myFeval: 0.92955
[23100]	training&#39;s l1: 0.039032	training&#39;s myFeval: 0.539925	valid_1&#39;s l1: 0.0673534	valid_1&#39;s myFeval: 0.929314
[23400]	training&#39;s l1: 0.0389419	training&#39;s myFeval: 0.538563	valid_1&#39;s l1: 0.0673274	valid_1&#39;s myFeval: 0.928891
[23700]	training&#39;s l1: 0.0388577	training&#39;s myFeval: 0.537346	valid_1&#39;s l1: 0.0673086	valid_1&#39;s myFeval: 0.928571
[24000]	training&#39;s l1: 0.0387792	training&#39;s myFeval: 0.536201	valid_1&#39;s l1: 0.0672921	valid_1&#39;s myFeval: 0.928255
[24300]	training&#39;s l1: 0.0386993	training&#39;s myFeval: 0.534927	valid_1&#39;s l1: 0.0672699	valid_1&#39;s myFeval: 0.927749
[24600]	training&#39;s l1: 0.0386258	training&#39;s myFeval: 0.533925	valid_1&#39;s l1: 0.0672634	valid_1&#39;s myFeval: 0.927605
[24900]	training&#39;s l1: 0.0385546	training&#39;s myFeval: 0.532843	valid_1&#39;s l1: 0.0672525	valid_1&#39;s myFeval: 0.927446
[25200]	training&#39;s l1: 0.0384566	training&#39;s myFeval: 0.531652	valid_1&#39;s l1: 0.0672429	valid_1&#39;s myFeval: 0.927291
[25500]	training&#39;s l1: 0.0383454	training&#39;s myFeval: 0.530212	valid_1&#39;s l1: 0.0672392	valid_1&#39;s myFeval: 0.927194
[25800]	training&#39;s l1: 0.0382634	training&#39;s myFeval: 0.529129	valid_1&#39;s l1: 0.0672296	valid_1&#39;s myFeval: 0.927133
[26100]	training&#39;s l1: 0.0381805	training&#39;s myFeval: 0.527968	valid_1&#39;s l1: 0.0672167	valid_1&#39;s myFeval: 0.926928
[26400]	training&#39;s l1: 0.0381136	training&#39;s myFeval: 0.527048	valid_1&#39;s l1: 0.0672019	valid_1&#39;s myFeval: 0.926709
[26700]	training&#39;s l1: 0.0380557	training&#39;s myFeval: 0.526457	valid_1&#39;s l1: 0.0671934	valid_1&#39;s myFeval: 0.926622
[27000]	training&#39;s l1: 0.0379938	training&#39;s myFeval: 0.525727	valid_1&#39;s l1: 0.0671841	valid_1&#39;s myFeval: 0.926437
[27300]	training&#39;s l1: 0.0379238	training&#39;s myFeval: 0.524762	valid_1&#39;s l1: 0.0671746	valid_1&#39;s myFeval: 0.926303
[27600]	training&#39;s l1: 0.0378724	training&#39;s myFeval: 0.524136	valid_1&#39;s l1: 0.0671665	valid_1&#39;s myFeval: 0.926156
[27900]	training&#39;s l1: 0.0378228	training&#39;s myFeval: 0.52353	valid_1&#39;s l1: 0.0671595	valid_1&#39;s myFeval: 0.926045
[28200]	training&#39;s l1: 0.0377747	training&#39;s myFeval: 0.522866	valid_1&#39;s l1: 0.0671522	valid_1&#39;s myFeval: 0.925922
[28500]	training&#39;s l1: 0.0377223	training&#39;s myFeval: 0.521911	valid_1&#39;s l1: 0.0671455	valid_1&#39;s myFeval: 0.925801
[28800]	training&#39;s l1: 0.0376728	training&#39;s myFeval: 0.521046	valid_1&#39;s l1: 0.0671374	valid_1&#39;s myFeval: 0.925644
[29100]	training&#39;s l1: 0.0376308	training&#39;s myFeval: 0.520302	valid_1&#39;s l1: 0.0671309	valid_1&#39;s myFeval: 0.925508
[29400]	training&#39;s l1: 0.037582	training&#39;s myFeval: 0.519523	valid_1&#39;s l1: 0.0671241	valid_1&#39;s myFeval: 0.925469
[29700]	training&#39;s l1: 0.0375237	training&#39;s myFeval: 0.518707	valid_1&#39;s l1: 0.0671151	valid_1&#39;s myFeval: 0.925405
[30000]	training&#39;s l1: 0.0374613	training&#39;s myFeval: 0.51781	valid_1&#39;s l1: 0.0671055	valid_1&#39;s myFeval: 0.925248
[30300]	training&#39;s l1: 0.0373875	training&#39;s myFeval: 0.51673	valid_1&#39;s l1: 0.0670947	valid_1&#39;s myFeval: 0.925036
[30600]	training&#39;s l1: 0.0372524	training&#39;s myFeval: 0.514837	valid_1&#39;s l1: 0.0670831	valid_1&#39;s myFeval: 0.92484
[30900]	training&#39;s l1: 0.0371669	training&#39;s myFeval: 0.513542	valid_1&#39;s l1: 0.0670745	valid_1&#39;s myFeval: 0.924727
[31200]	training&#39;s l1: 0.0371113	training&#39;s myFeval: 0.512715	valid_1&#39;s l1: 0.0670687	valid_1&#39;s myFeval: 0.924691
[31500]	training&#39;s l1: 0.0370546	training&#39;s myFeval: 0.511905	valid_1&#39;s l1: 0.0670598	valid_1&#39;s myFeval: 0.924492
[31800]	training&#39;s l1: 0.0369997	training&#39;s myFeval: 0.511127	valid_1&#39;s l1: 0.0670604	valid_1&#39;s myFeval: 0.924425
[32100]	training&#39;s l1: 0.036947	training&#39;s myFeval: 0.510447	valid_1&#39;s l1: 0.0670575	valid_1&#39;s myFeval: 0.924403
[32400]	training&#39;s l1: 0.0368879	training&#39;s myFeval: 0.509644	valid_1&#39;s l1: 0.0670514	valid_1&#39;s myFeval: 0.924282
[32700]	training&#39;s l1: 0.0368323	training&#39;s myFeval: 0.50872	valid_1&#39;s l1: 0.0670434	valid_1&#39;s myFeval: 0.924098
[33000]	training&#39;s l1: 0.0367748	training&#39;s myFeval: 0.507915	valid_1&#39;s l1: 0.0670356	valid_1&#39;s myFeval: 0.923962
[33300]	training&#39;s l1: 0.0367084	training&#39;s myFeval: 0.507023	valid_1&#39;s l1: 0.0670325	valid_1&#39;s myFeval: 0.923905
[33600]	training&#39;s l1: 0.0366289	training&#39;s myFeval: 0.506035	valid_1&#39;s l1: 0.0670121	valid_1&#39;s myFeval: 0.92364
[33900]	training&#39;s l1: 0.0365701	training&#39;s myFeval: 0.50528	valid_1&#39;s l1: 0.0670021	valid_1&#39;s myFeval: 0.923513
[34200]	training&#39;s l1: 0.0365237	training&#39;s myFeval: 0.504655	valid_1&#39;s l1: 0.0670015	valid_1&#39;s myFeval: 0.923503
[34500]	training&#39;s l1: 0.0364702	training&#39;s myFeval: 0.503921	valid_1&#39;s l1: 0.0669974	valid_1&#39;s myFeval: 0.923484
[34800]	training&#39;s l1: 0.0364249	training&#39;s myFeval: 0.503268	valid_1&#39;s l1: 0.066988	valid_1&#39;s myFeval: 0.923307
[35100]	training&#39;s l1: 0.0363838	training&#39;s myFeval: 0.50267	valid_1&#39;s l1: 0.066983	valid_1&#39;s myFeval: 0.923213
[35400]	training&#39;s l1: 0.0363402	training&#39;s myFeval: 0.502049	valid_1&#39;s l1: 0.0669712	valid_1&#39;s myFeval: 0.923066
[35700]	training&#39;s l1: 0.0362996	training&#39;s myFeval: 0.5014	valid_1&#39;s l1: 0.0669611	valid_1&#39;s myFeval: 0.922829
[36000]	training&#39;s l1: 0.0362589	training&#39;s myFeval: 0.500798	valid_1&#39;s l1: 0.0669582	valid_1&#39;s myFeval: 0.922814
[36300]	training&#39;s l1: 0.0362138	training&#39;s myFeval: 0.50016	valid_1&#39;s l1: 0.066951	valid_1&#39;s myFeval: 0.922694
[36600]	training&#39;s l1: 0.0361763	training&#39;s myFeval: 0.499638	valid_1&#39;s l1: 0.0669485	valid_1&#39;s myFeval: 0.922611
[36900]	training&#39;s l1: 0.0361372	training&#39;s myFeval: 0.499134	valid_1&#39;s l1: 0.0669425	valid_1&#39;s myFeval: 0.922486
[37200]	training&#39;s l1: 0.0360884	training&#39;s myFeval: 0.498509	valid_1&#39;s l1: 0.0669332	valid_1&#39;s myFeval: 0.922389
[37500]	training&#39;s l1: 0.036016	training&#39;s myFeval: 0.497604	valid_1&#39;s l1: 0.0669098	valid_1&#39;s myFeval: 0.922029
[37800]	training&#39;s l1: 0.0359467	training&#39;s myFeval: 0.496707	valid_1&#39;s l1: 0.066892	valid_1&#39;s myFeval: 0.92179
[38100]	training&#39;s l1: 0.035892	training&#39;s myFeval: 0.496041	valid_1&#39;s l1: 0.0668792	valid_1&#39;s myFeval: 0.921638
[38400]	training&#39;s l1: 0.035849	training&#39;s myFeval: 0.495534	valid_1&#39;s l1: 0.0668707	valid_1&#39;s myFeval: 0.921554
[38700]	training&#39;s l1: 0.0358033	training&#39;s myFeval: 0.494893	valid_1&#39;s l1: 0.0668604	valid_1&#39;s myFeval: 0.921362
[39000]	training&#39;s l1: 0.0357598	training&#39;s myFeval: 0.494259	valid_1&#39;s l1: 0.0668526	valid_1&#39;s myFeval: 0.921253
[39300]	training&#39;s l1: 0.0357182	training&#39;s myFeval: 0.493711	valid_1&#39;s l1: 0.0668525	valid_1&#39;s myFeval: 0.921249
[39600]	training&#39;s l1: 0.0356803	training&#39;s myFeval: 0.493187	valid_1&#39;s l1: 0.0668488	valid_1&#39;s myFeval: 0.921184
[39900]	training&#39;s l1: 0.0356367	training&#39;s myFeval: 0.492631	valid_1&#39;s l1: 0.06684	valid_1&#39;s myFeval: 0.921068
[40200]	training&#39;s l1: 0.0355982	training&#39;s myFeval: 0.492106	valid_1&#39;s l1: 0.0668323	valid_1&#39;s myFeval: 0.920974
[40500]	training&#39;s l1: 0.0355554	training&#39;s myFeval: 0.491507	valid_1&#39;s l1: 0.0668335	valid_1&#39;s myFeval: 0.920971
[40800]	training&#39;s l1: 0.0355196	training&#39;s myFeval: 0.491015	valid_1&#39;s l1: 0.0668288	valid_1&#39;s myFeval: 0.920869
[41100]	training&#39;s l1: 0.0354815	training&#39;s myFeval: 0.490466	valid_1&#39;s l1: 0.0668223	valid_1&#39;s myFeval: 0.920752
[41400]	training&#39;s l1: 0.0354425	training&#39;s myFeval: 0.489884	valid_1&#39;s l1: 0.0668164	valid_1&#39;s myFeval: 0.920643
[41700]	training&#39;s l1: 0.0354007	training&#39;s myFeval: 0.489291	valid_1&#39;s l1: 0.0668063	valid_1&#39;s myFeval: 0.920564
[42000]	training&#39;s l1: 0.0353651	training&#39;s myFeval: 0.488779	valid_1&#39;s l1: 0.0668044	valid_1&#39;s myFeval: 0.920519
[42300]	training&#39;s l1: 0.0353275	training&#39;s myFeval: 0.48827	valid_1&#39;s l1: 0.0668015	valid_1&#39;s myFeval: 0.920455
[42600]	training&#39;s l1: 0.0352848	training&#39;s myFeval: 0.487671	valid_1&#39;s l1: 0.0667959	valid_1&#39;s myFeval: 0.920356
[42900]	training&#39;s l1: 0.0352525	training&#39;s myFeval: 0.487242	valid_1&#39;s l1: 0.0667946	valid_1&#39;s myFeval: 0.920319
[43200]	training&#39;s l1: 0.0352221	training&#39;s myFeval: 0.486823	valid_1&#39;s l1: 0.0667936	valid_1&#39;s myFeval: 0.920301
[43500]	training&#39;s l1: 0.0351873	training&#39;s myFeval: 0.486406	valid_1&#39;s l1: 0.066789	valid_1&#39;s myFeval: 0.920257
[43800]	training&#39;s l1: 0.0351325	training&#39;s myFeval: 0.485733	valid_1&#39;s l1: 0.0667806	valid_1&#39;s myFeval: 0.920261
[44100]	training&#39;s l1: 0.0350812	training&#39;s myFeval: 0.485114	valid_1&#39;s l1: 0.0667706	valid_1&#39;s myFeval: 0.920218
[44400]	training&#39;s l1: 0.0350271	training&#39;s myFeval: 0.484462	valid_1&#39;s l1: 0.0667609	valid_1&#39;s myFeval: 0.920149
[44700]	training&#39;s l1: 0.0349879	training&#39;s myFeval: 0.483846	valid_1&#39;s l1: 0.0667522	valid_1&#39;s myFeval: 0.920026
[45000]	training&#39;s l1: 0.0349505	training&#39;s myFeval: 0.483297	valid_1&#39;s l1: 0.0667481	valid_1&#39;s myFeval: 0.919973
[45300]	training&#39;s l1: 0.0349101	training&#39;s myFeval: 0.482729	valid_1&#39;s l1: 0.0667419	valid_1&#39;s myFeval: 0.919907
[45600]	training&#39;s l1: 0.0348754	training&#39;s myFeval: 0.482205	valid_1&#39;s l1: 0.0667365	valid_1&#39;s myFeval: 0.919785
[45900]	training&#39;s l1: 0.0348443	training&#39;s myFeval: 0.481753	valid_1&#39;s l1: 0.0667334	valid_1&#39;s myFeval: 0.919699
[46200]	training&#39;s l1: 0.0348118	training&#39;s myFeval: 0.481293	valid_1&#39;s l1: 0.0667311	valid_1&#39;s myFeval: 0.919694
[46500]	training&#39;s l1: 0.0347757	training&#39;s myFeval: 0.480748	valid_1&#39;s l1: 0.0667246	valid_1&#39;s myFeval: 0.919642
[46800]	training&#39;s l1: 0.0347377	training&#39;s myFeval: 0.480242	valid_1&#39;s l1: 0.0667201	valid_1&#39;s myFeval: 0.919578
[47100]	training&#39;s l1: 0.0347024	training&#39;s myFeval: 0.479695	valid_1&#39;s l1: 0.066716	valid_1&#39;s myFeval: 0.919531
[47400]	training&#39;s l1: 0.0346687	training&#39;s myFeval: 0.47919	valid_1&#39;s l1: 0.0667155	valid_1&#39;s myFeval: 0.919499
[47700]	training&#39;s l1: 0.0346309	training&#39;s myFeval: 0.478676	valid_1&#39;s l1: 0.0667139	valid_1&#39;s myFeval: 0.919467
[48000]	training&#39;s l1: 0.0345976	training&#39;s myFeval: 0.478219	valid_1&#39;s l1: 0.0667139	valid_1&#39;s myFeval: 0.919462
[48300]	training&#39;s l1: 0.0345743	training&#39;s myFeval: 0.477861	valid_1&#39;s l1: 0.0667123	valid_1&#39;s myFeval: 0.919457
[48600]	training&#39;s l1: 0.0345468	training&#39;s myFeval: 0.47737	valid_1&#39;s l1: 0.0667098	valid_1&#39;s myFeval: 0.919405
[48900]	training&#39;s l1: 0.0345176	training&#39;s myFeval: 0.476907	valid_1&#39;s l1: 0.0667069	valid_1&#39;s myFeval: 0.919382
[49200]	training&#39;s l1: 0.0344872	training&#39;s myFeval: 0.476458	valid_1&#39;s l1: 0.0667015	valid_1&#39;s myFeval: 0.919254
[49500]	training&#39;s l1: 0.0344582	training&#39;s myFeval: 0.476031	valid_1&#39;s l1: 0.0666959	valid_1&#39;s myFeval: 0.919173
[49800]	training&#39;s l1: 0.0344262	training&#39;s myFeval: 0.4755	valid_1&#39;s l1: 0.0666946	valid_1&#39;s myFeval: 0.9192
Early stopping, best iteration is:
[49397]	training&#39;s l1: 0.0344679	training&#39;s myFeval: 0.476172	valid_1&#39;s l1: 0.0666966	valid_1&#39;s myFeval: 0.91916
fold n°7
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011497 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9903
[LightGBM] [Info] Number of data points in the train set: 26617, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.423031
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.11165	training&#39;s myFeval: 2.04461	valid_1&#39;s l1: 0.118337	valid_1&#39;s myFeval: 2.27117
[600]	training&#39;s l1: 0.0791025	training&#39;s myFeval: 1.2621	valid_1&#39;s l1: 0.0852341	valid_1&#39;s myFeval: 1.4391
[900]	training&#39;s l1: 0.0719023	training&#39;s myFeval: 1.08184	valid_1&#39;s l1: 0.0793708	valid_1&#39;s myFeval: 1.24152
[1200]	training&#39;s l1: 0.068061	training&#39;s myFeval: 1.0045	valid_1&#39;s l1: 0.0767842	valid_1&#39;s myFeval: 1.16621
[1500]	training&#39;s l1: 0.0652673	training&#39;s myFeval: 0.952721	valid_1&#39;s l1: 0.0752783	valid_1&#39;s myFeval: 1.13084
[1800]	training&#39;s l1: 0.0630586	training&#39;s myFeval: 0.914756	valid_1&#39;s l1: 0.0741822	valid_1&#39;s myFeval: 1.10798
[2100]	training&#39;s l1: 0.0612369	training&#39;s myFeval: 0.88104	valid_1&#39;s l1: 0.0732751	valid_1&#39;s myFeval: 1.08718
[2400]	training&#39;s l1: 0.0596956	training&#39;s myFeval: 0.853903	valid_1&#39;s l1: 0.072645	valid_1&#39;s myFeval: 1.07309
[2700]	training&#39;s l1: 0.0583115	training&#39;s myFeval: 0.831207	valid_1&#39;s l1: 0.072062	valid_1&#39;s myFeval: 1.06057
[3000]	training&#39;s l1: 0.0570617	training&#39;s myFeval: 0.811189	valid_1&#39;s l1: 0.0715239	valid_1&#39;s myFeval: 1.04833
[3300]	training&#39;s l1: 0.0559279	training&#39;s myFeval: 0.793344	valid_1&#39;s l1: 0.0710903	valid_1&#39;s myFeval: 1.03911
[3600]	training&#39;s l1: 0.0549456	training&#39;s myFeval: 0.7785	valid_1&#39;s l1: 0.0707606	valid_1&#39;s myFeval: 1.03228
[3900]	training&#39;s l1: 0.0540366	training&#39;s myFeval: 0.763979	valid_1&#39;s l1: 0.0704822	valid_1&#39;s myFeval: 1.02533
[4200]	training&#39;s l1: 0.0532222	training&#39;s myFeval: 0.751602	valid_1&#39;s l1: 0.0702248	valid_1&#39;s myFeval: 1.02007
[4500]	training&#39;s l1: 0.0524742	training&#39;s myFeval: 0.740093	valid_1&#39;s l1: 0.0699886	valid_1&#39;s myFeval: 1.01527
[4800]	training&#39;s l1: 0.0518143	training&#39;s myFeval: 0.730653	valid_1&#39;s l1: 0.0698071	valid_1&#39;s myFeval: 1.01177
[5100]	training&#39;s l1: 0.0511756	training&#39;s myFeval: 0.720531	valid_1&#39;s l1: 0.0695963	valid_1&#39;s myFeval: 1.00708
[5400]	training&#39;s l1: 0.0505683	training&#39;s myFeval: 0.711021	valid_1&#39;s l1: 0.0694246	valid_1&#39;s myFeval: 1.0037
[5700]	training&#39;s l1: 0.0500059	training&#39;s myFeval: 0.702004	valid_1&#39;s l1: 0.0692633	valid_1&#39;s myFeval: 1.00036
[6000]	training&#39;s l1: 0.0494889	training&#39;s myFeval: 0.693708	valid_1&#39;s l1: 0.0691392	valid_1&#39;s myFeval: 0.997844
[6300]	training&#39;s l1: 0.0490027	training&#39;s myFeval: 0.685913	valid_1&#39;s l1: 0.0690002	valid_1&#39;s myFeval: 0.995372
[6600]	training&#39;s l1: 0.0485359	training&#39;s myFeval: 0.679047	valid_1&#39;s l1: 0.0688846	valid_1&#39;s myFeval: 0.992923
[6900]	training&#39;s l1: 0.0481131	training&#39;s myFeval: 0.672547	valid_1&#39;s l1: 0.0687719	valid_1&#39;s myFeval: 0.990176
[7200]	training&#39;s l1: 0.047724	training&#39;s myFeval: 0.666254	valid_1&#39;s l1: 0.0686819	valid_1&#39;s myFeval: 0.987908
[7500]	training&#39;s l1: 0.0473817	training&#39;s myFeval: 0.660889	valid_1&#39;s l1: 0.068606	valid_1&#39;s myFeval: 0.986065
[7800]	training&#39;s l1: 0.0470723	training&#39;s myFeval: 0.65607	valid_1&#39;s l1: 0.0685253	valid_1&#39;s myFeval: 0.984334
[8100]	training&#39;s l1: 0.0467678	training&#39;s myFeval: 0.652274	valid_1&#39;s l1: 0.0684691	valid_1&#39;s myFeval: 0.983147
[8400]	training&#39;s l1: 0.0464594	training&#39;s myFeval: 0.648087	valid_1&#39;s l1: 0.0684143	valid_1&#39;s myFeval: 0.982059
[8700]	training&#39;s l1: 0.046164	training&#39;s myFeval: 0.643354	valid_1&#39;s l1: 0.0683765	valid_1&#39;s myFeval: 0.981893
[9000]	training&#39;s l1: 0.0458523	training&#39;s myFeval: 0.638638	valid_1&#39;s l1: 0.0682845	valid_1&#39;s myFeval: 0.980154
[9300]	training&#39;s l1: 0.0455698	training&#39;s myFeval: 0.63421	valid_1&#39;s l1: 0.0682199	valid_1&#39;s myFeval: 0.978552
[9600]	training&#39;s l1: 0.0452978	training&#39;s myFeval: 0.630089	valid_1&#39;s l1: 0.0681537	valid_1&#39;s myFeval: 0.977176
[9900]	training&#39;s l1: 0.0450431	training&#39;s myFeval: 0.625814	valid_1&#39;s l1: 0.0680979	valid_1&#39;s myFeval: 0.975954
[10200]	training&#39;s l1: 0.044802	training&#39;s myFeval: 0.622239	valid_1&#39;s l1: 0.0680548	valid_1&#39;s myFeval: 0.975168
[10500]	training&#39;s l1: 0.0446128	training&#39;s myFeval: 0.61912	valid_1&#39;s l1: 0.068021	valid_1&#39;s myFeval: 0.974376
[10800]	training&#39;s l1: 0.0444314	training&#39;s myFeval: 0.61636	valid_1&#39;s l1: 0.0679904	valid_1&#39;s myFeval: 0.973825
[11100]	training&#39;s l1: 0.0442017	training&#39;s myFeval: 0.612973	valid_1&#39;s l1: 0.0679385	valid_1&#39;s myFeval: 0.972977
[11400]	training&#39;s l1: 0.044005	training&#39;s myFeval: 0.610154	valid_1&#39;s l1: 0.067895	valid_1&#39;s myFeval: 0.971881
[11700]	training&#39;s l1: 0.0438042	training&#39;s myFeval: 0.6073	valid_1&#39;s l1: 0.0678542	valid_1&#39;s myFeval: 0.971259
[12000]	training&#39;s l1: 0.0436037	training&#39;s myFeval: 0.604346	valid_1&#39;s l1: 0.0678131	valid_1&#39;s myFeval: 0.970525
[12300]	training&#39;s l1: 0.0433987	training&#39;s myFeval: 0.601144	valid_1&#39;s l1: 0.0677732	valid_1&#39;s myFeval: 0.969694
[12600]	training&#39;s l1: 0.0432211	training&#39;s myFeval: 0.598562	valid_1&#39;s l1: 0.0677398	valid_1&#39;s myFeval: 0.969213
[12900]	training&#39;s l1: 0.0430622	training&#39;s myFeval: 0.59631	valid_1&#39;s l1: 0.0677185	valid_1&#39;s myFeval: 0.968773
[13200]	training&#39;s l1: 0.0428959	training&#39;s myFeval: 0.593803	valid_1&#39;s l1: 0.0676748	valid_1&#39;s myFeval: 0.96787
[13500]	training&#39;s l1: 0.0427121	training&#39;s myFeval: 0.59111	valid_1&#39;s l1: 0.067637	valid_1&#39;s myFeval: 0.967362
[13800]	training&#39;s l1: 0.0425535	training&#39;s myFeval: 0.588742	valid_1&#39;s l1: 0.0676125	valid_1&#39;s myFeval: 0.96672
[14100]	training&#39;s l1: 0.0423859	training&#39;s myFeval: 0.586219	valid_1&#39;s l1: 0.0675832	valid_1&#39;s myFeval: 0.96624
[14400]	training&#39;s l1: 0.0422264	training&#39;s myFeval: 0.583818	valid_1&#39;s l1: 0.06756	valid_1&#39;s myFeval: 0.965779
[14700]	training&#39;s l1: 0.0420861	training&#39;s myFeval: 0.58165	valid_1&#39;s l1: 0.0675392	valid_1&#39;s myFeval: 0.965252
[15000]	training&#39;s l1: 0.0419554	training&#39;s myFeval: 0.579586	valid_1&#39;s l1: 0.0675119	valid_1&#39;s myFeval: 0.964742
[15300]	training&#39;s l1: 0.0418344	training&#39;s myFeval: 0.57774	valid_1&#39;s l1: 0.067497	valid_1&#39;s myFeval: 0.964437
[15600]	training&#39;s l1: 0.0417176	training&#39;s myFeval: 0.576193	valid_1&#39;s l1: 0.0674901	valid_1&#39;s myFeval: 0.964096
[15900]	training&#39;s l1: 0.0415993	training&#39;s myFeval: 0.574365	valid_1&#39;s l1: 0.0674759	valid_1&#39;s myFeval: 0.963949
[16200]	training&#39;s l1: 0.0414826	training&#39;s myFeval: 0.572653	valid_1&#39;s l1: 0.0674708	valid_1&#39;s myFeval: 0.96387
[16500]	training&#39;s l1: 0.041349	training&#39;s myFeval: 0.570438	valid_1&#39;s l1: 0.0674537	valid_1&#39;s myFeval: 0.963283
[16800]	training&#39;s l1: 0.0412177	training&#39;s myFeval: 0.568361	valid_1&#39;s l1: 0.0674311	valid_1&#39;s myFeval: 0.962862
[17100]	training&#39;s l1: 0.0410981	training&#39;s myFeval: 0.566459	valid_1&#39;s l1: 0.0674107	valid_1&#39;s myFeval: 0.96231
[17400]	training&#39;s l1: 0.0409808	training&#39;s myFeval: 0.564922	valid_1&#39;s l1: 0.0673952	valid_1&#39;s myFeval: 0.961864
[17700]	training&#39;s l1: 0.0408786	training&#39;s myFeval: 0.563415	valid_1&#39;s l1: 0.0673725	valid_1&#39;s myFeval: 0.961535
[18000]	training&#39;s l1: 0.0407796	training&#39;s myFeval: 0.561976	valid_1&#39;s l1: 0.0673572	valid_1&#39;s myFeval: 0.960922
[18300]	training&#39;s l1: 0.0406882	training&#39;s myFeval: 0.560664	valid_1&#39;s l1: 0.0673435	valid_1&#39;s myFeval: 0.960541
[18600]	training&#39;s l1: 0.0405954	training&#39;s myFeval: 0.559313	valid_1&#39;s l1: 0.0673281	valid_1&#39;s myFeval: 0.959923
[18900]	training&#39;s l1: 0.0404957	training&#39;s myFeval: 0.557991	valid_1&#39;s l1: 0.0673127	valid_1&#39;s myFeval: 0.959617
[19200]	training&#39;s l1: 0.0403837	training&#39;s myFeval: 0.556589	valid_1&#39;s l1: 0.0672865	valid_1&#39;s myFeval: 0.959185
[19500]	training&#39;s l1: 0.0402833	training&#39;s myFeval: 0.555071	valid_1&#39;s l1: 0.0672709	valid_1&#39;s myFeval: 0.958918
[19800]	training&#39;s l1: 0.0401917	training&#39;s myFeval: 0.553994	valid_1&#39;s l1: 0.0672573	valid_1&#39;s myFeval: 0.958609
[20100]	training&#39;s l1: 0.0401085	training&#39;s myFeval: 0.553049	valid_1&#39;s l1: 0.0672505	valid_1&#39;s myFeval: 0.958528
[20400]	training&#39;s l1: 0.0400265	training&#39;s myFeval: 0.551955	valid_1&#39;s l1: 0.0672414	valid_1&#39;s myFeval: 0.958299
[20700]	training&#39;s l1: 0.039935	training&#39;s myFeval: 0.550553	valid_1&#39;s l1: 0.0672312	valid_1&#39;s myFeval: 0.958016
[21000]	training&#39;s l1: 0.0398349	training&#39;s myFeval: 0.548944	valid_1&#39;s l1: 0.0672157	valid_1&#39;s myFeval: 0.957729
[21300]	training&#39;s l1: 0.0397383	training&#39;s myFeval: 0.547435	valid_1&#39;s l1: 0.0671965	valid_1&#39;s myFeval: 0.957414
[21600]	training&#39;s l1: 0.0396531	training&#39;s myFeval: 0.546027	valid_1&#39;s l1: 0.0671844	valid_1&#39;s myFeval: 0.957135
[21900]	training&#39;s l1: 0.0395619	training&#39;s myFeval: 0.544626	valid_1&#39;s l1: 0.0671674	valid_1&#39;s myFeval: 0.956776
[22200]	training&#39;s l1: 0.0394803	training&#39;s myFeval: 0.543323	valid_1&#39;s l1: 0.0671503	valid_1&#39;s myFeval: 0.956466
[22500]	training&#39;s l1: 0.0394062	training&#39;s myFeval: 0.542267	valid_1&#39;s l1: 0.0671314	valid_1&#39;s myFeval: 0.95608
[22800]	training&#39;s l1: 0.0393407	training&#39;s myFeval: 0.541191	valid_1&#39;s l1: 0.0671134	valid_1&#39;s myFeval: 0.955669
[23100]	training&#39;s l1: 0.0392641	training&#39;s myFeval: 0.540067	valid_1&#39;s l1: 0.0671043	valid_1&#39;s myFeval: 0.955566
[23400]	training&#39;s l1: 0.039186	training&#39;s myFeval: 0.538912	valid_1&#39;s l1: 0.067088	valid_1&#39;s myFeval: 0.955267
[23700]	training&#39;s l1: 0.0391116	training&#39;s myFeval: 0.537823	valid_1&#39;s l1: 0.0670806	valid_1&#39;s myFeval: 0.955152
[24000]	training&#39;s l1: 0.0390396	training&#39;s myFeval: 0.536754	valid_1&#39;s l1: 0.0670773	valid_1&#39;s myFeval: 0.955052
[24300]	training&#39;s l1: 0.038963	training&#39;s myFeval: 0.53547	valid_1&#39;s l1: 0.0670717	valid_1&#39;s myFeval: 0.954894
[24600]	training&#39;s l1: 0.0388847	training&#39;s myFeval: 0.534185	valid_1&#39;s l1: 0.0670589	valid_1&#39;s myFeval: 0.954453
[24900]	training&#39;s l1: 0.0388113	training&#39;s myFeval: 0.53304	valid_1&#39;s l1: 0.0670489	valid_1&#39;s myFeval: 0.954186
[25200]	training&#39;s l1: 0.038735	training&#39;s myFeval: 0.53196	valid_1&#39;s l1: 0.0670305	valid_1&#39;s myFeval: 0.9539
[25500]	training&#39;s l1: 0.0386545	training&#39;s myFeval: 0.530916	valid_1&#39;s l1: 0.0670135	valid_1&#39;s myFeval: 0.95367
[25800]	training&#39;s l1: 0.0385859	training&#39;s myFeval: 0.529768	valid_1&#39;s l1: 0.0670021	valid_1&#39;s myFeval: 0.953413
[26100]	training&#39;s l1: 0.038522	training&#39;s myFeval: 0.528614	valid_1&#39;s l1: 0.0669923	valid_1&#39;s myFeval: 0.953235
[26400]	training&#39;s l1: 0.0384397	training&#39;s myFeval: 0.527467	valid_1&#39;s l1: 0.0669838	valid_1&#39;s myFeval: 0.953073
[26700]	training&#39;s l1: 0.0383381	training&#39;s myFeval: 0.526112	valid_1&#39;s l1: 0.0669835	valid_1&#39;s myFeval: 0.953096
[27000]	training&#39;s l1: 0.0382623	training&#39;s myFeval: 0.525088	valid_1&#39;s l1: 0.0669729	valid_1&#39;s myFeval: 0.952955
[27300]	training&#39;s l1: 0.0381955	training&#39;s myFeval: 0.524107	valid_1&#39;s l1: 0.0669607	valid_1&#39;s myFeval: 0.952776
[27600]	training&#39;s l1: 0.0381335	training&#39;s myFeval: 0.523146	valid_1&#39;s l1: 0.0669516	valid_1&#39;s myFeval: 0.95243
[27900]	training&#39;s l1: 0.0380905	training&#39;s myFeval: 0.522487	valid_1&#39;s l1: 0.0669418	valid_1&#39;s myFeval: 0.952273
[28200]	training&#39;s l1: 0.038043	training&#39;s myFeval: 0.521715	valid_1&#39;s l1: 0.0669358	valid_1&#39;s myFeval: 0.952192
[28500]	training&#39;s l1: 0.0379799	training&#39;s myFeval: 0.520848	valid_1&#39;s l1: 0.066926	valid_1&#39;s myFeval: 0.952045
[28800]	training&#39;s l1: 0.0379131	training&#39;s myFeval: 0.519892	valid_1&#39;s l1: 0.0669223	valid_1&#39;s myFeval: 0.951948
[29100]	training&#39;s l1: 0.0378478	training&#39;s myFeval: 0.518963	valid_1&#39;s l1: 0.0669131	valid_1&#39;s myFeval: 0.951815
[29400]	training&#39;s l1: 0.0377915	training&#39;s myFeval: 0.51809	valid_1&#39;s l1: 0.0669081	valid_1&#39;s myFeval: 0.951683
[29700]	training&#39;s l1: 0.0377462	training&#39;s myFeval: 0.51758	valid_1&#39;s l1: 0.0669027	valid_1&#39;s myFeval: 0.951585
[30000]	training&#39;s l1: 0.0377029	training&#39;s myFeval: 0.517089	valid_1&#39;s l1: 0.0668989	valid_1&#39;s myFeval: 0.951504
[30300]	training&#39;s l1: 0.0376581	training&#39;s myFeval: 0.516502	valid_1&#39;s l1: 0.0668954	valid_1&#39;s myFeval: 0.951415
[30600]	training&#39;s l1: 0.0376077	training&#39;s myFeval: 0.515815	valid_1&#39;s l1: 0.066889	valid_1&#39;s myFeval: 0.951169
[30900]	training&#39;s l1: 0.0375646	training&#39;s myFeval: 0.515333	valid_1&#39;s l1: 0.066882	valid_1&#39;s myFeval: 0.951054
[31200]	training&#39;s l1: 0.0375258	training&#39;s myFeval: 0.51489	valid_1&#39;s l1: 0.0668796	valid_1&#39;s myFeval: 0.95104
[31500]	training&#39;s l1: 0.0374738	training&#39;s myFeval: 0.514244	valid_1&#39;s l1: 0.066871	valid_1&#39;s myFeval: 0.950958
[31800]	training&#39;s l1: 0.0374041	training&#39;s myFeval: 0.513316	valid_1&#39;s l1: 0.0668643	valid_1&#39;s myFeval: 0.950839
[32100]	training&#39;s l1: 0.0373409	training&#39;s myFeval: 0.512411	valid_1&#39;s l1: 0.0668529	valid_1&#39;s myFeval: 0.9506
[32400]	training&#39;s l1: 0.0372887	training&#39;s myFeval: 0.511557	valid_1&#39;s l1: 0.0668472	valid_1&#39;s myFeval: 0.950488
[32700]	training&#39;s l1: 0.0372346	training&#39;s myFeval: 0.510705	valid_1&#39;s l1: 0.066843	valid_1&#39;s myFeval: 0.950329
[33000]	training&#39;s l1: 0.0371754	training&#39;s myFeval: 0.509893	valid_1&#39;s l1: 0.0668321	valid_1&#39;s myFeval: 0.950224
[33300]	training&#39;s l1: 0.037118	training&#39;s myFeval: 0.50893	valid_1&#39;s l1: 0.0668198	valid_1&#39;s myFeval: 0.950067
[33600]	training&#39;s l1: 0.0370638	training&#39;s myFeval: 0.508065	valid_1&#39;s l1: 0.0668171	valid_1&#39;s myFeval: 0.949982
[33900]	training&#39;s l1: 0.0370142	training&#39;s myFeval: 0.507323	valid_1&#39;s l1: 0.066809	valid_1&#39;s myFeval: 0.949745
[34200]	training&#39;s l1: 0.0369421	training&#39;s myFeval: 0.50642	valid_1&#39;s l1: 0.0668126	valid_1&#39;s myFeval: 0.949661
[34500]	training&#39;s l1: 0.0368905	training&#39;s myFeval: 0.505656	valid_1&#39;s l1: 0.0668073	valid_1&#39;s myFeval: 0.949535
[34800]	training&#39;s l1: 0.0368341	training&#39;s myFeval: 0.504862	valid_1&#39;s l1: 0.0668038	valid_1&#39;s myFeval: 0.949387
[35100]	training&#39;s l1: 0.0367836	training&#39;s myFeval: 0.504114	valid_1&#39;s l1: 0.0667942	valid_1&#39;s myFeval: 0.949174
[35400]	training&#39;s l1: 0.0367341	training&#39;s myFeval: 0.503419	valid_1&#39;s l1: 0.0667891	valid_1&#39;s myFeval: 0.949171
[35700]	training&#39;s l1: 0.0366825	training&#39;s myFeval: 0.502682	valid_1&#39;s l1: 0.0667822	valid_1&#39;s myFeval: 0.949115
[36000]	training&#39;s l1: 0.0366361	training&#39;s myFeval: 0.502022	valid_1&#39;s l1: 0.0667716	valid_1&#39;s myFeval: 0.949004
[36300]	training&#39;s l1: 0.0365846	training&#39;s myFeval: 0.501223	valid_1&#39;s l1: 0.0667641	valid_1&#39;s myFeval: 0.948826
[36600]	training&#39;s l1: 0.0365282	training&#39;s myFeval: 0.500418	valid_1&#39;s l1: 0.0667544	valid_1&#39;s myFeval: 0.948515
[36900]	training&#39;s l1: 0.0364812	training&#39;s myFeval: 0.499798	valid_1&#39;s l1: 0.0667482	valid_1&#39;s myFeval: 0.948381
[37200]	training&#39;s l1: 0.0364389	training&#39;s myFeval: 0.499226	valid_1&#39;s l1: 0.066741	valid_1&#39;s myFeval: 0.948296
[37500]	training&#39;s l1: 0.0363977	training&#39;s myFeval: 0.49873	valid_1&#39;s l1: 0.0667359	valid_1&#39;s myFeval: 0.948254
[37800]	training&#39;s l1: 0.0363496	training&#39;s myFeval: 0.498039	valid_1&#39;s l1: 0.0667268	valid_1&#39;s myFeval: 0.948046
[38100]	training&#39;s l1: 0.0363087	training&#39;s myFeval: 0.497317	valid_1&#39;s l1: 0.0667212	valid_1&#39;s myFeval: 0.947912
[38400]	training&#39;s l1: 0.0362669	training&#39;s myFeval: 0.49671	valid_1&#39;s l1: 0.0667134	valid_1&#39;s myFeval: 0.94782
[38700]	training&#39;s l1: 0.0362252	training&#39;s myFeval: 0.496109	valid_1&#39;s l1: 0.0667098	valid_1&#39;s myFeval: 0.94772
[39000]	training&#39;s l1: 0.0361798	training&#39;s myFeval: 0.495393	valid_1&#39;s l1: 0.0667031	valid_1&#39;s myFeval: 0.947549
[39300]	training&#39;s l1: 0.0361368	training&#39;s myFeval: 0.494563	valid_1&#39;s l1: 0.0666966	valid_1&#39;s myFeval: 0.947397
[39600]	training&#39;s l1: 0.0360944	training&#39;s myFeval: 0.4939	valid_1&#39;s l1: 0.0666904	valid_1&#39;s myFeval: 0.947256
[39900]	training&#39;s l1: 0.0360504	training&#39;s myFeval: 0.493234	valid_1&#39;s l1: 0.0666937	valid_1&#39;s myFeval: 0.947311
[40200]	training&#39;s l1: 0.0360181	training&#39;s myFeval: 0.492717	valid_1&#39;s l1: 0.0666911	valid_1&#39;s myFeval: 0.947224
[40500]	training&#39;s l1: 0.0359798	training&#39;s myFeval: 0.492169	valid_1&#39;s l1: 0.0666861	valid_1&#39;s myFeval: 0.947123
[40800]	training&#39;s l1: 0.0359449	training&#39;s myFeval: 0.491731	valid_1&#39;s l1: 0.0666785	valid_1&#39;s myFeval: 0.947
[41100]	training&#39;s l1: 0.0358992	training&#39;s myFeval: 0.491107	valid_1&#39;s l1: 0.0666738	valid_1&#39;s myFeval: 0.946901
[41400]	training&#39;s l1: 0.035838	training&#39;s myFeval: 0.490268	valid_1&#39;s l1: 0.0666798	valid_1&#39;s myFeval: 0.94697
[41700]	training&#39;s l1: 0.0357962	training&#39;s myFeval: 0.489683	valid_1&#39;s l1: 0.0666707	valid_1&#39;s myFeval: 0.946869
[42000]	training&#39;s l1: 0.0357562	training&#39;s myFeval: 0.489125	valid_1&#39;s l1: 0.0666682	valid_1&#39;s myFeval: 0.94679
[42300]	training&#39;s l1: 0.035718	training&#39;s myFeval: 0.48855	valid_1&#39;s l1: 0.0666668	valid_1&#39;s myFeval: 0.946724
[42600]	training&#39;s l1: 0.0356777	training&#39;s myFeval: 0.487973	valid_1&#39;s l1: 0.0666587	valid_1&#39;s myFeval: 0.946609
[42900]	training&#39;s l1: 0.0356326	training&#39;s myFeval: 0.487339	valid_1&#39;s l1: 0.0666513	valid_1&#39;s myFeval: 0.946468
[43200]	training&#39;s l1: 0.0355913	training&#39;s myFeval: 0.486798	valid_1&#39;s l1: 0.0666489	valid_1&#39;s myFeval: 0.946427
[43500]	training&#39;s l1: 0.0355289	training&#39;s myFeval: 0.486113	valid_1&#39;s l1: 0.0666305	valid_1&#39;s myFeval: 0.946322
[43800]	training&#39;s l1: 0.0354753	training&#39;s myFeval: 0.48554	valid_1&#39;s l1: 0.0666226	valid_1&#39;s myFeval: 0.946199
[44100]	training&#39;s l1: 0.0354346	training&#39;s myFeval: 0.48502	valid_1&#39;s l1: 0.0666233	valid_1&#39;s myFeval: 0.946054
[44400]	training&#39;s l1: 0.0354001	training&#39;s myFeval: 0.484561	valid_1&#39;s l1: 0.0666191	valid_1&#39;s myFeval: 0.945971
[44700]	training&#39;s l1: 0.0353628	training&#39;s myFeval: 0.48405	valid_1&#39;s l1: 0.0666126	valid_1&#39;s myFeval: 0.94586
[45000]	training&#39;s l1: 0.0353248	training&#39;s myFeval: 0.483497	valid_1&#39;s l1: 0.066608	valid_1&#39;s myFeval: 0.945727
[45300]	training&#39;s l1: 0.035287	training&#39;s myFeval: 0.483026	valid_1&#39;s l1: 0.0666025	valid_1&#39;s myFeval: 0.945651
[45600]	training&#39;s l1: 0.0352508	training&#39;s myFeval: 0.482561	valid_1&#39;s l1: 0.066601	valid_1&#39;s myFeval: 0.94559
[45900]	training&#39;s l1: 0.0352132	training&#39;s myFeval: 0.482079	valid_1&#39;s l1: 0.0665952	valid_1&#39;s myFeval: 0.945494
[46200]	training&#39;s l1: 0.0351832	training&#39;s myFeval: 0.481704	valid_1&#39;s l1: 0.0665911	valid_1&#39;s myFeval: 0.945414
[46500]	training&#39;s l1: 0.0351374	training&#39;s myFeval: 0.481168	valid_1&#39;s l1: 0.066584	valid_1&#39;s myFeval: 0.945358
[46800]	training&#39;s l1: 0.035098	training&#39;s myFeval: 0.480717	valid_1&#39;s l1: 0.0665746	valid_1&#39;s myFeval: 0.945173
[47100]	training&#39;s l1: 0.0350539	training&#39;s myFeval: 0.48023	valid_1&#39;s l1: 0.0665662	valid_1&#39;s myFeval: 0.945085
[47400]	training&#39;s l1: 0.0350183	training&#39;s myFeval: 0.479734	valid_1&#39;s l1: 0.066567	valid_1&#39;s myFeval: 0.945077
[47700]	training&#39;s l1: 0.0349326	training&#39;s myFeval: 0.478716	valid_1&#39;s l1: 0.0665949	valid_1&#39;s myFeval: 0.945321
Early stopping, best iteration is:
[47335]	training&#39;s l1: 0.0350288	training&#39;s myFeval: 0.479872	valid_1&#39;s l1: 0.0665657	valid_1&#39;s myFeval: 0.945051
fold n°8
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008545 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9907
[LightGBM] [Info] Number of data points in the train set: 26617, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.424803
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.111793	training&#39;s myFeval: 2.05905	valid_1&#39;s l1: 0.110706	valid_1&#39;s myFeval: 1.99172
[600]	training&#39;s l1: 0.0791654	training&#39;s myFeval: 1.27203	valid_1&#39;s l1: 0.0819999	valid_1&#39;s myFeval: 1.27678
[900]	training&#39;s l1: 0.0718616	training&#39;s myFeval: 1.0756	valid_1&#39;s l1: 0.0768208	valid_1&#39;s myFeval: 1.14423
[1200]	training&#39;s l1: 0.0680316	training&#39;s myFeval: 0.999394	valid_1&#39;s l1: 0.0744375	valid_1&#39;s myFeval: 1.09907
[1500]	training&#39;s l1: 0.0653233	training&#39;s myFeval: 0.949662	valid_1&#39;s l1: 0.0730168	valid_1&#39;s myFeval: 1.0689
[1800]	training&#39;s l1: 0.0631712	training&#39;s myFeval: 0.911417	valid_1&#39;s l1: 0.071981	valid_1&#39;s myFeval: 1.04694
[2100]	training&#39;s l1: 0.0613367	training&#39;s myFeval: 0.8801	valid_1&#39;s l1: 0.0711265	valid_1&#39;s myFeval: 1.02958
[2400]	training&#39;s l1: 0.0597553	training&#39;s myFeval: 0.853819	valid_1&#39;s l1: 0.0704121	valid_1&#39;s myFeval: 1.01598
[2700]	training&#39;s l1: 0.0583719	training&#39;s myFeval: 0.831038	valid_1&#39;s l1: 0.0698921	valid_1&#39;s myFeval: 1.00656
[3000]	training&#39;s l1: 0.0571093	training&#39;s myFeval: 0.811764	valid_1&#39;s l1: 0.0694292	valid_1&#39;s myFeval: 0.998802
[3300]	training&#39;s l1: 0.0560053	training&#39;s myFeval: 0.794105	valid_1&#39;s l1: 0.0690829	valid_1&#39;s myFeval: 0.992506
[3600]	training&#39;s l1: 0.0550137	training&#39;s myFeval: 0.77871	valid_1&#39;s l1: 0.0687713	valid_1&#39;s myFeval: 0.987421
[3900]	training&#39;s l1: 0.0541313	training&#39;s myFeval: 0.765016	valid_1&#39;s l1: 0.0685059	valid_1&#39;s myFeval: 0.983001
[4200]	training&#39;s l1: 0.0533206	training&#39;s myFeval: 0.751706	valid_1&#39;s l1: 0.0682505	valid_1&#39;s myFeval: 0.978767
[4500]	training&#39;s l1: 0.0525823	training&#39;s myFeval: 0.740364	valid_1&#39;s l1: 0.0680032	valid_1&#39;s myFeval: 0.974536
[4800]	training&#39;s l1: 0.0518907	training&#39;s myFeval: 0.729857	valid_1&#39;s l1: 0.0677999	valid_1&#39;s myFeval: 0.971438
[5100]	training&#39;s l1: 0.0512573	training&#39;s myFeval: 0.720368	valid_1&#39;s l1: 0.0676487	valid_1&#39;s myFeval: 0.969344
[5400]	training&#39;s l1: 0.0506511	training&#39;s myFeval: 0.711158	valid_1&#39;s l1: 0.0675016	valid_1&#39;s myFeval: 0.966836
[5700]	training&#39;s l1: 0.0500909	training&#39;s myFeval: 0.70274	valid_1&#39;s l1: 0.0673462	valid_1&#39;s myFeval: 0.964321
[6000]	training&#39;s l1: 0.0495566	training&#39;s myFeval: 0.694669	valid_1&#39;s l1: 0.0672242	valid_1&#39;s myFeval: 0.962259
[6300]	training&#39;s l1: 0.0490727	training&#39;s myFeval: 0.687442	valid_1&#39;s l1: 0.0670946	valid_1&#39;s myFeval: 0.960144
[6600]	training&#39;s l1: 0.0486081	training&#39;s myFeval: 0.679908	valid_1&#39;s l1: 0.0670003	valid_1&#39;s myFeval: 0.958713
[6900]	training&#39;s l1: 0.0481882	training&#39;s myFeval: 0.673186	valid_1&#39;s l1: 0.0668959	valid_1&#39;s myFeval: 0.957183
[7200]	training&#39;s l1: 0.0477902	training&#39;s myFeval: 0.666847	valid_1&#39;s l1: 0.0667873	valid_1&#39;s myFeval: 0.955352
[7500]	training&#39;s l1: 0.0474346	training&#39;s myFeval: 0.661376	valid_1&#39;s l1: 0.0667092	valid_1&#39;s myFeval: 0.954046
[7800]	training&#39;s l1: 0.0470925	training&#39;s myFeval: 0.654999	valid_1&#39;s l1: 0.0666189	valid_1&#39;s myFeval: 0.952369
[8100]	training&#39;s l1: 0.0467856	training&#39;s myFeval: 0.650077	valid_1&#39;s l1: 0.0665264	valid_1&#39;s myFeval: 0.951101
[8400]	training&#39;s l1: 0.046481	training&#39;s myFeval: 0.644875	valid_1&#39;s l1: 0.0664563	valid_1&#39;s myFeval: 0.950013
[8700]	training&#39;s l1: 0.0461765	training&#39;s myFeval: 0.639904	valid_1&#39;s l1: 0.0664	valid_1&#39;s myFeval: 0.948924
[9000]	training&#39;s l1: 0.0458998	training&#39;s myFeval: 0.6357	valid_1&#39;s l1: 0.0663228	valid_1&#39;s myFeval: 0.947736
[9300]	training&#39;s l1: 0.0456172	training&#39;s myFeval: 0.631285	valid_1&#39;s l1: 0.0662661	valid_1&#39;s myFeval: 0.946653
[9600]	training&#39;s l1: 0.0453934	training&#39;s myFeval: 0.627862	valid_1&#39;s l1: 0.0662076	valid_1&#39;s myFeval: 0.945888
[9900]	training&#39;s l1: 0.0451478	training&#39;s myFeval: 0.624482	valid_1&#39;s l1: 0.0661407	valid_1&#39;s myFeval: 0.944797
[10200]	training&#39;s l1: 0.0449367	training&#39;s myFeval: 0.621839	valid_1&#39;s l1: 0.0660964	valid_1&#39;s myFeval: 0.944115
[10500]	training&#39;s l1: 0.0446987	training&#39;s myFeval: 0.618249	valid_1&#39;s l1: 0.0660402	valid_1&#39;s myFeval: 0.943103
[10800]	training&#39;s l1: 0.0444697	training&#39;s myFeval: 0.614767	valid_1&#39;s l1: 0.0659796	valid_1&#39;s myFeval: 0.942067
[11100]	training&#39;s l1: 0.0442845	training&#39;s myFeval: 0.611962	valid_1&#39;s l1: 0.0659444	valid_1&#39;s myFeval: 0.941305
[11400]	training&#39;s l1: 0.0441184	training&#39;s myFeval: 0.609608	valid_1&#39;s l1: 0.065917	valid_1&#39;s myFeval: 0.94071
[11700]	training&#39;s l1: 0.0439332	training&#39;s myFeval: 0.606766	valid_1&#39;s l1: 0.0658808	valid_1&#39;s myFeval: 0.940082
[12000]	training&#39;s l1: 0.0437665	training&#39;s myFeval: 0.604165	valid_1&#39;s l1: 0.0658507	valid_1&#39;s myFeval: 0.939549
[12300]	training&#39;s l1: 0.0436079	training&#39;s myFeval: 0.601617	valid_1&#39;s l1: 0.0658136	valid_1&#39;s myFeval: 0.939014
[12600]	training&#39;s l1: 0.0434297	training&#39;s myFeval: 0.598958	valid_1&#39;s l1: 0.0657776	valid_1&#39;s myFeval: 0.938413
[12900]	training&#39;s l1: 0.0432553	training&#39;s myFeval: 0.596325	valid_1&#39;s l1: 0.0657403	valid_1&#39;s myFeval: 0.9377
[13200]	training&#39;s l1: 0.0431172	training&#39;s myFeval: 0.594644	valid_1&#39;s l1: 0.0657014	valid_1&#39;s myFeval: 0.937292
[13500]	training&#39;s l1: 0.0429861	training&#39;s myFeval: 0.593119	valid_1&#39;s l1: 0.0656731	valid_1&#39;s myFeval: 0.936917
[13800]	training&#39;s l1: 0.0428192	training&#39;s myFeval: 0.590832	valid_1&#39;s l1: 0.0656455	valid_1&#39;s myFeval: 0.936481
[14100]	training&#39;s l1: 0.0426668	training&#39;s myFeval: 0.588574	valid_1&#39;s l1: 0.0656186	valid_1&#39;s myFeval: 0.935912
[14400]	training&#39;s l1: 0.0425475	training&#39;s myFeval: 0.586712	valid_1&#39;s l1: 0.0655773	valid_1&#39;s myFeval: 0.935344
[14700]	training&#39;s l1: 0.0424274	training&#39;s myFeval: 0.584897	valid_1&#39;s l1: 0.0655461	valid_1&#39;s myFeval: 0.934858
[15000]	training&#39;s l1: 0.0422869	training&#39;s myFeval: 0.582955	valid_1&#39;s l1: 0.0655243	valid_1&#39;s myFeval: 0.934465
[15300]	training&#39;s l1: 0.0421216	training&#39;s myFeval: 0.58079	valid_1&#39;s l1: 0.0654886	valid_1&#39;s myFeval: 0.933817
[15600]	training&#39;s l1: 0.0419729	training&#39;s myFeval: 0.578549	valid_1&#39;s l1: 0.0654551	valid_1&#39;s myFeval: 0.933159
[15900]	training&#39;s l1: 0.0418525	training&#39;s myFeval: 0.576809	valid_1&#39;s l1: 0.0654283	valid_1&#39;s myFeval: 0.932723
[16200]	training&#39;s l1: 0.0417323	training&#39;s myFeval: 0.575062	valid_1&#39;s l1: 0.0654025	valid_1&#39;s myFeval: 0.932307
[16500]	training&#39;s l1: 0.041619	training&#39;s myFeval: 0.573475	valid_1&#39;s l1: 0.065379	valid_1&#39;s myFeval: 0.931895
[16800]	training&#39;s l1: 0.0414538	training&#39;s myFeval: 0.571069	valid_1&#39;s l1: 0.0653522	valid_1&#39;s myFeval: 0.931338
[17100]	training&#39;s l1: 0.0412585	training&#39;s myFeval: 0.568117	valid_1&#39;s l1: 0.0653354	valid_1&#39;s myFeval: 0.930717
[17400]	training&#39;s l1: 0.0411265	training&#39;s myFeval: 0.566229	valid_1&#39;s l1: 0.0653095	valid_1&#39;s myFeval: 0.93026
[17700]	training&#39;s l1: 0.0410186	training&#39;s myFeval: 0.564653	valid_1&#39;s l1: 0.0652869	valid_1&#39;s myFeval: 0.92992
[18000]	training&#39;s l1: 0.0408968	training&#39;s myFeval: 0.562855	valid_1&#39;s l1: 0.0652597	valid_1&#39;s myFeval: 0.929506
[18300]	training&#39;s l1: 0.0407706	training&#39;s myFeval: 0.561153	valid_1&#39;s l1: 0.0652388	valid_1&#39;s myFeval: 0.929123
[18600]	training&#39;s l1: 0.0406602	training&#39;s myFeval: 0.559606	valid_1&#39;s l1: 0.06522	valid_1&#39;s myFeval: 0.928834
[18900]	training&#39;s l1: 0.0405577	training&#39;s myFeval: 0.558055	valid_1&#39;s l1: 0.0652072	valid_1&#39;s myFeval: 0.928573
[19200]	training&#39;s l1: 0.0404502	training&#39;s myFeval: 0.556508	valid_1&#39;s l1: 0.0651896	valid_1&#39;s myFeval: 0.928208
[19500]	training&#39;s l1: 0.0403697	training&#39;s myFeval: 0.555376	valid_1&#39;s l1: 0.0651704	valid_1&#39;s myFeval: 0.927889
[19800]	training&#39;s l1: 0.0402753	training&#39;s myFeval: 0.554315	valid_1&#39;s l1: 0.0651445	valid_1&#39;s myFeval: 0.927606
[20100]	training&#39;s l1: 0.0401791	training&#39;s myFeval: 0.553284	valid_1&#39;s l1: 0.0651151	valid_1&#39;s myFeval: 0.927279
[20400]	training&#39;s l1: 0.0400768	training&#39;s myFeval: 0.552072	valid_1&#39;s l1: 0.0650913	valid_1&#39;s myFeval: 0.926974
[20700]	training&#39;s l1: 0.0399799	training&#39;s myFeval: 0.550684	valid_1&#39;s l1: 0.0650717	valid_1&#39;s myFeval: 0.926631
[21000]	training&#39;s l1: 0.0398879	training&#39;s myFeval: 0.549374	valid_1&#39;s l1: 0.0650599	valid_1&#39;s myFeval: 0.92641
[21300]	training&#39;s l1: 0.0397967	training&#39;s myFeval: 0.548113	valid_1&#39;s l1: 0.0650377	valid_1&#39;s myFeval: 0.92605
[21600]	training&#39;s l1: 0.0397001	training&#39;s myFeval: 0.546795	valid_1&#39;s l1: 0.0650238	valid_1&#39;s myFeval: 0.92584
[21900]	training&#39;s l1: 0.0396004	training&#39;s myFeval: 0.545596	valid_1&#39;s l1: 0.0650119	valid_1&#39;s myFeval: 0.92552
[22200]	training&#39;s l1: 0.0395098	training&#39;s myFeval: 0.544283	valid_1&#39;s l1: 0.0649969	valid_1&#39;s myFeval: 0.92525
[22500]	training&#39;s l1: 0.0394167	training&#39;s myFeval: 0.54296	valid_1&#39;s l1: 0.0649808	valid_1&#39;s myFeval: 0.924957
[22800]	training&#39;s l1: 0.0393365	training&#39;s myFeval: 0.541772	valid_1&#39;s l1: 0.0649619	valid_1&#39;s myFeval: 0.924601
[23100]	training&#39;s l1: 0.0392488	training&#39;s myFeval: 0.540521	valid_1&#39;s l1: 0.0649476	valid_1&#39;s myFeval: 0.924347
[23400]	training&#39;s l1: 0.0391683	training&#39;s myFeval: 0.539401	valid_1&#39;s l1: 0.0649349	valid_1&#39;s myFeval: 0.924187
[23700]	training&#39;s l1: 0.03909	training&#39;s myFeval: 0.538304	valid_1&#39;s l1: 0.0649195	valid_1&#39;s myFeval: 0.923953
[24000]	training&#39;s l1: 0.039011	training&#39;s myFeval: 0.537186	valid_1&#39;s l1: 0.0649123	valid_1&#39;s myFeval: 0.923871
[24300]	training&#39;s l1: 0.0389385	training&#39;s myFeval: 0.536177	valid_1&#39;s l1: 0.0649026	valid_1&#39;s myFeval: 0.923647
[24600]	training&#39;s l1: 0.0388766	training&#39;s myFeval: 0.535332	valid_1&#39;s l1: 0.0648904	valid_1&#39;s myFeval: 0.92343
[24900]	training&#39;s l1: 0.0388089	training&#39;s myFeval: 0.534342	valid_1&#39;s l1: 0.0648827	valid_1&#39;s myFeval: 0.923227
[25200]	training&#39;s l1: 0.0387362	training&#39;s myFeval: 0.533327	valid_1&#39;s l1: 0.0648687	valid_1&#39;s myFeval: 0.922909
[25500]	training&#39;s l1: 0.0386747	training&#39;s myFeval: 0.532283	valid_1&#39;s l1: 0.0648678	valid_1&#39;s myFeval: 0.922962
[25800]	training&#39;s l1: 0.0386026	training&#39;s myFeval: 0.531239	valid_1&#39;s l1: 0.064857	valid_1&#39;s myFeval: 0.922709
[26100]	training&#39;s l1: 0.0385331	training&#39;s myFeval: 0.530375	valid_1&#39;s l1: 0.0648461	valid_1&#39;s myFeval: 0.922566
[26400]	training&#39;s l1: 0.0384532	training&#39;s myFeval: 0.529459	valid_1&#39;s l1: 0.064837	valid_1&#39;s myFeval: 0.922393
[26700]	training&#39;s l1: 0.0383854	training&#39;s myFeval: 0.52865	valid_1&#39;s l1: 0.0648301	valid_1&#39;s myFeval: 0.922289
[27000]	training&#39;s l1: 0.0383056	training&#39;s myFeval: 0.527785	valid_1&#39;s l1: 0.0648125	valid_1&#39;s myFeval: 0.92213
[27300]	training&#39;s l1: 0.0382344	training&#39;s myFeval: 0.526948	valid_1&#39;s l1: 0.0648026	valid_1&#39;s myFeval: 0.922061
[27600]	training&#39;s l1: 0.0381744	training&#39;s myFeval: 0.526253	valid_1&#39;s l1: 0.0647941	valid_1&#39;s myFeval: 0.921921
[27900]	training&#39;s l1: 0.0381202	training&#39;s myFeval: 0.525376	valid_1&#39;s l1: 0.0647867	valid_1&#39;s myFeval: 0.921769
[28200]	training&#39;s l1: 0.0380711	training&#39;s myFeval: 0.524451	valid_1&#39;s l1: 0.0647776	valid_1&#39;s myFeval: 0.921528
[28500]	training&#39;s l1: 0.0380134	training&#39;s myFeval: 0.523604	valid_1&#39;s l1: 0.0647673	valid_1&#39;s myFeval: 0.921329
[28800]	training&#39;s l1: 0.0379503	training&#39;s myFeval: 0.522715	valid_1&#39;s l1: 0.0647626	valid_1&#39;s myFeval: 0.92121
[29100]	training&#39;s l1: 0.0378976	training&#39;s myFeval: 0.521987	valid_1&#39;s l1: 0.0647611	valid_1&#39;s myFeval: 0.921167
[29400]	training&#39;s l1: 0.0378519	training&#39;s myFeval: 0.521467	valid_1&#39;s l1: 0.0647542	valid_1&#39;s myFeval: 0.921012
[29700]	training&#39;s l1: 0.0377902	training&#39;s myFeval: 0.520669	valid_1&#39;s l1: 0.0647414	valid_1&#39;s myFeval: 0.920893
[30000]	training&#39;s l1: 0.0376985	training&#39;s myFeval: 0.519428	valid_1&#39;s l1: 0.0647397	valid_1&#39;s myFeval: 0.920828
[30300]	training&#39;s l1: 0.0376339	training&#39;s myFeval: 0.518547	valid_1&#39;s l1: 0.0647331	valid_1&#39;s myFeval: 0.920687
[30600]	training&#39;s l1: 0.0375788	training&#39;s myFeval: 0.517814	valid_1&#39;s l1: 0.0647285	valid_1&#39;s myFeval: 0.920495
[30900]	training&#39;s l1: 0.0375282	training&#39;s myFeval: 0.516974	valid_1&#39;s l1: 0.0647181	valid_1&#39;s myFeval: 0.920091
[31200]	training&#39;s l1: 0.0374716	training&#39;s myFeval: 0.51606	valid_1&#39;s l1: 0.0647102	valid_1&#39;s myFeval: 0.919873
[31500]	training&#39;s l1: 0.037415	training&#39;s myFeval: 0.515244	valid_1&#39;s l1: 0.0647036	valid_1&#39;s myFeval: 0.919648
[31800]	training&#39;s l1: 0.037349	training&#39;s myFeval: 0.514355	valid_1&#39;s l1: 0.0646969	valid_1&#39;s myFeval: 0.919513
[32100]	training&#39;s l1: 0.0372957	training&#39;s myFeval: 0.513698	valid_1&#39;s l1: 0.0646915	valid_1&#39;s myFeval: 0.91946
[32400]	training&#39;s l1: 0.0372468	training&#39;s myFeval: 0.512972	valid_1&#39;s l1: 0.0646822	valid_1&#39;s myFeval: 0.919352
[32700]	training&#39;s l1: 0.0372105	training&#39;s myFeval: 0.51232	valid_1&#39;s l1: 0.064679	valid_1&#39;s myFeval: 0.919222
[33000]	training&#39;s l1: 0.0371729	training&#39;s myFeval: 0.511703	valid_1&#39;s l1: 0.0646737	valid_1&#39;s myFeval: 0.919138
[33300]	training&#39;s l1: 0.0371168	training&#39;s myFeval: 0.510828	valid_1&#39;s l1: 0.064667	valid_1&#39;s myFeval: 0.91905
[33600]	training&#39;s l1: 0.0370587	training&#39;s myFeval: 0.510056	valid_1&#39;s l1: 0.0646639	valid_1&#39;s myFeval: 0.919015
[33900]	training&#39;s l1: 0.0370002	training&#39;s myFeval: 0.5092	valid_1&#39;s l1: 0.0646544	valid_1&#39;s myFeval: 0.918799
[34200]	training&#39;s l1: 0.0369509	training&#39;s myFeval: 0.508505	valid_1&#39;s l1: 0.064649	valid_1&#39;s myFeval: 0.918713
[34500]	training&#39;s l1: 0.0369043	training&#39;s myFeval: 0.507923	valid_1&#39;s l1: 0.0646383	valid_1&#39;s myFeval: 0.918602
[34800]	training&#39;s l1: 0.0368599	training&#39;s myFeval: 0.507293	valid_1&#39;s l1: 0.0646269	valid_1&#39;s myFeval: 0.918359
[35100]	training&#39;s l1: 0.0368107	training&#39;s myFeval: 0.506556	valid_1&#39;s l1: 0.0646169	valid_1&#39;s myFeval: 0.918195
[35400]	training&#39;s l1: 0.0367481	training&#39;s myFeval: 0.505706	valid_1&#39;s l1: 0.0646027	valid_1&#39;s myFeval: 0.917873
[35700]	training&#39;s l1: 0.0366975	training&#39;s myFeval: 0.504986	valid_1&#39;s l1: 0.064595	valid_1&#39;s myFeval: 0.917733
[36000]	training&#39;s l1: 0.0366463	training&#39;s myFeval: 0.50414	valid_1&#39;s l1: 0.0645842	valid_1&#39;s myFeval: 0.917619
[36300]	training&#39;s l1: 0.0365928	training&#39;s myFeval: 0.503066	valid_1&#39;s l1: 0.0645678	valid_1&#39;s myFeval: 0.91725
[36600]	training&#39;s l1: 0.0365462	training&#39;s myFeval: 0.502129	valid_1&#39;s l1: 0.0645544	valid_1&#39;s myFeval: 0.916989
[36900]	training&#39;s l1: 0.0364981	training&#39;s myFeval: 0.501316	valid_1&#39;s l1: 0.0645473	valid_1&#39;s myFeval: 0.916789
[37200]	training&#39;s l1: 0.0364572	training&#39;s myFeval: 0.500763	valid_1&#39;s l1: 0.0645427	valid_1&#39;s myFeval: 0.916632
[37500]	training&#39;s l1: 0.0363946	training&#39;s myFeval: 0.500147	valid_1&#39;s l1: 0.0645351	valid_1&#39;s myFeval: 0.91644
[37800]	training&#39;s l1: 0.0363377	training&#39;s myFeval: 0.499579	valid_1&#39;s l1: 0.064527	valid_1&#39;s myFeval: 0.916319
[38100]	training&#39;s l1: 0.0362857	training&#39;s myFeval: 0.499046	valid_1&#39;s l1: 0.0645268	valid_1&#39;s myFeval: 0.916267
[38400]	training&#39;s l1: 0.0362419	training&#39;s myFeval: 0.498456	valid_1&#39;s l1: 0.0645207	valid_1&#39;s myFeval: 0.916145
[38700]	training&#39;s l1: 0.0361749	training&#39;s myFeval: 0.497625	valid_1&#39;s l1: 0.0645053	valid_1&#39;s myFeval: 0.915862
[39000]	training&#39;s l1: 0.036121	training&#39;s myFeval: 0.496957	valid_1&#39;s l1: 0.064493	valid_1&#39;s myFeval: 0.915669
[39300]	training&#39;s l1: 0.0360734	training&#39;s myFeval: 0.496397	valid_1&#39;s l1: 0.0644828	valid_1&#39;s myFeval: 0.915492
[39600]	training&#39;s l1: 0.0360279	training&#39;s myFeval: 0.495781	valid_1&#39;s l1: 0.0644826	valid_1&#39;s myFeval: 0.915391
[39900]	training&#39;s l1: 0.0359882	training&#39;s myFeval: 0.495218	valid_1&#39;s l1: 0.0644809	valid_1&#39;s myFeval: 0.915356
[40200]	training&#39;s l1: 0.0359486	training&#39;s myFeval: 0.494596	valid_1&#39;s l1: 0.0644753	valid_1&#39;s myFeval: 0.915233
[40500]	training&#39;s l1: 0.0359094	training&#39;s myFeval: 0.493951	valid_1&#39;s l1: 0.0644703	valid_1&#39;s myFeval: 0.915055
[40800]	training&#39;s l1: 0.0358691	training&#39;s myFeval: 0.493396	valid_1&#39;s l1: 0.0644607	valid_1&#39;s myFeval: 0.914915
[41100]	training&#39;s l1: 0.0358311	training&#39;s myFeval: 0.492868	valid_1&#39;s l1: 0.0644571	valid_1&#39;s myFeval: 0.914816
[41400]	training&#39;s l1: 0.0357877	training&#39;s myFeval: 0.492292	valid_1&#39;s l1: 0.06445	valid_1&#39;s myFeval: 0.914664
[41700]	training&#39;s l1: 0.0357474	training&#39;s myFeval: 0.491686	valid_1&#39;s l1: 0.0644445	valid_1&#39;s myFeval: 0.914581
[42000]	training&#39;s l1: 0.035717	training&#39;s myFeval: 0.491286	valid_1&#39;s l1: 0.0644429	valid_1&#39;s myFeval: 0.914532
[42300]	training&#39;s l1: 0.0356809	training&#39;s myFeval: 0.490802	valid_1&#39;s l1: 0.0644399	valid_1&#39;s myFeval: 0.914465
[42600]	training&#39;s l1: 0.0356508	training&#39;s myFeval: 0.490337	valid_1&#39;s l1: 0.0644356	valid_1&#39;s myFeval: 0.914378
[42900]	training&#39;s l1: 0.0356195	training&#39;s myFeval: 0.489818	valid_1&#39;s l1: 0.0644348	valid_1&#39;s myFeval: 0.914331
[43200]	training&#39;s l1: 0.0355856	training&#39;s myFeval: 0.489311	valid_1&#39;s l1: 0.0644308	valid_1&#39;s myFeval: 0.914288
[43500]	training&#39;s l1: 0.0355499	training&#39;s myFeval: 0.488777	valid_1&#39;s l1: 0.0644261	valid_1&#39;s myFeval: 0.914209
[43800]	training&#39;s l1: 0.0355147	training&#39;s myFeval: 0.488294	valid_1&#39;s l1: 0.0644216	valid_1&#39;s myFeval: 0.914119
[44100]	training&#39;s l1: 0.0354697	training&#39;s myFeval: 0.487713	valid_1&#39;s l1: 0.0644128	valid_1&#39;s myFeval: 0.913977
[44400]	training&#39;s l1: 0.0354308	training&#39;s myFeval: 0.487179	valid_1&#39;s l1: 0.0644124	valid_1&#39;s myFeval: 0.913905
[44700]	training&#39;s l1: 0.0353955	training&#39;s myFeval: 0.486731	valid_1&#39;s l1: 0.0644081	valid_1&#39;s myFeval: 0.913854
[45000]	training&#39;s l1: 0.0353617	training&#39;s myFeval: 0.486311	valid_1&#39;s l1: 0.0644049	valid_1&#39;s myFeval: 0.913796
[45300]	training&#39;s l1: 0.0353202	training&#39;s myFeval: 0.485774	valid_1&#39;s l1: 0.0643928	valid_1&#39;s myFeval: 0.913703
[45600]	training&#39;s l1: 0.03527	training&#39;s myFeval: 0.485126	valid_1&#39;s l1: 0.0643867	valid_1&#39;s myFeval: 0.913604
[45900]	training&#39;s l1: 0.0352047	training&#39;s myFeval: 0.484301	valid_1&#39;s l1: 0.0643771	valid_1&#39;s myFeval: 0.913518
[46200]	training&#39;s l1: 0.0351475	training&#39;s myFeval: 0.483576	valid_1&#39;s l1: 0.0643728	valid_1&#39;s myFeval: 0.913419
[46500]	training&#39;s l1: 0.035095	training&#39;s myFeval: 0.482936	valid_1&#39;s l1: 0.0643641	valid_1&#39;s myFeval: 0.913337
[46800]	training&#39;s l1: 0.0350555	training&#39;s myFeval: 0.482436	valid_1&#39;s l1: 0.0643612	valid_1&#39;s myFeval: 0.913263
[47100]	training&#39;s l1: 0.0350167	training&#39;s myFeval: 0.481939	valid_1&#39;s l1: 0.0643498	valid_1&#39;s myFeval: 0.913119
[47400]	training&#39;s l1: 0.0349804	training&#39;s myFeval: 0.481428	valid_1&#39;s l1: 0.0643389	valid_1&#39;s myFeval: 0.912963
[47700]	training&#39;s l1: 0.03495	training&#39;s myFeval: 0.480973	valid_1&#39;s l1: 0.064335	valid_1&#39;s myFeval: 0.912885
[48000]	training&#39;s l1: 0.0349205	training&#39;s myFeval: 0.480573	valid_1&#39;s l1: 0.0643293	valid_1&#39;s myFeval: 0.912787
[48300]	training&#39;s l1: 0.0348928	training&#39;s myFeval: 0.480106	valid_1&#39;s l1: 0.0643248	valid_1&#39;s myFeval: 0.912659
[48600]	training&#39;s l1: 0.0348636	training&#39;s myFeval: 0.479676	valid_1&#39;s l1: 0.0643208	valid_1&#39;s myFeval: 0.912587
[48900]	training&#39;s l1: 0.0348364	training&#39;s myFeval: 0.479271	valid_1&#39;s l1: 0.0643164	valid_1&#39;s myFeval: 0.912487
[49200]	training&#39;s l1: 0.0348081	training&#39;s myFeval: 0.478857	valid_1&#39;s l1: 0.0643134	valid_1&#39;s myFeval: 0.912388
[49500]	training&#39;s l1: 0.0347823	training&#39;s myFeval: 0.478491	valid_1&#39;s l1: 0.064312	valid_1&#39;s myFeval: 0.912365
[49800]	training&#39;s l1: 0.0347555	training&#39;s myFeval: 0.4781	valid_1&#39;s l1: 0.0643102	valid_1&#39;s myFeval: 0.912277
[50100]	training&#39;s l1: 0.0347253	training&#39;s myFeval: 0.477685	valid_1&#39;s l1: 0.0643071	valid_1&#39;s myFeval: 0.912214
[50400]	training&#39;s l1: 0.0346708	training&#39;s myFeval: 0.476952	valid_1&#39;s l1: 0.0643027	valid_1&#39;s myFeval: 0.912256
[50700]	training&#39;s l1: 0.0346329	training&#39;s myFeval: 0.476451	valid_1&#39;s l1: 0.0642985	valid_1&#39;s myFeval: 0.912149
[51000]	training&#39;s l1: 0.0345927	training&#39;s myFeval: 0.476008	valid_1&#39;s l1: 0.0642964	valid_1&#39;s myFeval: 0.912134
[51300]	training&#39;s l1: 0.034559	training&#39;s myFeval: 0.47567	valid_1&#39;s l1: 0.0642957	valid_1&#39;s myFeval: 0.912129
[51600]	training&#39;s l1: 0.0345239	training&#39;s myFeval: 0.475201	valid_1&#39;s l1: 0.0642897	valid_1&#39;s myFeval: 0.912042
[51900]	training&#39;s l1: 0.0344929	training&#39;s myFeval: 0.474776	valid_1&#39;s l1: 0.0642853	valid_1&#39;s myFeval: 0.911971
[52200]	training&#39;s l1: 0.0344617	training&#39;s myFeval: 0.47432	valid_1&#39;s l1: 0.0642839	valid_1&#39;s myFeval: 0.911923
[52500]	training&#39;s l1: 0.0344345	training&#39;s myFeval: 0.473892	valid_1&#39;s l1: 0.0642819	valid_1&#39;s myFeval: 0.911876
[52800]	training&#39;s l1: 0.0344089	training&#39;s myFeval: 0.473488	valid_1&#39;s l1: 0.0642807	valid_1&#39;s myFeval: 0.91177
[53100]	training&#39;s l1: 0.0343835	training&#39;s myFeval: 0.473131	valid_1&#39;s l1: 0.0642773	valid_1&#39;s myFeval: 0.9117
[53400]	training&#39;s l1: 0.034358	training&#39;s myFeval: 0.472776	valid_1&#39;s l1: 0.064276	valid_1&#39;s myFeval: 0.911652
[53700]	training&#39;s l1: 0.0343262	training&#39;s myFeval: 0.472319	valid_1&#39;s l1: 0.0642722	valid_1&#39;s myFeval: 0.911569
[54000]	training&#39;s l1: 0.0342957	training&#39;s myFeval: 0.471895	valid_1&#39;s l1: 0.0642685	valid_1&#39;s myFeval: 0.911504
[54300]	training&#39;s l1: 0.0342668	training&#39;s myFeval: 0.471489	valid_1&#39;s l1: 0.0642668	valid_1&#39;s myFeval: 0.911476
[54600]	training&#39;s l1: 0.0342405	training&#39;s myFeval: 0.471074	valid_1&#39;s l1: 0.0642637	valid_1&#39;s myFeval: 0.911402
[54900]	training&#39;s l1: 0.0342041	training&#39;s myFeval: 0.470605	valid_1&#39;s l1: 0.0642623	valid_1&#39;s myFeval: 0.911329
[55200]	training&#39;s l1: 0.0341684	training&#39;s myFeval: 0.470145	valid_1&#39;s l1: 0.0642599	valid_1&#39;s myFeval: 0.911304
[55500]	training&#39;s l1: 0.0341409	training&#39;s myFeval: 0.469753	valid_1&#39;s l1: 0.0642576	valid_1&#39;s myFeval: 0.911227
[55800]	training&#39;s l1: 0.0341174	training&#39;s myFeval: 0.46942	valid_1&#39;s l1: 0.064255	valid_1&#39;s myFeval: 0.911112
[56100]	training&#39;s l1: 0.0340938	training&#39;s myFeval: 0.469104	valid_1&#39;s l1: 0.0642523	valid_1&#39;s myFeval: 0.911074
[56400]	training&#39;s l1: 0.0340668	training&#39;s myFeval: 0.468741	valid_1&#39;s l1: 0.0642486	valid_1&#39;s myFeval: 0.911031
[56700]	training&#39;s l1: 0.0340431	training&#39;s myFeval: 0.468375	valid_1&#39;s l1: 0.0642457	valid_1&#39;s myFeval: 0.910968
[57000]	training&#39;s l1: 0.0340193	training&#39;s myFeval: 0.468004	valid_1&#39;s l1: 0.0642419	valid_1&#39;s myFeval: 0.910831
[57300]	training&#39;s l1: 0.0339969	training&#39;s myFeval: 0.467667	valid_1&#39;s l1: 0.0642395	valid_1&#39;s myFeval: 0.910747
[57600]	training&#39;s l1: 0.0339731	training&#39;s myFeval: 0.467319	valid_1&#39;s l1: 0.0642378	valid_1&#39;s myFeval: 0.9107
[57900]	training&#39;s l1: 0.0339466	training&#39;s myFeval: 0.466939	valid_1&#39;s l1: 0.0642356	valid_1&#39;s myFeval: 0.910652
[58200]	training&#39;s l1: 0.0339224	training&#39;s myFeval: 0.466567	valid_1&#39;s l1: 0.0642332	valid_1&#39;s myFeval: 0.910606
[58500]	training&#39;s l1: 0.0338963	training&#39;s myFeval: 0.466158	valid_1&#39;s l1: 0.0642267	valid_1&#39;s myFeval: 0.910399
[58800]	training&#39;s l1: 0.0338716	training&#39;s myFeval: 0.465843	valid_1&#39;s l1: 0.0642166	valid_1&#39;s myFeval: 0.910225
[59100]	training&#39;s l1: 0.0338401	training&#39;s myFeval: 0.46545	valid_1&#39;s l1: 0.0642115	valid_1&#39;s myFeval: 0.910123
[59400]	training&#39;s l1: 0.0338136	training&#39;s myFeval: 0.465099	valid_1&#39;s l1: 0.0642111	valid_1&#39;s myFeval: 0.910143
[59700]	training&#39;s l1: 0.0337871	training&#39;s myFeval: 0.464749	valid_1&#39;s l1: 0.0642062	valid_1&#39;s myFeval: 0.910003
[60000]	training&#39;s l1: 0.0337673	training&#39;s myFeval: 0.464475	valid_1&#39;s l1: 0.0642026	valid_1&#39;s myFeval: 0.909935
[60300]	training&#39;s l1: 0.0337475	training&#39;s myFeval: 0.464172	valid_1&#39;s l1: 0.0641978	valid_1&#39;s myFeval: 0.90986
[60600]	training&#39;s l1: 0.0337307	training&#39;s myFeval: 0.463851	valid_1&#39;s l1: 0.0641966	valid_1&#39;s myFeval: 0.909823
[60900]	training&#39;s l1: 0.0337073	training&#39;s myFeval: 0.463371	valid_1&#39;s l1: 0.064189	valid_1&#39;s myFeval: 0.909682
[61200]	training&#39;s l1: 0.0336857	training&#39;s myFeval: 0.463052	valid_1&#39;s l1: 0.0641842	valid_1&#39;s myFeval: 0.909592
[61500]	training&#39;s l1: 0.0336591	training&#39;s myFeval: 0.46268	valid_1&#39;s l1: 0.0641809	valid_1&#39;s myFeval: 0.909549
[61800]	training&#39;s l1: 0.0336297	training&#39;s myFeval: 0.462297	valid_1&#39;s l1: 0.0641761	valid_1&#39;s myFeval: 0.909519
[62100]	training&#39;s l1: 0.0336052	training&#39;s myFeval: 0.461987	valid_1&#39;s l1: 0.0641744	valid_1&#39;s myFeval: 0.909466
[62400]	training&#39;s l1: 0.0335832	training&#39;s myFeval: 0.461651	valid_1&#39;s l1: 0.0641716	valid_1&#39;s myFeval: 0.909406
[62700]	training&#39;s l1: 0.0335682	training&#39;s myFeval: 0.461397	valid_1&#39;s l1: 0.0641734	valid_1&#39;s myFeval: 0.909409
[63000]	training&#39;s l1: 0.0335506	training&#39;s myFeval: 0.461108	valid_1&#39;s l1: 0.0641711	valid_1&#39;s myFeval: 0.90933
[63300]	training&#39;s l1: 0.0335287	training&#39;s myFeval: 0.460779	valid_1&#39;s l1: 0.0641666	valid_1&#39;s myFeval: 0.909225
[63600]	training&#39;s l1: 0.0335077	training&#39;s myFeval: 0.460482	valid_1&#39;s l1: 0.0641611	valid_1&#39;s myFeval: 0.909154
[63900]	training&#39;s l1: 0.0334872	training&#39;s myFeval: 0.460182	valid_1&#39;s l1: 0.0641609	valid_1&#39;s myFeval: 0.909158
[64200]	training&#39;s l1: 0.0334651	training&#39;s myFeval: 0.45986	valid_1&#39;s l1: 0.0641553	valid_1&#39;s myFeval: 0.909053
[64500]	training&#39;s l1: 0.0334436	training&#39;s myFeval: 0.459554	valid_1&#39;s l1: 0.0641536	valid_1&#39;s myFeval: 0.909025
[64800]	training&#39;s l1: 0.0334206	training&#39;s myFeval: 0.459245	valid_1&#39;s l1: 0.0641515	valid_1&#39;s myFeval: 0.909001
[65100]	training&#39;s l1: 0.0334007	training&#39;s myFeval: 0.458976	valid_1&#39;s l1: 0.0641471	valid_1&#39;s myFeval: 0.908913
[65400]	training&#39;s l1: 0.0333769	training&#39;s myFeval: 0.458669	valid_1&#39;s l1: 0.0641373	valid_1&#39;s myFeval: 0.908769
[65700]	training&#39;s l1: 0.0333452	training&#39;s myFeval: 0.45825	valid_1&#39;s l1: 0.0641261	valid_1&#39;s myFeval: 0.908628
[66000]	training&#39;s l1: 0.0333193	training&#39;s myFeval: 0.457933	valid_1&#39;s l1: 0.0641227	valid_1&#39;s myFeval: 0.908607
[66300]	training&#39;s l1: 0.0332974	training&#39;s myFeval: 0.457659	valid_1&#39;s l1: 0.064119	valid_1&#39;s myFeval: 0.908589
[66600]	training&#39;s l1: 0.0332757	training&#39;s myFeval: 0.45735	valid_1&#39;s l1: 0.0641185	valid_1&#39;s myFeval: 0.908553
[66900]	training&#39;s l1: 0.0332528	training&#39;s myFeval: 0.457039	valid_1&#39;s l1: 0.0641171	valid_1&#39;s myFeval: 0.908473
[67200]	training&#39;s l1: 0.0332311	training&#39;s myFeval: 0.456731	valid_1&#39;s l1: 0.0641146	valid_1&#39;s myFeval: 0.908396
[67500]	training&#39;s l1: 0.0332085	training&#39;s myFeval: 0.456421	valid_1&#39;s l1: 0.0641146	valid_1&#39;s myFeval: 0.908398
[67800]	training&#39;s l1: 0.0331858	training&#39;s myFeval: 0.456065	valid_1&#39;s l1: 0.0641118	valid_1&#39;s myFeval: 0.908337
[68100]	training&#39;s l1: 0.0331639	training&#39;s myFeval: 0.455754	valid_1&#39;s l1: 0.0641092	valid_1&#39;s myFeval: 0.908242
[68400]	training&#39;s l1: 0.0331412	training&#39;s myFeval: 0.455445	valid_1&#39;s l1: 0.064106	valid_1&#39;s myFeval: 0.908195
[68700]	training&#39;s l1: 0.0331224	training&#39;s myFeval: 0.455161	valid_1&#39;s l1: 0.0641051	valid_1&#39;s myFeval: 0.908158
[69000]	training&#39;s l1: 0.0331071	training&#39;s myFeval: 0.454931	valid_1&#39;s l1: 0.0641	valid_1&#39;s myFeval: 0.908087
[69300]	training&#39;s l1: 0.0330883	training&#39;s myFeval: 0.454649	valid_1&#39;s l1: 0.0640972	valid_1&#39;s myFeval: 0.908027
[69600]	training&#39;s l1: 0.0330662	training&#39;s myFeval: 0.454321	valid_1&#39;s l1: 0.0640955	valid_1&#39;s myFeval: 0.907937
[69900]	training&#39;s l1: 0.033045	training&#39;s myFeval: 0.454055	valid_1&#39;s l1: 0.0640932	valid_1&#39;s myFeval: 0.907888
[70200]	training&#39;s l1: 0.033025	training&#39;s myFeval: 0.453787	valid_1&#39;s l1: 0.0640891	valid_1&#39;s myFeval: 0.907845
[70500]	training&#39;s l1: 0.0330021	training&#39;s myFeval: 0.453478	valid_1&#39;s l1: 0.0640846	valid_1&#39;s myFeval: 0.907735
[70800]	training&#39;s l1: 0.0329812	training&#39;s myFeval: 0.453203	valid_1&#39;s l1: 0.0640858	valid_1&#39;s myFeval: 0.90774
[71100]	training&#39;s l1: 0.0329494	training&#39;s myFeval: 0.452779	valid_1&#39;s l1: 0.0640821	valid_1&#39;s myFeval: 0.907672
[71400]	training&#39;s l1: 0.0329159	training&#39;s myFeval: 0.452347	valid_1&#39;s l1: 0.064077	valid_1&#39;s myFeval: 0.907652
[71700]	training&#39;s l1: 0.0328921	training&#39;s myFeval: 0.452034	valid_1&#39;s l1: 0.0640743	valid_1&#39;s myFeval: 0.907618
[72000]	training&#39;s l1: 0.0328759	training&#39;s myFeval: 0.451834	valid_1&#39;s l1: 0.0640694	valid_1&#39;s myFeval: 0.907587
[72300]	training&#39;s l1: 0.0328607	training&#39;s myFeval: 0.451623	valid_1&#39;s l1: 0.0640685	valid_1&#39;s myFeval: 0.907545
[72600]	training&#39;s l1: 0.0328428	training&#39;s myFeval: 0.451371	valid_1&#39;s l1: 0.0640673	valid_1&#39;s myFeval: 0.907473
[72900]	training&#39;s l1: 0.0328254	training&#39;s myFeval: 0.451142	valid_1&#39;s l1: 0.0640664	valid_1&#39;s myFeval: 0.907457
[73200]	training&#39;s l1: 0.0328051	training&#39;s myFeval: 0.450883	valid_1&#39;s l1: 0.0640612	valid_1&#39;s myFeval: 0.907399
[73500]	training&#39;s l1: 0.0327881	training&#39;s myFeval: 0.450626	valid_1&#39;s l1: 0.0640601	valid_1&#39;s myFeval: 0.907362
[73800]	training&#39;s l1: 0.0327659	training&#39;s myFeval: 0.450285	valid_1&#39;s l1: 0.064058	valid_1&#39;s myFeval: 0.907257
[74100]	training&#39;s l1: 0.0327493	training&#39;s myFeval: 0.450069	valid_1&#39;s l1: 0.0640564	valid_1&#39;s myFeval: 0.907234
[74400]	training&#39;s l1: 0.0327294	training&#39;s myFeval: 0.449781	valid_1&#39;s l1: 0.064053	valid_1&#39;s myFeval: 0.907174
[74700]	training&#39;s l1: 0.0327118	training&#39;s myFeval: 0.449524	valid_1&#39;s l1: 0.0640518	valid_1&#39;s myFeval: 0.907117
[75000]	training&#39;s l1: 0.0326938	training&#39;s myFeval: 0.449268	valid_1&#39;s l1: 0.0640489	valid_1&#39;s myFeval: 0.907036
[75300]	training&#39;s l1: 0.0326741	training&#39;s myFeval: 0.448958	valid_1&#39;s l1: 0.0640458	valid_1&#39;s myFeval: 0.90699
[75600]	training&#39;s l1: 0.0326564	training&#39;s myFeval: 0.448709	valid_1&#39;s l1: 0.0640425	valid_1&#39;s myFeval: 0.906918
[75900]	training&#39;s l1: 0.0326386	training&#39;s myFeval: 0.448431	valid_1&#39;s l1: 0.0640405	valid_1&#39;s myFeval: 0.906843
[76200]	training&#39;s l1: 0.032621	training&#39;s myFeval: 0.448171	valid_1&#39;s l1: 0.0640385	valid_1&#39;s myFeval: 0.906806
[76500]	training&#39;s l1: 0.0326018	training&#39;s myFeval: 0.447897	valid_1&#39;s l1: 0.0640361	valid_1&#39;s myFeval: 0.906748
[76800]	training&#39;s l1: 0.0325833	training&#39;s myFeval: 0.447654	valid_1&#39;s l1: 0.0640347	valid_1&#39;s myFeval: 0.906722
[77100]	training&#39;s l1: 0.032566	training&#39;s myFeval: 0.447418	valid_1&#39;s l1: 0.0640302	valid_1&#39;s myFeval: 0.90663
[77400]	training&#39;s l1: 0.0325443	training&#39;s myFeval: 0.447135	valid_1&#39;s l1: 0.06403	valid_1&#39;s myFeval: 0.906628
[77700]	training&#39;s l1: 0.0325199	training&#39;s myFeval: 0.446826	valid_1&#39;s l1: 0.0640267	valid_1&#39;s myFeval: 0.906596
[78000]	training&#39;s l1: 0.0324992	training&#39;s myFeval: 0.446528	valid_1&#39;s l1: 0.0640247	valid_1&#39;s myFeval: 0.90656
[78300]	training&#39;s l1: 0.0324814	training&#39;s myFeval: 0.446278	valid_1&#39;s l1: 0.0640239	valid_1&#39;s myFeval: 0.906555
[78600]	training&#39;s l1: 0.0324597	training&#39;s myFeval: 0.445991	valid_1&#39;s l1: 0.0640198	valid_1&#39;s myFeval: 0.906483
[78900]	training&#39;s l1: 0.0324279	training&#39;s myFeval: 0.445588	valid_1&#39;s l1: 0.0640161	valid_1&#39;s myFeval: 0.906419
[79200]	training&#39;s l1: 0.032398	training&#39;s myFeval: 0.445215	valid_1&#39;s l1: 0.0640133	valid_1&#39;s myFeval: 0.906353
[79500]	training&#39;s l1: 0.0323726	training&#39;s myFeval: 0.444873	valid_1&#39;s l1: 0.0640072	valid_1&#39;s myFeval: 0.906282
[79800]	training&#39;s l1: 0.0323333	training&#39;s myFeval: 0.44437	valid_1&#39;s l1: 0.0639946	valid_1&#39;s myFeval: 0.906122
[80100]	training&#39;s l1: 0.0323065	training&#39;s myFeval: 0.444033	valid_1&#39;s l1: 0.0639932	valid_1&#39;s myFeval: 0.906061
[80400]	training&#39;s l1: 0.0322902	training&#39;s myFeval: 0.443821	valid_1&#39;s l1: 0.0639936	valid_1&#39;s myFeval: 0.906047
[80700]	training&#39;s l1: 0.0322745	training&#39;s myFeval: 0.443604	valid_1&#39;s l1: 0.06399	valid_1&#39;s myFeval: 0.905992
[81000]	training&#39;s l1: 0.0322569	training&#39;s myFeval: 0.443377	valid_1&#39;s l1: 0.0639872	valid_1&#39;s myFeval: 0.905951
[81300]	training&#39;s l1: 0.0322388	training&#39;s myFeval: 0.44316	valid_1&#39;s l1: 0.0639814	valid_1&#39;s myFeval: 0.905891
[81600]	training&#39;s l1: 0.0322238	training&#39;s myFeval: 0.442962	valid_1&#39;s l1: 0.0639792	valid_1&#39;s myFeval: 0.905867
[81900]	training&#39;s l1: 0.0322079	training&#39;s myFeval: 0.442743	valid_1&#39;s l1: 0.0639752	valid_1&#39;s myFeval: 0.905815
[82200]	training&#39;s l1: 0.0321937	training&#39;s myFeval: 0.442559	valid_1&#39;s l1: 0.0639736	valid_1&#39;s myFeval: 0.90579
[82500]	training&#39;s l1: 0.0321777	training&#39;s myFeval: 0.442333	valid_1&#39;s l1: 0.0639715	valid_1&#39;s myFeval: 0.90576
[82800]	training&#39;s l1: 0.03216	training&#39;s myFeval: 0.442097	valid_1&#39;s l1: 0.0639697	valid_1&#39;s myFeval: 0.905712
[83100]	training&#39;s l1: 0.0321444	training&#39;s myFeval: 0.441871	valid_1&#39;s l1: 0.0639688	valid_1&#39;s myFeval: 0.9057
[83400]	training&#39;s l1: 0.0321276	training&#39;s myFeval: 0.441657	valid_1&#39;s l1: 0.0639636	valid_1&#39;s myFeval: 0.905606
[83700]	training&#39;s l1: 0.0321109	training&#39;s myFeval: 0.44144	valid_1&#39;s l1: 0.0639593	valid_1&#39;s myFeval: 0.905556
[84000]	training&#39;s l1: 0.0320964	training&#39;s myFeval: 0.441222	valid_1&#39;s l1: 0.0639556	valid_1&#39;s myFeval: 0.905521
[84300]	training&#39;s l1: 0.0320764	training&#39;s myFeval: 0.440958	valid_1&#39;s l1: 0.0639531	valid_1&#39;s myFeval: 0.905503
[84600]	training&#39;s l1: 0.0320494	training&#39;s myFeval: 0.440601	valid_1&#39;s l1: 0.0639519	valid_1&#39;s myFeval: 0.90549
[84900]	training&#39;s l1: 0.0320337	training&#39;s myFeval: 0.440362	valid_1&#39;s l1: 0.0639482	valid_1&#39;s myFeval: 0.905381
[85200]	training&#39;s l1: 0.0320163	training&#39;s myFeval: 0.440114	valid_1&#39;s l1: 0.063948	valid_1&#39;s myFeval: 0.905371
[85500]	training&#39;s l1: 0.0319991	training&#39;s myFeval: 0.439868	valid_1&#39;s l1: 0.0639455	valid_1&#39;s myFeval: 0.905318
[85800]	training&#39;s l1: 0.0319814	training&#39;s myFeval: 0.439591	valid_1&#39;s l1: 0.0639443	valid_1&#39;s myFeval: 0.905267
[86100]	training&#39;s l1: 0.0319623	training&#39;s myFeval: 0.439346	valid_1&#39;s l1: 0.0639436	valid_1&#39;s myFeval: 0.905247
[86400]	training&#39;s l1: 0.0319462	training&#39;s myFeval: 0.439128	valid_1&#39;s l1: 0.0639436	valid_1&#39;s myFeval: 0.905264
[86700]	training&#39;s l1: 0.0319307	training&#39;s myFeval: 0.438895	valid_1&#39;s l1: 0.0639399	valid_1&#39;s myFeval: 0.905176
[87000]	training&#39;s l1: 0.0319165	training&#39;s myFeval: 0.43867	valid_1&#39;s l1: 0.0639343	valid_1&#39;s myFeval: 0.905025
[87300]	training&#39;s l1: 0.0319007	training&#39;s myFeval: 0.438412	valid_1&#39;s l1: 0.0639311	valid_1&#39;s myFeval: 0.904994
[87600]	training&#39;s l1: 0.0318837	training&#39;s myFeval: 0.438175	valid_1&#39;s l1: 0.063931	valid_1&#39;s myFeval: 0.905001
[87900]	training&#39;s l1: 0.0318561	training&#39;s myFeval: 0.437839	valid_1&#39;s l1: 0.063923	valid_1&#39;s myFeval: 0.904945
[88200]	training&#39;s l1: 0.031833	training&#39;s myFeval: 0.437551	valid_1&#39;s l1: 0.063921	valid_1&#39;s myFeval: 0.904933
[88500]	training&#39;s l1: 0.0318144	training&#39;s myFeval: 0.437261	valid_1&#39;s l1: 0.0639191	valid_1&#39;s myFeval: 0.904877
[88800]	training&#39;s l1: 0.0317989	training&#39;s myFeval: 0.437032	valid_1&#39;s l1: 0.0639196	valid_1&#39;s myFeval: 0.904844
[89100]	training&#39;s l1: 0.0317809	training&#39;s myFeval: 0.436794	valid_1&#39;s l1: 0.0639162	valid_1&#39;s myFeval: 0.904803
[89400]	training&#39;s l1: 0.0317639	training&#39;s myFeval: 0.436549	valid_1&#39;s l1: 0.063913	valid_1&#39;s myFeval: 0.904741
[89700]	training&#39;s l1: 0.031749	training&#39;s myFeval: 0.436341	valid_1&#39;s l1: 0.0639108	valid_1&#39;s myFeval: 0.904692
[90000]	training&#39;s l1: 0.0317352	training&#39;s myFeval: 0.436147	valid_1&#39;s l1: 0.06391	valid_1&#39;s myFeval: 0.904655
[90300]	training&#39;s l1: 0.0317207	training&#39;s myFeval: 0.435949	valid_1&#39;s l1: 0.0639105	valid_1&#39;s myFeval: 0.904681
Early stopping, best iteration is:
[89865]	training&#39;s l1: 0.0317411	training&#39;s myFeval: 0.436224	valid_1&#39;s l1: 0.0639095	valid_1&#39;s myFeval: 0.904666
fold n°9
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013079 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9903
[LightGBM] [Info] Number of data points in the train set: 26617, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.431857
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.111938	training&#39;s myFeval: 2.0782	valid_1&#39;s l1: 0.1174	valid_1&#39;s myFeval: 1.97221
[600]	training&#39;s l1: 0.0791043	training&#39;s myFeval: 1.27971	valid_1&#39;s l1: 0.0855671	valid_1&#39;s myFeval: 1.23259
[900]	training&#39;s l1: 0.0718889	training&#39;s myFeval: 1.09167	valid_1&#39;s l1: 0.0801292	valid_1&#39;s myFeval: 1.1235
[1200]	training&#39;s l1: 0.0680978	training&#39;s myFeval: 1.01042	valid_1&#39;s l1: 0.0777803	valid_1&#39;s myFeval: 1.08762
[1500]	training&#39;s l1: 0.0653729	training&#39;s myFeval: 0.960993	valid_1&#39;s l1: 0.0762916	valid_1&#39;s myFeval: 1.06709
[1800]	training&#39;s l1: 0.0632141	training&#39;s myFeval: 0.921144	valid_1&#39;s l1: 0.0752167	valid_1&#39;s myFeval: 1.0513
[2100]	training&#39;s l1: 0.0613946	training&#39;s myFeval: 0.885965	valid_1&#39;s l1: 0.0743116	valid_1&#39;s myFeval: 1.0366
[2400]	training&#39;s l1: 0.0598558	training&#39;s myFeval: 0.861541	valid_1&#39;s l1: 0.0736323	valid_1&#39;s myFeval: 1.02747
[2700]	training&#39;s l1: 0.0584683	training&#39;s myFeval: 0.838294	valid_1&#39;s l1: 0.0730175	valid_1&#39;s myFeval: 1.01892
[3000]	training&#39;s l1: 0.0572627	training&#39;s myFeval: 0.818506	valid_1&#39;s l1: 0.0725635	valid_1&#39;s myFeval: 1.01185
[3300]	training&#39;s l1: 0.0561536	training&#39;s myFeval: 0.800206	valid_1&#39;s l1: 0.0721497	valid_1&#39;s myFeval: 1.00546
[3600]	training&#39;s l1: 0.0551781	training&#39;s myFeval: 0.784245	valid_1&#39;s l1: 0.071752	valid_1&#39;s myFeval: 0.999054
[3900]	training&#39;s l1: 0.0542686	training&#39;s myFeval: 0.770291	valid_1&#39;s l1: 0.0714278	valid_1&#39;s myFeval: 0.993829
[4200]	training&#39;s l1: 0.05347	training&#39;s myFeval: 0.757032	valid_1&#39;s l1: 0.0711147	valid_1&#39;s myFeval: 0.988829
[4500]	training&#39;s l1: 0.0527142	training&#39;s myFeval: 0.745226	valid_1&#39;s l1: 0.0708488	valid_1&#39;s myFeval: 0.9848
[4800]	training&#39;s l1: 0.0520349	training&#39;s myFeval: 0.734494	valid_1&#39;s l1: 0.0706229	valid_1&#39;s myFeval: 0.981743
[5100]	training&#39;s l1: 0.0514123	training&#39;s myFeval: 0.724798	valid_1&#39;s l1: 0.0704083	valid_1&#39;s myFeval: 0.978209
[5400]	training&#39;s l1: 0.0508217	training&#39;s myFeval: 0.715631	valid_1&#39;s l1: 0.0701903	valid_1&#39;s myFeval: 0.975106
[5700]	training&#39;s l1: 0.0502695	training&#39;s myFeval: 0.707014	valid_1&#39;s l1: 0.0700148	valid_1&#39;s myFeval: 0.972426
[6000]	training&#39;s l1: 0.0497786	training&#39;s myFeval: 0.698994	valid_1&#39;s l1: 0.0698382	valid_1&#39;s myFeval: 0.969696
[6300]	training&#39;s l1: 0.0493083	training&#39;s myFeval: 0.691983	valid_1&#39;s l1: 0.0696826	valid_1&#39;s myFeval: 0.967572
[6600]	training&#39;s l1: 0.0488786	training&#39;s myFeval: 0.685449	valid_1&#39;s l1: 0.0695431	valid_1&#39;s myFeval: 0.965564
[6900]	training&#39;s l1: 0.0484674	training&#39;s myFeval: 0.67894	valid_1&#39;s l1: 0.0694087	valid_1&#39;s myFeval: 0.963518
[7200]	training&#39;s l1: 0.0480757	training&#39;s myFeval: 0.673046	valid_1&#39;s l1: 0.069301	valid_1&#39;s myFeval: 0.962012
[7500]	training&#39;s l1: 0.0476903	training&#39;s myFeval: 0.667372	valid_1&#39;s l1: 0.0692065	valid_1&#39;s myFeval: 0.960702
[7800]	training&#39;s l1: 0.0473218	training&#39;s myFeval: 0.661733	valid_1&#39;s l1: 0.0691021	valid_1&#39;s myFeval: 0.959111
[8100]	training&#39;s l1: 0.0470124	training&#39;s myFeval: 0.657691	valid_1&#39;s l1: 0.0690323	valid_1&#39;s myFeval: 0.95815
[8400]	training&#39;s l1: 0.0466897	training&#39;s myFeval: 0.652884	valid_1&#39;s l1: 0.068957	valid_1&#39;s myFeval: 0.957323
[8700]	training&#39;s l1: 0.0463981	training&#39;s myFeval: 0.648356	valid_1&#39;s l1: 0.0688824	valid_1&#39;s myFeval: 0.956336
[9000]	training&#39;s l1: 0.0461177	training&#39;s myFeval: 0.643963	valid_1&#39;s l1: 0.0688232	valid_1&#39;s myFeval: 0.955556
[9300]	training&#39;s l1: 0.0458464	training&#39;s myFeval: 0.639644	valid_1&#39;s l1: 0.0687334	valid_1&#39;s myFeval: 0.954086
[9600]	training&#39;s l1: 0.0455758	training&#39;s myFeval: 0.635374	valid_1&#39;s l1: 0.0686452	valid_1&#39;s myFeval: 0.952715
[9900]	training&#39;s l1: 0.0453239	training&#39;s myFeval: 0.631644	valid_1&#39;s l1: 0.0685608	valid_1&#39;s myFeval: 0.951293
[10200]	training&#39;s l1: 0.0450679	training&#39;s myFeval: 0.627655	valid_1&#39;s l1: 0.0684896	valid_1&#39;s myFeval: 0.949958
[10500]	training&#39;s l1: 0.0448427	training&#39;s myFeval: 0.624301	valid_1&#39;s l1: 0.0684281	valid_1&#39;s myFeval: 0.948852
[10800]	training&#39;s l1: 0.0446203	training&#39;s myFeval: 0.620817	valid_1&#39;s l1: 0.0683795	valid_1&#39;s myFeval: 0.947982
[11100]	training&#39;s l1: 0.0444027	training&#39;s myFeval: 0.617643	valid_1&#39;s l1: 0.0683229	valid_1&#39;s myFeval: 0.94709
[11400]	training&#39;s l1: 0.0441762	training&#39;s myFeval: 0.614341	valid_1&#39;s l1: 0.0682731	valid_1&#39;s myFeval: 0.946146
[11700]	training&#39;s l1: 0.0439986	training&#39;s myFeval: 0.611485	valid_1&#39;s l1: 0.0682383	valid_1&#39;s myFeval: 0.945534
[12000]	training&#39;s l1: 0.0438296	training&#39;s myFeval: 0.60878	valid_1&#39;s l1: 0.0681929	valid_1&#39;s myFeval: 0.944856
[12300]	training&#39;s l1: 0.0436567	training&#39;s myFeval: 0.606034	valid_1&#39;s l1: 0.0681463	valid_1&#39;s myFeval: 0.944075
[12600]	training&#39;s l1: 0.0434717	training&#39;s myFeval: 0.602999	valid_1&#39;s l1: 0.0681018	valid_1&#39;s myFeval: 0.943217
[12900]	training&#39;s l1: 0.0433142	training&#39;s myFeval: 0.600312	valid_1&#39;s l1: 0.0680668	valid_1&#39;s myFeval: 0.942655
[13200]	training&#39;s l1: 0.0431565	training&#39;s myFeval: 0.597549	valid_1&#39;s l1: 0.06804	valid_1&#39;s myFeval: 0.942154
[13500]	training&#39;s l1: 0.0430002	training&#39;s myFeval: 0.595201	valid_1&#39;s l1: 0.0680028	valid_1&#39;s myFeval: 0.94151
[13800]	training&#39;s l1: 0.0428347	training&#39;s myFeval: 0.592801	valid_1&#39;s l1: 0.0679711	valid_1&#39;s myFeval: 0.941026
[14100]	training&#39;s l1: 0.0426528	training&#39;s myFeval: 0.590157	valid_1&#39;s l1: 0.0679461	valid_1&#39;s myFeval: 0.940573
[14400]	training&#39;s l1: 0.0424664	training&#39;s myFeval: 0.58795	valid_1&#39;s l1: 0.0679165	valid_1&#39;s myFeval: 0.940101
[14700]	training&#39;s l1: 0.0423115	training&#39;s myFeval: 0.585743	valid_1&#39;s l1: 0.0678855	valid_1&#39;s myFeval: 0.939702
[15000]	training&#39;s l1: 0.0421735	training&#39;s myFeval: 0.58379	valid_1&#39;s l1: 0.0678461	valid_1&#39;s myFeval: 0.939024
[15300]	training&#39;s l1: 0.0420474	training&#39;s myFeval: 0.581901	valid_1&#39;s l1: 0.0678121	valid_1&#39;s myFeval: 0.938414
[15600]	training&#39;s l1: 0.0419145	training&#39;s myFeval: 0.579977	valid_1&#39;s l1: 0.0677779	valid_1&#39;s myFeval: 0.937874
[15900]	training&#39;s l1: 0.0417786	training&#39;s myFeval: 0.577874	valid_1&#39;s l1: 0.0677524	valid_1&#39;s myFeval: 0.937504
[16200]	training&#39;s l1: 0.0416408	training&#39;s myFeval: 0.575706	valid_1&#39;s l1: 0.0677119	valid_1&#39;s myFeval: 0.936945
[16500]	training&#39;s l1: 0.041513	training&#39;s myFeval: 0.573892	valid_1&#39;s l1: 0.0676729	valid_1&#39;s myFeval: 0.93633
[16800]	training&#39;s l1: 0.0413842	training&#39;s myFeval: 0.572084	valid_1&#39;s l1: 0.0676435	valid_1&#39;s myFeval: 0.935806
[17100]	training&#39;s l1: 0.0412846	training&#39;s myFeval: 0.570143	valid_1&#39;s l1: 0.0676178	valid_1&#39;s myFeval: 0.935303
[17400]	training&#39;s l1: 0.0411888	training&#39;s myFeval: 0.56788	valid_1&#39;s l1: 0.067587	valid_1&#39;s myFeval: 0.934547
[17700]	training&#39;s l1: 0.0410873	training&#39;s myFeval: 0.565977	valid_1&#39;s l1: 0.0675601	valid_1&#39;s myFeval: 0.933871
[18000]	training&#39;s l1: 0.0409758	training&#39;s myFeval: 0.56441	valid_1&#39;s l1: 0.0675433	valid_1&#39;s myFeval: 0.933547
[18300]	training&#39;s l1: 0.040876	training&#39;s myFeval: 0.562915	valid_1&#39;s l1: 0.0675244	valid_1&#39;s myFeval: 0.93316
[18600]	training&#39;s l1: 0.0407574	training&#39;s myFeval: 0.561267	valid_1&#39;s l1: 0.067501	valid_1&#39;s myFeval: 0.932788
[18900]	training&#39;s l1: 0.04064	training&#39;s myFeval: 0.559727	valid_1&#39;s l1: 0.0674711	valid_1&#39;s myFeval: 0.93224
[19200]	training&#39;s l1: 0.0405313	training&#39;s myFeval: 0.558301	valid_1&#39;s l1: 0.0674662	valid_1&#39;s myFeval: 0.932015
[19500]	training&#39;s l1: 0.0404198	training&#39;s myFeval: 0.556855	valid_1&#39;s l1: 0.0674353	valid_1&#39;s myFeval: 0.931688
[19800]	training&#39;s l1: 0.040336	training&#39;s myFeval: 0.555939	valid_1&#39;s l1: 0.06743	valid_1&#39;s myFeval: 0.931586
[20100]	training&#39;s l1: 0.0402516	training&#39;s myFeval: 0.555024	valid_1&#39;s l1: 0.067419	valid_1&#39;s myFeval: 0.931487
[20400]	training&#39;s l1: 0.0401586	training&#39;s myFeval: 0.553689	valid_1&#39;s l1: 0.0673981	valid_1&#39;s myFeval: 0.931123
[20700]	training&#39;s l1: 0.0400595	training&#39;s myFeval: 0.552152	valid_1&#39;s l1: 0.0673717	valid_1&#39;s myFeval: 0.930704
[21000]	training&#39;s l1: 0.039965	training&#39;s myFeval: 0.550821	valid_1&#39;s l1: 0.0673486	valid_1&#39;s myFeval: 0.930402
[21300]	training&#39;s l1: 0.0398855	training&#39;s myFeval: 0.549626	valid_1&#39;s l1: 0.0673325	valid_1&#39;s myFeval: 0.93011
[21600]	training&#39;s l1: 0.0397836	training&#39;s myFeval: 0.548207	valid_1&#39;s l1: 0.0673118	valid_1&#39;s myFeval: 0.929794
[21900]	training&#39;s l1: 0.0396726	training&#39;s myFeval: 0.546679	valid_1&#39;s l1: 0.0672939	valid_1&#39;s myFeval: 0.929624
[22200]	training&#39;s l1: 0.039583	training&#39;s myFeval: 0.545494	valid_1&#39;s l1: 0.0672845	valid_1&#39;s myFeval: 0.929524
[22500]	training&#39;s l1: 0.039503	training&#39;s myFeval: 0.544234	valid_1&#39;s l1: 0.0672601	valid_1&#39;s myFeval: 0.929081
[22800]	training&#39;s l1: 0.0394287	training&#39;s myFeval: 0.543155	valid_1&#39;s l1: 0.0672497	valid_1&#39;s myFeval: 0.928907
[23100]	training&#39;s l1: 0.0393683	training&#39;s myFeval: 0.542486	valid_1&#39;s l1: 0.0672361	valid_1&#39;s myFeval: 0.928753
[23400]	training&#39;s l1: 0.0393073	training&#39;s myFeval: 0.54176	valid_1&#39;s l1: 0.0672274	valid_1&#39;s myFeval: 0.928531
[23700]	training&#39;s l1: 0.0392293	training&#39;s myFeval: 0.540657	valid_1&#39;s l1: 0.0672052	valid_1&#39;s myFeval: 0.928315
[24000]	training&#39;s l1: 0.0391464	training&#39;s myFeval: 0.539515	valid_1&#39;s l1: 0.0671935	valid_1&#39;s myFeval: 0.928085
[24300]	training&#39;s l1: 0.0390754	training&#39;s myFeval: 0.538629	valid_1&#39;s l1: 0.0671813	valid_1&#39;s myFeval: 0.92793
[24600]	training&#39;s l1: 0.0390083	training&#39;s myFeval: 0.537794	valid_1&#39;s l1: 0.0671745	valid_1&#39;s myFeval: 0.927794
[24900]	training&#39;s l1: 0.0389365	training&#39;s myFeval: 0.536763	valid_1&#39;s l1: 0.0671546	valid_1&#39;s myFeval: 0.92744
[25200]	training&#39;s l1: 0.0388669	training&#39;s myFeval: 0.535776	valid_1&#39;s l1: 0.0671413	valid_1&#39;s myFeval: 0.927211
[25500]	training&#39;s l1: 0.0388094	training&#39;s myFeval: 0.535105	valid_1&#39;s l1: 0.067131	valid_1&#39;s myFeval: 0.927092
[25800]	training&#39;s l1: 0.0387517	training&#39;s myFeval: 0.534412	valid_1&#39;s l1: 0.0671234	valid_1&#39;s myFeval: 0.92696
[26100]	training&#39;s l1: 0.0386887	training&#39;s myFeval: 0.5336	valid_1&#39;s l1: 0.067112	valid_1&#39;s myFeval: 0.926807
[26400]	training&#39;s l1: 0.0386213	training&#39;s myFeval: 0.532804	valid_1&#39;s l1: 0.0671006	valid_1&#39;s myFeval: 0.926627
[26700]	training&#39;s l1: 0.0385521	training&#39;s myFeval: 0.531839	valid_1&#39;s l1: 0.0670846	valid_1&#39;s myFeval: 0.92633
[27000]	training&#39;s l1: 0.0384851	training&#39;s myFeval: 0.530879	valid_1&#39;s l1: 0.0670665	valid_1&#39;s myFeval: 0.926068
[27300]	training&#39;s l1: 0.0384161	training&#39;s myFeval: 0.52984	valid_1&#39;s l1: 0.0670552	valid_1&#39;s myFeval: 0.925844
[27600]	training&#39;s l1: 0.0383577	training&#39;s myFeval: 0.529021	valid_1&#39;s l1: 0.0670396	valid_1&#39;s myFeval: 0.925622
[27900]	training&#39;s l1: 0.0382817	training&#39;s myFeval: 0.528161	valid_1&#39;s l1: 0.0670297	valid_1&#39;s myFeval: 0.925514
[28200]	training&#39;s l1: 0.0382103	training&#39;s myFeval: 0.527176	valid_1&#39;s l1: 0.0670164	valid_1&#39;s myFeval: 0.925434
[28500]	training&#39;s l1: 0.0381612	training&#39;s myFeval: 0.52626	valid_1&#39;s l1: 0.0670078	valid_1&#39;s myFeval: 0.925303
[28800]	training&#39;s l1: 0.0381058	training&#39;s myFeval: 0.525261	valid_1&#39;s l1: 0.0669977	valid_1&#39;s myFeval: 0.925108
[29100]	training&#39;s l1: 0.0380445	training&#39;s myFeval: 0.524457	valid_1&#39;s l1: 0.066983	valid_1&#39;s myFeval: 0.924912
[29400]	training&#39;s l1: 0.0379862	training&#39;s myFeval: 0.523635	valid_1&#39;s l1: 0.0669752	valid_1&#39;s myFeval: 0.924771
[29700]	training&#39;s l1: 0.0379227	training&#39;s myFeval: 0.522815	valid_1&#39;s l1: 0.066963	valid_1&#39;s myFeval: 0.924672
[30000]	training&#39;s l1: 0.0378506	training&#39;s myFeval: 0.521937	valid_1&#39;s l1: 0.0669542	valid_1&#39;s myFeval: 0.924619
[30300]	training&#39;s l1: 0.0377943	training&#39;s myFeval: 0.521266	valid_1&#39;s l1: 0.0669367	valid_1&#39;s myFeval: 0.924457
[30600]	training&#39;s l1: 0.0377464	training&#39;s myFeval: 0.520693	valid_1&#39;s l1: 0.0669336	valid_1&#39;s myFeval: 0.92445
[30900]	training&#39;s l1: 0.0376903	training&#39;s myFeval: 0.519923	valid_1&#39;s l1: 0.0669249	valid_1&#39;s myFeval: 0.924314
[31200]	training&#39;s l1: 0.0376368	training&#39;s myFeval: 0.519151	valid_1&#39;s l1: 0.0669132	valid_1&#39;s myFeval: 0.924131
[31500]	training&#39;s l1: 0.0375774	training&#39;s myFeval: 0.51821	valid_1&#39;s l1: 0.0668975	valid_1&#39;s myFeval: 0.923906
[31800]	training&#39;s l1: 0.037524	training&#39;s myFeval: 0.517444	valid_1&#39;s l1: 0.0668809	valid_1&#39;s myFeval: 0.923655
[32100]	training&#39;s l1: 0.0374688	training&#39;s myFeval: 0.51666	valid_1&#39;s l1: 0.0668732	valid_1&#39;s myFeval: 0.923454
[32400]	training&#39;s l1: 0.037412	training&#39;s myFeval: 0.515882	valid_1&#39;s l1: 0.0668632	valid_1&#39;s myFeval: 0.923177
[32700]	training&#39;s l1: 0.0373583	training&#39;s myFeval: 0.515091	valid_1&#39;s l1: 0.0668569	valid_1&#39;s myFeval: 0.923003
[33000]	training&#39;s l1: 0.0372751	training&#39;s myFeval: 0.514028	valid_1&#39;s l1: 0.0668405	valid_1&#39;s myFeval: 0.922806
[33300]	training&#39;s l1: 0.0372174	training&#39;s myFeval: 0.513252	valid_1&#39;s l1: 0.0668299	valid_1&#39;s myFeval: 0.922603
[33600]	training&#39;s l1: 0.0371606	training&#39;s myFeval: 0.512511	valid_1&#39;s l1: 0.0668184	valid_1&#39;s myFeval: 0.922415
[33900]	training&#39;s l1: 0.0371106	training&#39;s myFeval: 0.511741	valid_1&#39;s l1: 0.0668064	valid_1&#39;s myFeval: 0.922152
[34200]	training&#39;s l1: 0.0370626	training&#39;s myFeval: 0.511033	valid_1&#39;s l1: 0.0667979	valid_1&#39;s myFeval: 0.92203
[34500]	training&#39;s l1: 0.0370133	training&#39;s myFeval: 0.510362	valid_1&#39;s l1: 0.0667848	valid_1&#39;s myFeval: 0.921827
[34800]	training&#39;s l1: 0.036973	training&#39;s myFeval: 0.509757	valid_1&#39;s l1: 0.0667786	valid_1&#39;s myFeval: 0.921697
[35100]	training&#39;s l1: 0.036923	training&#39;s myFeval: 0.509003	valid_1&#39;s l1: 0.0667748	valid_1&#39;s myFeval: 0.92155
[35400]	training&#39;s l1: 0.036878	training&#39;s myFeval: 0.508188	valid_1&#39;s l1: 0.066769	valid_1&#39;s myFeval: 0.921347
[35700]	training&#39;s l1: 0.0368339	training&#39;s myFeval: 0.507388	valid_1&#39;s l1: 0.0667668	valid_1&#39;s myFeval: 0.921328
[36000]	training&#39;s l1: 0.0367885	training&#39;s myFeval: 0.506733	valid_1&#39;s l1: 0.0667537	valid_1&#39;s myFeval: 0.921133
[36300]	training&#39;s l1: 0.0367458	training&#39;s myFeval: 0.506076	valid_1&#39;s l1: 0.066744	valid_1&#39;s myFeval: 0.920959
[36600]	training&#39;s l1: 0.0366893	training&#39;s myFeval: 0.505404	valid_1&#39;s l1: 0.0667363	valid_1&#39;s myFeval: 0.920854
[36900]	training&#39;s l1: 0.0366455	training&#39;s myFeval: 0.504859	valid_1&#39;s l1: 0.0667268	valid_1&#39;s myFeval: 0.920763
[37200]	training&#39;s l1: 0.0365957	training&#39;s myFeval: 0.504212	valid_1&#39;s l1: 0.0667173	valid_1&#39;s myFeval: 0.920578
[37500]	training&#39;s l1: 0.0365501	training&#39;s myFeval: 0.503565	valid_1&#39;s l1: 0.0667098	valid_1&#39;s myFeval: 0.920418
[37800]	training&#39;s l1: 0.0365076	training&#39;s myFeval: 0.502997	valid_1&#39;s l1: 0.0667042	valid_1&#39;s myFeval: 0.920331
[38100]	training&#39;s l1: 0.0364685	training&#39;s myFeval: 0.502447	valid_1&#39;s l1: 0.0666976	valid_1&#39;s myFeval: 0.920193
[38400]	training&#39;s l1: 0.0364267	training&#39;s myFeval: 0.501872	valid_1&#39;s l1: 0.0666916	valid_1&#39;s myFeval: 0.920112
[38700]	training&#39;s l1: 0.036384	training&#39;s myFeval: 0.501269	valid_1&#39;s l1: 0.0666779	valid_1&#39;s myFeval: 0.919925
[39000]	training&#39;s l1: 0.0363422	training&#39;s myFeval: 0.500613	valid_1&#39;s l1: 0.0666644	valid_1&#39;s myFeval: 0.919739
[39300]	training&#39;s l1: 0.0363009	training&#39;s myFeval: 0.499983	valid_1&#39;s l1: 0.06666	valid_1&#39;s myFeval: 0.919588
[39600]	training&#39;s l1: 0.0362597	training&#39;s myFeval: 0.499362	valid_1&#39;s l1: 0.0666549	valid_1&#39;s myFeval: 0.919397
[39900]	training&#39;s l1: 0.0362154	training&#39;s myFeval: 0.498606	valid_1&#39;s l1: 0.0666396	valid_1&#39;s myFeval: 0.919097
[40200]	training&#39;s l1: 0.0361688	training&#39;s myFeval: 0.497672	valid_1&#39;s l1: 0.0666198	valid_1&#39;s myFeval: 0.918715
[40500]	training&#39;s l1: 0.0361256	training&#39;s myFeval: 0.496931	valid_1&#39;s l1: 0.0666098	valid_1&#39;s myFeval: 0.918478
[40800]	training&#39;s l1: 0.0360827	training&#39;s myFeval: 0.496353	valid_1&#39;s l1: 0.0666057	valid_1&#39;s myFeval: 0.918375
[41100]	training&#39;s l1: 0.036043	training&#39;s myFeval: 0.495784	valid_1&#39;s l1: 0.0665958	valid_1&#39;s myFeval: 0.918252
[41400]	training&#39;s l1: 0.0360017	training&#39;s myFeval: 0.495258	valid_1&#39;s l1: 0.0665886	valid_1&#39;s myFeval: 0.918135
[41700]	training&#39;s l1: 0.0359525	training&#39;s myFeval: 0.494669	valid_1&#39;s l1: 0.06659	valid_1&#39;s myFeval: 0.918159
[42000]	training&#39;s l1: 0.0359009	training&#39;s myFeval: 0.49406	valid_1&#39;s l1: 0.0665839	valid_1&#39;s myFeval: 0.918086
[42300]	training&#39;s l1: 0.0358632	training&#39;s myFeval: 0.493576	valid_1&#39;s l1: 0.0665834	valid_1&#39;s myFeval: 0.918015
[42600]	training&#39;s l1: 0.035832	training&#39;s myFeval: 0.493155	valid_1&#39;s l1: 0.0665782	valid_1&#39;s myFeval: 0.917931
[42900]	training&#39;s l1: 0.0357924	training&#39;s myFeval: 0.492643	valid_1&#39;s l1: 0.0665716	valid_1&#39;s myFeval: 0.917848
[43200]	training&#39;s l1: 0.0357588	training&#39;s myFeval: 0.492172	valid_1&#39;s l1: 0.0665691	valid_1&#39;s myFeval: 0.917814
[43500]	training&#39;s l1: 0.0357258	training&#39;s myFeval: 0.491701	valid_1&#39;s l1: 0.0665655	valid_1&#39;s myFeval: 0.917719
[43800]	training&#39;s l1: 0.0356948	training&#39;s myFeval: 0.491241	valid_1&#39;s l1: 0.0665637	valid_1&#39;s myFeval: 0.917694
[44100]	training&#39;s l1: 0.035671	training&#39;s myFeval: 0.49091	valid_1&#39;s l1: 0.0665624	valid_1&#39;s myFeval: 0.917671
[44400]	training&#39;s l1: 0.0356407	training&#39;s myFeval: 0.490513	valid_1&#39;s l1: 0.0665585	valid_1&#39;s myFeval: 0.917579
[44700]	training&#39;s l1: 0.0356031	training&#39;s myFeval: 0.489978	valid_1&#39;s l1: 0.0665538	valid_1&#39;s myFeval: 0.917432
[45000]	training&#39;s l1: 0.0355663	training&#39;s myFeval: 0.489486	valid_1&#39;s l1: 0.0665471	valid_1&#39;s myFeval: 0.917293
[45300]	training&#39;s l1: 0.0355327	training&#39;s myFeval: 0.489048	valid_1&#39;s l1: 0.0665445	valid_1&#39;s myFeval: 0.91725
[45600]	training&#39;s l1: 0.0354992	training&#39;s myFeval: 0.488551	valid_1&#39;s l1: 0.0665382	valid_1&#39;s myFeval: 0.917123
[45900]	training&#39;s l1: 0.0354646	training&#39;s myFeval: 0.488028	valid_1&#39;s l1: 0.0665327	valid_1&#39;s myFeval: 0.916993
[46200]	training&#39;s l1: 0.0354317	training&#39;s myFeval: 0.487555	valid_1&#39;s l1: 0.0665313	valid_1&#39;s myFeval: 0.916978
[46500]	training&#39;s l1: 0.03539	training&#39;s myFeval: 0.487026	valid_1&#39;s l1: 0.0665305	valid_1&#39;s myFeval: 0.916955
[46800]	training&#39;s l1: 0.0353431	training&#39;s myFeval: 0.486437	valid_1&#39;s l1: 0.0665254	valid_1&#39;s myFeval: 0.916894
[47100]	training&#39;s l1: 0.0353054	training&#39;s myFeval: 0.485977	valid_1&#39;s l1: 0.0665214	valid_1&#39;s myFeval: 0.916821
[47400]	training&#39;s l1: 0.0352662	training&#39;s myFeval: 0.485401	valid_1&#39;s l1: 0.0665151	valid_1&#39;s myFeval: 0.916718
[47700]	training&#39;s l1: 0.0352356	training&#39;s myFeval: 0.484945	valid_1&#39;s l1: 0.0665133	valid_1&#39;s myFeval: 0.916689
[48000]	training&#39;s l1: 0.035197	training&#39;s myFeval: 0.484414	valid_1&#39;s l1: 0.0665095	valid_1&#39;s myFeval: 0.916592
[48300]	training&#39;s l1: 0.0351364	training&#39;s myFeval: 0.483674	valid_1&#39;s l1: 0.066512	valid_1&#39;s myFeval: 0.91659
[48600]	training&#39;s l1: 0.0350983	training&#39;s myFeval: 0.483169	valid_1&#39;s l1: 0.0665079	valid_1&#39;s myFeval: 0.916481
[48900]	training&#39;s l1: 0.0350639	training&#39;s myFeval: 0.482685	valid_1&#39;s l1: 0.0665072	valid_1&#39;s myFeval: 0.916444
[49200]	training&#39;s l1: 0.0350306	training&#39;s myFeval: 0.482231	valid_1&#39;s l1: 0.0665039	valid_1&#39;s myFeval: 0.916347
[49500]	training&#39;s l1: 0.0349961	training&#39;s myFeval: 0.481783	valid_1&#39;s l1: 0.0665033	valid_1&#39;s myFeval: 0.916334
[49800]	training&#39;s l1: 0.0349384	training&#39;s myFeval: 0.481032	valid_1&#39;s l1: 0.0665115	valid_1&#39;s myFeval: 0.916382
Early stopping, best iteration is:
[49339]	training&#39;s l1: 0.0350187	training&#39;s myFeval: 0.482073	valid_1&#39;s l1: 0.066503	valid_1&#39;s myFeval: 0.916322
fold n°10
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012890 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 9897
[LightGBM] [Info] Number of data points in the train set: 26617, number of used features: 124
[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20
[LightGBM] [Info] Start training from score 2.424803
Training until validation scores don&#39;t improve for 600 rounds
[300]	training&#39;s l1: 0.112388	training&#39;s myFeval: 2.087	valid_1&#39;s l1: 0.113208	valid_1&#39;s myFeval: 1.94498
[600]	training&#39;s l1: 0.0791707	training&#39;s myFeval: 1.27768	valid_1&#39;s l1: 0.0826433	valid_1&#39;s myFeval: 1.23645
[900]	training&#39;s l1: 0.0717636	training&#39;s myFeval: 1.08246	valid_1&#39;s l1: 0.0779443	valid_1&#39;s myFeval: 1.13991
[1200]	training&#39;s l1: 0.0679624	training&#39;s myFeval: 1.00289	valid_1&#39;s l1: 0.0759051	valid_1&#39;s myFeval: 1.10566
[1500]	training&#39;s l1: 0.0652285	training&#39;s myFeval: 0.953735	valid_1&#39;s l1: 0.074441	valid_1&#39;s myFeval: 1.07839
[1800]	training&#39;s l1: 0.0630298	training&#39;s myFeval: 0.91606	valid_1&#39;s l1: 0.0734475	valid_1&#39;s myFeval: 1.06202
[2100]	training&#39;s l1: 0.061171	training&#39;s myFeval: 0.882559	valid_1&#39;s l1: 0.0726631	valid_1&#39;s myFeval: 1.04705
[2400]	training&#39;s l1: 0.0596102	training&#39;s myFeval: 0.855285	valid_1&#39;s l1: 0.0720267	valid_1&#39;s myFeval: 1.03479
[2700]	training&#39;s l1: 0.0582365	training&#39;s myFeval: 0.833582	valid_1&#39;s l1: 0.0715293	valid_1&#39;s myFeval: 1.02677
[3000]	training&#39;s l1: 0.0570458	training&#39;s myFeval: 0.814155	valid_1&#39;s l1: 0.0711512	valid_1&#39;s myFeval: 1.01962
[3300]	training&#39;s l1: 0.0559649	training&#39;s myFeval: 0.796051	valid_1&#39;s l1: 0.0708078	valid_1&#39;s myFeval: 1.01298
[3600]	training&#39;s l1: 0.0550005	training&#39;s myFeval: 0.780937	valid_1&#39;s l1: 0.0705367	valid_1&#39;s myFeval: 1.00826
[3900]	training&#39;s l1: 0.05412	training&#39;s myFeval: 0.767012	valid_1&#39;s l1: 0.0702722	valid_1&#39;s myFeval: 1.0033
[4200]	training&#39;s l1: 0.0533057	training&#39;s myFeval: 0.754533	valid_1&#39;s l1: 0.0700338	valid_1&#39;s myFeval: 0.99917
[4500]	training&#39;s l1: 0.0525678	training&#39;s myFeval: 0.743132	valid_1&#39;s l1: 0.0698346	valid_1&#39;s myFeval: 0.995578
[4800]	training&#39;s l1: 0.051874	training&#39;s myFeval: 0.732238	valid_1&#39;s l1: 0.0696365	valid_1&#39;s myFeval: 0.992382
[5100]	training&#39;s l1: 0.051269	training&#39;s myFeval: 0.722184	valid_1&#39;s l1: 0.0694839	valid_1&#39;s myFeval: 0.98947
[5400]	training&#39;s l1: 0.0506853	training&#39;s myFeval: 0.712718	valid_1&#39;s l1: 0.0693435	valid_1&#39;s myFeval: 0.986943
[5700]	training&#39;s l1: 0.0501673	training&#39;s myFeval: 0.703847	valid_1&#39;s l1: 0.0692312	valid_1&#39;s myFeval: 0.9848
[6000]	training&#39;s l1: 0.0497036	training&#39;s myFeval: 0.697039	valid_1&#39;s l1: 0.0691617	valid_1&#39;s myFeval: 0.983411
[6300]	training&#39;s l1: 0.0492365	training&#39;s myFeval: 0.690809	valid_1&#39;s l1: 0.0690399	valid_1&#39;s myFeval: 0.981754
[6600]	training&#39;s l1: 0.0487781	training&#39;s myFeval: 0.684228	valid_1&#39;s l1: 0.0689369	valid_1&#39;s myFeval: 0.98007
[6900]	training&#39;s l1: 0.0483568	training&#39;s myFeval: 0.677868	valid_1&#39;s l1: 0.0688354	valid_1&#39;s myFeval: 0.978444
[7200]	training&#39;s l1: 0.0479728	training&#39;s myFeval: 0.672274	valid_1&#39;s l1: 0.0687252	valid_1&#39;s myFeval: 0.976637
[7500]	training&#39;s l1: 0.0476269	training&#39;s myFeval: 0.666521	valid_1&#39;s l1: 0.0686575	valid_1&#39;s myFeval: 0.975273
[7800]	training&#39;s l1: 0.0473646	training&#39;s myFeval: 0.661685	valid_1&#39;s l1: 0.0686103	valid_1&#39;s myFeval: 0.974187
[8100]	training&#39;s l1: 0.0471353	training&#39;s myFeval: 0.657784	valid_1&#39;s l1: 0.0685553	valid_1&#39;s myFeval: 0.973395
[8400]	training&#39;s l1: 0.0468011	training&#39;s myFeval: 0.65317	valid_1&#39;s l1: 0.0684788	valid_1&#39;s myFeval: 0.972388
[8700]	training&#39;s l1: 0.0464671	training&#39;s myFeval: 0.648443	valid_1&#39;s l1: 0.0684201	valid_1&#39;s myFeval: 0.97132
[9000]	training&#39;s l1: 0.0461541	training&#39;s myFeval: 0.64329	valid_1&#39;s l1: 0.0683474	valid_1&#39;s myFeval: 0.970045
[9300]	training&#39;s l1: 0.0458561	training&#39;s myFeval: 0.639411	valid_1&#39;s l1: 0.0682763	valid_1&#39;s myFeval: 0.968771
[9600]	training&#39;s l1: 0.0455764	training&#39;s myFeval: 0.635038	valid_1&#39;s l1: 0.0682119	valid_1&#39;s myFeval: 0.967423
[9900]	training&#39;s l1: 0.0453264	training&#39;s myFeval: 0.631475	valid_1&#39;s l1: 0.0681602	valid_1&#39;s myFeval: 0.966748
[10200]	training&#39;s l1: 0.0450935	training&#39;s myFeval: 0.627805	valid_1&#39;s l1: 0.0681044	valid_1&#39;s myFeval: 0.96579
[10500]	training&#39;s l1: 0.0448747	training&#39;s myFeval: 0.624861	valid_1&#39;s l1: 0.0680541	valid_1&#39;s myFeval: 0.965027
[10800]	training&#39;s l1: 0.0446535	training&#39;s myFeval: 0.622341	valid_1&#39;s l1: 0.068	valid_1&#39;s myFeval: 0.964435
[11100]	training&#39;s l1: 0.0444515	training&#39;s myFeval: 0.61989	valid_1&#39;s l1: 0.0679705	valid_1&#39;s myFeval: 0.964019
[11400]	training&#39;s l1: 0.0442551	training&#39;s myFeval: 0.61702	valid_1&#39;s l1: 0.0679297	valid_1&#39;s myFeval: 0.963496
[11700]	training&#39;s l1: 0.0440711	training&#39;s myFeval: 0.614484	valid_1&#39;s l1: 0.0678789	valid_1&#39;s myFeval: 0.962616
[12000]	training&#39;s l1: 0.0438588	training&#39;s myFeval: 0.611326	valid_1&#39;s l1: 0.0678437	valid_1&#39;s myFeval: 0.961902
[12300]	training&#39;s l1: 0.043662	training&#39;s myFeval: 0.608332	valid_1&#39;s l1: 0.0678179	valid_1&#39;s myFeval: 0.961593
[12600]	training&#39;s l1: 0.0434873	training&#39;s myFeval: 0.605862	valid_1&#39;s l1: 0.0677825	valid_1&#39;s myFeval: 0.960917
[12900]	training&#39;s l1: 0.0433451	training&#39;s myFeval: 0.60421	valid_1&#39;s l1: 0.0677462	valid_1&#39;s myFeval: 0.960474
[13200]	training&#39;s l1: 0.0431956	training&#39;s myFeval: 0.602231	valid_1&#39;s l1: 0.0677175	valid_1&#39;s myFeval: 0.959844
[13500]	training&#39;s l1: 0.0430285	training&#39;s myFeval: 0.599647	valid_1&#39;s l1: 0.0676966	valid_1&#39;s myFeval: 0.959405
[13800]	training&#39;s l1: 0.0428444	training&#39;s myFeval: 0.597114	valid_1&#39;s l1: 0.0676744	valid_1&#39;s myFeval: 0.958997
[14100]	training&#39;s l1: 0.0426929	training&#39;s myFeval: 0.594715	valid_1&#39;s l1: 0.0676354	valid_1&#39;s myFeval: 0.958276
[14400]	training&#39;s l1: 0.0425448	training&#39;s myFeval: 0.592497	valid_1&#39;s l1: 0.067613	valid_1&#39;s myFeval: 0.957725
[14700]	training&#39;s l1: 0.0423826	training&#39;s myFeval: 0.590274	valid_1&#39;s l1: 0.0675828	valid_1&#39;s myFeval: 0.957207
[15000]	training&#39;s l1: 0.0422409	training&#39;s myFeval: 0.588118	valid_1&#39;s l1: 0.0675516	valid_1&#39;s myFeval: 0.956673
[15300]	training&#39;s l1: 0.042122	training&#39;s myFeval: 0.586402	valid_1&#39;s l1: 0.0675224	valid_1&#39;s myFeval: 0.956041
[15600]	training&#39;s l1: 0.0419997	training&#39;s myFeval: 0.584492	valid_1&#39;s l1: 0.0674908	valid_1&#39;s myFeval: 0.955228
[15900]	training&#39;s l1: 0.0418857	training&#39;s myFeval: 0.582806	valid_1&#39;s l1: 0.0674685	valid_1&#39;s myFeval: 0.954858
[16200]	training&#39;s l1: 0.0417652	training&#39;s myFeval: 0.58098	valid_1&#39;s l1: 0.0674486	valid_1&#39;s myFeval: 0.954447
[16500]	training&#39;s l1: 0.041645	training&#39;s myFeval: 0.579204	valid_1&#39;s l1: 0.0674289	valid_1&#39;s myFeval: 0.953893
[16800]	training&#39;s l1: 0.0415366	training&#39;s myFeval: 0.577644	valid_1&#39;s l1: 0.0674083	valid_1&#39;s myFeval: 0.953374
[17100]	training&#39;s l1: 0.0414394	training&#39;s myFeval: 0.576247	valid_1&#39;s l1: 0.0673932	valid_1&#39;s myFeval: 0.952905
[17400]	training&#39;s l1: 0.0413388	training&#39;s myFeval: 0.574808	valid_1&#39;s l1: 0.0673756	valid_1&#39;s myFeval: 0.952705
[17700]	training&#39;s l1: 0.0411708	training&#39;s myFeval: 0.572785	valid_1&#39;s l1: 0.0673784	valid_1&#39;s myFeval: 0.952663
[18000]	training&#39;s l1: 0.0410199	training&#39;s myFeval: 0.570833	valid_1&#39;s l1: 0.0673466	valid_1&#39;s myFeval: 0.952075
[18300]	training&#39;s l1: 0.0409193	training&#39;s myFeval: 0.569375	valid_1&#39;s l1: 0.0673294	valid_1&#39;s myFeval: 0.951884
[18600]	training&#39;s l1: 0.0408101	training&#39;s myFeval: 0.56788	valid_1&#39;s l1: 0.0673037	valid_1&#39;s myFeval: 0.951527
[18900]	training&#39;s l1: 0.0407202	training&#39;s myFeval: 0.566532	valid_1&#39;s l1: 0.0672995	valid_1&#39;s myFeval: 0.951246
[19200]	training&#39;s l1: 0.0406302	training&#39;s myFeval: 0.565349	valid_1&#39;s l1: 0.0672961	valid_1&#39;s myFeval: 0.950993
[19500]	training&#39;s l1: 0.0405229	training&#39;s myFeval: 0.563823	valid_1&#39;s l1: 0.0672829	valid_1&#39;s myFeval: 0.950719
[19800]	training&#39;s l1: 0.0404185	training&#39;s myFeval: 0.562248	valid_1&#39;s l1: 0.0672559	valid_1&#39;s myFeval: 0.950164
[20100]	training&#39;s l1: 0.0403256	training&#39;s myFeval: 0.56101	valid_1&#39;s l1: 0.0672513	valid_1&#39;s myFeval: 0.949997
[20400]	training&#39;s l1: 0.0402295	training&#39;s myFeval: 0.559689	valid_1&#39;s l1: 0.0672154	valid_1&#39;s myFeval: 0.949378
[20700]	training&#39;s l1: 0.0401304	training&#39;s myFeval: 0.558185	valid_1&#39;s l1: 0.0671978	valid_1&#39;s myFeval: 0.949125
[21000]	training&#39;s l1: 0.0400251	training&#39;s myFeval: 0.556663	valid_1&#39;s l1: 0.0671799	valid_1&#39;s myFeval: 0.948773
[21300]	training&#39;s l1: 0.0399264	training&#39;s myFeval: 0.555518	valid_1&#39;s l1: 0.0671598	valid_1&#39;s myFeval: 0.948551
[21600]	training&#39;s l1: 0.0398254	training&#39;s myFeval: 0.55422	valid_1&#39;s l1: 0.0671345	valid_1&#39;s myFeval: 0.948248
[21900]	training&#39;s l1: 0.0397253	training&#39;s myFeval: 0.552869	valid_1&#39;s l1: 0.0671181	valid_1&#39;s myFeval: 0.94794
[22200]	training&#39;s l1: 0.0396283	training&#39;s myFeval: 0.551467	valid_1&#39;s l1: 0.0671052	valid_1&#39;s myFeval: 0.947607
[22500]	training&#39;s l1: 0.0395382	training&#39;s myFeval: 0.550181	valid_1&#39;s l1: 0.0670891	valid_1&#39;s myFeval: 0.947263
[22800]	training&#39;s l1: 0.039458	training&#39;s myFeval: 0.54889	valid_1&#39;s l1: 0.0670739	valid_1&#39;s myFeval: 0.946872
[23100]	training&#39;s l1: 0.0393911	training&#39;s myFeval: 0.548032	valid_1&#39;s l1: 0.0670575	valid_1&#39;s myFeval: 0.94659
[23400]	training&#39;s l1: 0.0393193	training&#39;s myFeval: 0.547027	valid_1&#39;s l1: 0.0670433	valid_1&#39;s myFeval: 0.94638
[23700]	training&#39;s l1: 0.0392356	training&#39;s myFeval: 0.545747	valid_1&#39;s l1: 0.0670307	valid_1&#39;s myFeval: 0.946064
[24000]	training&#39;s l1: 0.0391551	training&#39;s myFeval: 0.544507	valid_1&#39;s l1: 0.0670065	valid_1&#39;s myFeval: 0.945611
[24300]	training&#39;s l1: 0.0390767	training&#39;s myFeval: 0.543317	valid_1&#39;s l1: 0.0669994	valid_1&#39;s myFeval: 0.945379
[24600]	training&#39;s l1: 0.0389946	training&#39;s myFeval: 0.542243	valid_1&#39;s l1: 0.0669887	valid_1&#39;s myFeval: 0.945098
[24900]	training&#39;s l1: 0.0389182	training&#39;s myFeval: 0.541131	valid_1&#39;s l1: 0.0669706	valid_1&#39;s myFeval: 0.944746
[25200]	training&#39;s l1: 0.0388369	training&#39;s myFeval: 0.539768	valid_1&#39;s l1: 0.0669608	valid_1&#39;s myFeval: 0.944488
[25500]	training&#39;s l1: 0.0387667	training&#39;s myFeval: 0.538537	valid_1&#39;s l1: 0.0669418	valid_1&#39;s myFeval: 0.944005
[25800]	training&#39;s l1: 0.0387008	training&#39;s myFeval: 0.537529	valid_1&#39;s l1: 0.0669286	valid_1&#39;s myFeval: 0.943771
[26100]	training&#39;s l1: 0.0386382	training&#39;s myFeval: 0.536536	valid_1&#39;s l1: 0.0669153	valid_1&#39;s myFeval: 0.943543
[26400]	training&#39;s l1: 0.0385695	training&#39;s myFeval: 0.535384	valid_1&#39;s l1: 0.0668969	valid_1&#39;s myFeval: 0.94313
[26700]	training&#39;s l1: 0.0385009	training&#39;s myFeval: 0.534314	valid_1&#39;s l1: 0.0668872	valid_1&#39;s myFeval: 0.942942
[27000]	training&#39;s l1: 0.0384267	training&#39;s myFeval: 0.533205	valid_1&#39;s l1: 0.0668755	valid_1&#39;s myFeval: 0.942747
[27300]	training&#39;s l1: 0.0383498	training&#39;s myFeval: 0.532113	valid_1&#39;s l1: 0.0668579	valid_1&#39;s myFeval: 0.942424
[27600]	training&#39;s l1: 0.038285	training&#39;s myFeval: 0.531102	valid_1&#39;s l1: 0.0668475	valid_1&#39;s myFeval: 0.94226
[27900]	training&#39;s l1: 0.0382255	training&#39;s myFeval: 0.529972	valid_1&#39;s l1: 0.0668359	valid_1&#39;s myFeval: 0.942112
[28200]	training&#39;s l1: 0.0381609	training&#39;s myFeval: 0.528989	valid_1&#39;s l1: 0.0668259	valid_1&#39;s myFeval: 0.941933
[28500]	training&#39;s l1: 0.0380984	training&#39;s myFeval: 0.528056	valid_1&#39;s l1: 0.0668128	valid_1&#39;s myFeval: 0.941691
[28800]	training&#39;s l1: 0.0380432	training&#39;s myFeval: 0.527077	valid_1&#39;s l1: 0.0668026	valid_1&#39;s myFeval: 0.941454
[29100]	training&#39;s l1: 0.0379752	training&#39;s myFeval: 0.525759	valid_1&#39;s l1: 0.0667883	valid_1&#39;s myFeval: 0.94117
[29400]	training&#39;s l1: 0.0379098	training&#39;s myFeval: 0.524795	valid_1&#39;s l1: 0.066777	valid_1&#39;s myFeval: 0.940984
[29700]	training&#39;s l1: 0.0378546	training&#39;s myFeval: 0.523915	valid_1&#39;s l1: 0.0667649	valid_1&#39;s myFeval: 0.940724
[30000]	training&#39;s l1: 0.0377954	training&#39;s myFeval: 0.522975	valid_1&#39;s l1: 0.0667565	valid_1&#39;s myFeval: 0.940551
[30300]	training&#39;s l1: 0.0377389	training&#39;s myFeval: 0.522105	valid_1&#39;s l1: 0.0667466	valid_1&#39;s myFeval: 0.940334
[30600]	training&#39;s l1: 0.037679	training&#39;s myFeval: 0.521162	valid_1&#39;s l1: 0.0667354	valid_1&#39;s myFeval: 0.940133
[30900]	training&#39;s l1: 0.0376089	training&#39;s myFeval: 0.520351	valid_1&#39;s l1: 0.0667234	valid_1&#39;s myFeval: 0.939908
[31200]	training&#39;s l1: 0.0375335	training&#39;s myFeval: 0.519436	valid_1&#39;s l1: 0.0667021	valid_1&#39;s myFeval: 0.939592
[31500]	training&#39;s l1: 0.0374737	training&#39;s myFeval: 0.518603	valid_1&#39;s l1: 0.0666913	valid_1&#39;s myFeval: 0.939435
[31800]	training&#39;s l1: 0.0374345	training&#39;s myFeval: 0.517971	valid_1&#39;s l1: 0.0666815	valid_1&#39;s myFeval: 0.939278
[32100]	training&#39;s l1: 0.0373751	training&#39;s myFeval: 0.517113	valid_1&#39;s l1: 0.066674	valid_1&#39;s myFeval: 0.939196
[32400]	training&#39;s l1: 0.0373163	training&#39;s myFeval: 0.516273	valid_1&#39;s l1: 0.0666654	valid_1&#39;s myFeval: 0.939095
[32700]	training&#39;s l1: 0.0372586	training&#39;s myFeval: 0.515386	valid_1&#39;s l1: 0.0666518	valid_1&#39;s myFeval: 0.938918
[33000]	training&#39;s l1: 0.0371999	training&#39;s myFeval: 0.514512	valid_1&#39;s l1: 0.0666451	valid_1&#39;s myFeval: 0.938837
[33300]	training&#39;s l1: 0.0371442	training&#39;s myFeval: 0.513629	valid_1&#39;s l1: 0.0666315	valid_1&#39;s myFeval: 0.938569
[33600]	training&#39;s l1: 0.0370881	training&#39;s myFeval: 0.512759	valid_1&#39;s l1: 0.0666185	valid_1&#39;s myFeval: 0.938325
[33900]	training&#39;s l1: 0.0370282	training&#39;s myFeval: 0.511884	valid_1&#39;s l1: 0.0666084	valid_1&#39;s myFeval: 0.938084
[34200]	training&#39;s l1: 0.0369714	training&#39;s myFeval: 0.511083	valid_1&#39;s l1: 0.0666049	valid_1&#39;s myFeval: 0.937975
[34500]	training&#39;s l1: 0.0369223	training&#39;s myFeval: 0.510302	valid_1&#39;s l1: 0.0665976	valid_1&#39;s myFeval: 0.937823
[34800]	training&#39;s l1: 0.0368738	training&#39;s myFeval: 0.509571	valid_1&#39;s l1: 0.0665866	valid_1&#39;s myFeval: 0.937579
[35100]	training&#39;s l1: 0.0368226	training&#39;s myFeval: 0.508757	valid_1&#39;s l1: 0.0665792	valid_1&#39;s myFeval: 0.937504
[35400]	training&#39;s l1: 0.0367749	training&#39;s myFeval: 0.50798	valid_1&#39;s l1: 0.0665661	valid_1&#39;s myFeval: 0.937233
[35700]	training&#39;s l1: 0.0367199	training&#39;s myFeval: 0.506972	valid_1&#39;s l1: 0.0665603	valid_1&#39;s myFeval: 0.93704
[36000]	training&#39;s l1: 0.036667	training&#39;s myFeval: 0.506116	valid_1&#39;s l1: 0.0665496	valid_1&#39;s myFeval: 0.936839
[36300]	training&#39;s l1: 0.0366001	training&#39;s myFeval: 0.505316	valid_1&#39;s l1: 0.0665294	valid_1&#39;s myFeval: 0.936582
[36600]	training&#39;s l1: 0.0365461	training&#39;s myFeval: 0.504633	valid_1&#39;s l1: 0.0665175	valid_1&#39;s myFeval: 0.936424
[36900]	training&#39;s l1: 0.0365045	training&#39;s myFeval: 0.504082	valid_1&#39;s l1: 0.0665111	valid_1&#39;s myFeval: 0.93629
[37200]	training&#39;s l1: 0.0364617	training&#39;s myFeval: 0.503476	valid_1&#39;s l1: 0.0664991	valid_1&#39;s myFeval: 0.936118
[37500]	training&#39;s l1: 0.0364191	training&#39;s myFeval: 0.502883	valid_1&#39;s l1: 0.0664921	valid_1&#39;s myFeval: 0.935984
[37800]	training&#39;s l1: 0.0363505	training&#39;s myFeval: 0.50211	valid_1&#39;s l1: 0.0664728	valid_1&#39;s myFeval: 0.935756
[38100]	training&#39;s l1: 0.0362814	training&#39;s myFeval: 0.501321	valid_1&#39;s l1: 0.0664653	valid_1&#39;s myFeval: 0.935634
[38400]	training&#39;s l1: 0.0362168	training&#39;s myFeval: 0.50056	valid_1&#39;s l1: 0.0664639	valid_1&#39;s myFeval: 0.935595
[38700]	training&#39;s l1: 0.0361644	training&#39;s myFeval: 0.499855	valid_1&#39;s l1: 0.0664608	valid_1&#39;s myFeval: 0.935607
[39000]	training&#39;s l1: 0.0361084	training&#39;s myFeval: 0.499137	valid_1&#39;s l1: 0.0664576	valid_1&#39;s myFeval: 0.935569
[39300]	training&#39;s l1: 0.0360659	training&#39;s myFeval: 0.498547	valid_1&#39;s l1: 0.0664494	valid_1&#39;s myFeval: 0.935471
[39600]	training&#39;s l1: 0.0360204	training&#39;s myFeval: 0.497914	valid_1&#39;s l1: 0.066444	valid_1&#39;s myFeval: 0.935373
[39900]	training&#39;s l1: 0.035977	training&#39;s myFeval: 0.497207	valid_1&#39;s l1: 0.0664352	valid_1&#39;s myFeval: 0.9352
[40200]	training&#39;s l1: 0.0359341	training&#39;s myFeval: 0.496532	valid_1&#39;s l1: 0.0664258	valid_1&#39;s myFeval: 0.935058
[40500]	training&#39;s l1: 0.0358904	training&#39;s myFeval: 0.495799	valid_1&#39;s l1: 0.0664194	valid_1&#39;s myFeval: 0.934911
[40800]	training&#39;s l1: 0.0358484	training&#39;s myFeval: 0.495165	valid_1&#39;s l1: 0.0664125	valid_1&#39;s myFeval: 0.934736
[41100]	training&#39;s l1: 0.0358051	training&#39;s myFeval: 0.494436	valid_1&#39;s l1: 0.0664068	valid_1&#39;s myFeval: 0.934566
[41400]	training&#39;s l1: 0.0357693	training&#39;s myFeval: 0.493859	valid_1&#39;s l1: 0.0664023	valid_1&#39;s myFeval: 0.93444
[41700]	training&#39;s l1: 0.0357269	training&#39;s myFeval: 0.493208	valid_1&#39;s l1: 0.0663953	valid_1&#39;s myFeval: 0.934288
[42000]	training&#39;s l1: 0.0356861	training&#39;s myFeval: 0.492592	valid_1&#39;s l1: 0.066388	valid_1&#39;s myFeval: 0.934245
[42300]	training&#39;s l1: 0.0356488	training&#39;s myFeval: 0.492003	valid_1&#39;s l1: 0.0663784	valid_1&#39;s myFeval: 0.934101
[42600]	training&#39;s l1: 0.0356117	training&#39;s myFeval: 0.491449	valid_1&#39;s l1: 0.0663816	valid_1&#39;s myFeval: 0.93412
[42900]	training&#39;s l1: 0.0355816	training&#39;s myFeval: 0.490955	valid_1&#39;s l1: 0.0663777	valid_1&#39;s myFeval: 0.934036
[43200]	training&#39;s l1: 0.0355459	training&#39;s myFeval: 0.49042	valid_1&#39;s l1: 0.0663747	valid_1&#39;s myFeval: 0.933961
[43500]	training&#39;s l1: 0.0355111	training&#39;s myFeval: 0.489868	valid_1&#39;s l1: 0.0663682	valid_1&#39;s myFeval: 0.93384
[43800]	training&#39;s l1: 0.0354714	training&#39;s myFeval: 0.489219	valid_1&#39;s l1: 0.0663616	valid_1&#39;s myFeval: 0.933708
[44100]	training&#39;s l1: 0.0354332	training&#39;s myFeval: 0.488644	valid_1&#39;s l1: 0.0663559	valid_1&#39;s myFeval: 0.933648
[44400]	training&#39;s l1: 0.0353977	training&#39;s myFeval: 0.488101	valid_1&#39;s l1: 0.0663526	valid_1&#39;s myFeval: 0.933557
[44700]	training&#39;s l1: 0.0353607	training&#39;s myFeval: 0.487542	valid_1&#39;s l1: 0.0663482	valid_1&#39;s myFeval: 0.93344
[45000]	training&#39;s l1: 0.0353255	training&#39;s myFeval: 0.48699	valid_1&#39;s l1: 0.0663393	valid_1&#39;s myFeval: 0.933304
[45300]	training&#39;s l1: 0.0352863	training&#39;s myFeval: 0.486445	valid_1&#39;s l1: 0.0663297	valid_1&#39;s myFeval: 0.933229
[45600]	training&#39;s l1: 0.0352531	training&#39;s myFeval: 0.485906	valid_1&#39;s l1: 0.066325	valid_1&#39;s myFeval: 0.93309
[45900]	training&#39;s l1: 0.035214	training&#39;s myFeval: 0.485325	valid_1&#39;s l1: 0.0663183	valid_1&#39;s myFeval: 0.932976
[46200]	training&#39;s l1: 0.0351603	training&#39;s myFeval: 0.484681	valid_1&#39;s l1: 0.0663138	valid_1&#39;s myFeval: 0.932907
[46500]	training&#39;s l1: 0.035122	training&#39;s myFeval: 0.484165	valid_1&#39;s l1: 0.0663119	valid_1&#39;s myFeval: 0.932851
[46800]	training&#39;s l1: 0.0350881	training&#39;s myFeval: 0.483593	valid_1&#39;s l1: 0.0663058	valid_1&#39;s myFeval: 0.932779
[47100]	training&#39;s l1: 0.0350446	training&#39;s myFeval: 0.483034	valid_1&#39;s l1: 0.0663021	valid_1&#39;s myFeval: 0.932686
[47400]	training&#39;s l1: 0.0349976	training&#39;s myFeval: 0.482432	valid_1&#39;s l1: 0.0663003	valid_1&#39;s myFeval: 0.932643
[47700]	training&#39;s l1: 0.0349484	training&#39;s myFeval: 0.481807	valid_1&#39;s l1: 0.0662945	valid_1&#39;s myFeval: 0.93254
[48000]	training&#39;s l1: 0.0349038	training&#39;s myFeval: 0.481236	valid_1&#39;s l1: 0.0662887	valid_1&#39;s myFeval: 0.9325
[48300]	training&#39;s l1: 0.034867	training&#39;s myFeval: 0.480699	valid_1&#39;s l1: 0.0662852	valid_1&#39;s myFeval: 0.93241
[48600]	training&#39;s l1: 0.0348328	training&#39;s myFeval: 0.480187	valid_1&#39;s l1: 0.0662766	valid_1&#39;s myFeval: 0.932299
[48900]	training&#39;s l1: 0.0348011	training&#39;s myFeval: 0.479633	valid_1&#39;s l1: 0.0662713	valid_1&#39;s myFeval: 0.932189
[49200]	training&#39;s l1: 0.0347743	training&#39;s myFeval: 0.479163	valid_1&#39;s l1: 0.0662675	valid_1&#39;s myFeval: 0.93212
[49500]	training&#39;s l1: 0.0347493	training&#39;s myFeval: 0.478745	valid_1&#39;s l1: 0.0662641	valid_1&#39;s myFeval: 0.932044
[49800]	training&#39;s l1: 0.0347241	training&#39;s myFeval: 0.478335	valid_1&#39;s l1: 0.0662601	valid_1&#39;s myFeval: 0.931939
[50100]	training&#39;s l1: 0.0346994	training&#39;s myFeval: 0.477895	valid_1&#39;s l1: 0.0662562	valid_1&#39;s myFeval: 0.931882
[50400]	training&#39;s l1: 0.0346711	training&#39;s myFeval: 0.477474	valid_1&#39;s l1: 0.0662544	valid_1&#39;s myFeval: 0.93186
[50700]	training&#39;s l1: 0.0346423	training&#39;s myFeval: 0.477048	valid_1&#39;s l1: 0.0662507	valid_1&#39;s myFeval: 0.93179
[51000]	training&#39;s l1: 0.0345911	training&#39;s myFeval: 0.476385	valid_1&#39;s l1: 0.0662451	valid_1&#39;s myFeval: 0.931692
[51300]	training&#39;s l1: 0.0345393	training&#39;s myFeval: 0.475729	valid_1&#39;s l1: 0.0662451	valid_1&#39;s myFeval: 0.931678
[51600]	training&#39;s l1: 0.0345091	training&#39;s myFeval: 0.475272	valid_1&#39;s l1: 0.0662408	valid_1&#39;s myFeval: 0.931615
[51900]	training&#39;s l1: 0.0344747	training&#39;s myFeval: 0.474729	valid_1&#39;s l1: 0.0662345	valid_1&#39;s myFeval: 0.931523
[52200]	training&#39;s l1: 0.0344483	training&#39;s myFeval: 0.474304	valid_1&#39;s l1: 0.0662289	valid_1&#39;s myFeval: 0.931409
[52500]	training&#39;s l1: 0.0344194	training&#39;s myFeval: 0.473886	valid_1&#39;s l1: 0.0662251	valid_1&#39;s myFeval: 0.931365
[52800]	training&#39;s l1: 0.0343892	training&#39;s myFeval: 0.473426	valid_1&#39;s l1: 0.066218	valid_1&#39;s myFeval: 0.931238
[53100]	training&#39;s l1: 0.0343606	training&#39;s myFeval: 0.473003	valid_1&#39;s l1: 0.0662149	valid_1&#39;s myFeval: 0.931176
[53400]	training&#39;s l1: 0.0343296	training&#39;s myFeval: 0.47255	valid_1&#39;s l1: 0.0662122	valid_1&#39;s myFeval: 0.931147
[53700]	training&#39;s l1: 0.0342973	training&#39;s myFeval: 0.472063	valid_1&#39;s l1: 0.0662071	valid_1&#39;s myFeval: 0.931024
[54000]	training&#39;s l1: 0.0342713	training&#39;s myFeval: 0.471653	valid_1&#39;s l1: 0.0662046	valid_1&#39;s myFeval: 0.930997
[54300]	training&#39;s l1: 0.0342436	training&#39;s myFeval: 0.471263	valid_1&#39;s l1: 0.0661987	valid_1&#39;s myFeval: 0.930861
[54600]	training&#39;s l1: 0.0342176	training&#39;s myFeval: 0.470891	valid_1&#39;s l1: 0.0661911	valid_1&#39;s myFeval: 0.930716
[54900]	training&#39;s l1: 0.0341818	training&#39;s myFeval: 0.470389	valid_1&#39;s l1: 0.0661875	valid_1&#39;s myFeval: 0.930644
[55200]	training&#39;s l1: 0.0341044	training&#39;s myFeval: 0.469354	valid_1&#39;s l1: 0.0661912	valid_1&#39;s myFeval: 0.930762
Early stopping, best iteration is:
[54859]	training&#39;s l1: 0.0341906	training&#39;s myFeval: 0.47051	valid_1&#39;s l1: 0.0661864	valid_1&#39;s myFeval: 0.93061
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[153]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lightgbm score: </span><span class="si">{:&lt;8.8f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">oof_lgb</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">Y_data</span><span class="p">))))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>lightgbm score: 0.94371396
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[154]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Model_Evaluate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">oof_lgb</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">Y_train</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[154]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(0.5653970405441818, 0.4797795360789883, 0.09213294159504425)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[155]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions_lgb</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[155]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([2.97893488, 2.49167778, 1.18187019, ..., 2.05622709, 1.40278638,
       2.73605528])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[156]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#保存lgb结果</span>
<span class="n">lgb_predict</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predictions_lgb</span><span class="p">)),</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">,</span><span class="s1">&#39;price_predict&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[157]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lgb_predict</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">test_carid</span><span class="o">.</span><span class="n">values</span>
<span class="n">lgb_predict</span><span class="p">[</span><span class="s1">&#39;price_predict&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictions_lgb</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[168]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lgb_predict</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;E:/Mather Cup/Coding/dataset/lgb_predict.xlsx&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="02-catBoost">02 catBoost<a class="anchor-link" href="#02-catBoost">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[160]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">kfolder</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2018</span><span class="p">)</span>
<span class="n">oof_cb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_data</span><span class="p">))</span>
<span class="n">predictions_cb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_data_test</span><span class="p">))</span>
<span class="n">predictions_train_cb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_data</span><span class="p">))</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">kfolder</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">Y_data</span><span class="p">)</span>
<span class="n">fold_</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[161]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">vali_index</span> <span class="ow">in</span> <span class="n">kfold</span><span class="p">:</span>
    <span class="n">fold_</span> <span class="o">=</span> <span class="n">fold_</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;fold n°</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fold_</span><span class="p">))</span>
    <span class="n">k_x_train</span> <span class="o">=</span> <span class="n">X_data</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
    <span class="n">k_y_train</span> <span class="o">=</span> <span class="n">Y_data</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
    <span class="n">k_x_vali</span> <span class="o">=</span> <span class="n">X_data</span><span class="p">[</span><span class="n">vali_index</span><span class="p">]</span>
    <span class="n">k_y_vali</span> <span class="o">=</span> <span class="n">Y_data</span><span class="p">[</span><span class="n">vali_index</span><span class="p">]</span>
    <span class="n">cb_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">100000000</span><span class="p">,</span>
        <span class="s1">&#39;loss_function&#39;</span><span class="p">:</span> <span class="s1">&#39;MAE&#39;</span><span class="p">,</span>
        <span class="s1">&#39;eval_metric&#39;</span><span class="p">:</span> <span class="s1">&#39;MAE&#39;</span><span class="p">,</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="s1">&#39;depth&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="s1">&#39;use_best_model&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span>
        <span class="s1">&#39;bootstrap_type&#39;</span><span class="p">:</span> <span class="s1">&#39;Bernoulli&#39;</span><span class="p">,</span>
        <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;one_hot_max_size&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">model_cb</span> <span class="o">=</span> <span class="n">CatBoostRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">cb_params</span><span class="p">)</span>
    <span class="c1"># train the model</span>
    <span class="n">model_cb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">k_x_train</span><span class="p">,</span> <span class="n">k_y_train</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">k_x_vali</span><span class="p">,</span> <span class="n">k_y_vali</span><span class="p">)],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">600</span><span class="p">)</span>
    <span class="n">oof_cb</span><span class="p">[</span><span class="n">vali_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_cb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">k_x_vali</span><span class="p">,</span> <span class="n">ntree_end</span><span class="o">=</span><span class="n">model_cb</span><span class="o">.</span><span class="n">best_iteration_</span><span class="p">)</span>
    <span class="n">predictions_cb</span> <span class="o">+=</span> <span class="n">model_cb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_data_test</span><span class="p">,</span> <span class="n">ntree_end</span><span class="o">=</span><span class="n">model_cb</span><span class="o">.</span><span class="n">best_iteration_</span><span class="p">)</span> <span class="o">/</span> <span class="n">kfolder</span><span class="o">.</span><span class="n">n_splits</span>
    <span class="n">predictions_train_cb</span> <span class="o">+=</span> <span class="n">model_cb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span> <span class="n">ntree_end</span><span class="o">=</span><span class="n">model_cb</span><span class="o">.</span><span class="n">best_iteration_</span><span class="p">)</span> <span class="o">/</span> <span class="n">kfolder</span><span class="o">.</span><span class="n">n_splits</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>fold n°1
0:	learn: 0.5712874	test: 0.5538403	best: 0.5538403 (0)	total: 8.63ms	remaining: 9d 23h 52m 40s
300:	learn: 0.1342443	test: 0.1299768	best: 0.1299768 (300)	total: 2.38s	remaining: 9d 3h 34m 37s
600:	learn: 0.0982407	test: 0.0972442	best: 0.0972442 (600)	total: 4.77s	remaining: 9d 4h 28m 55s
900:	learn: 0.0892324	test: 0.0892560	best: 0.0892560 (900)	total: 7.18s	remaining: 9d 5h 30m 17s
1200:	learn: 0.0839525	test: 0.0846886	best: 0.0846886 (1200)	total: 9.5s	remaining: 9d 3h 43m 29s
1500:	learn: 0.0800151	test: 0.0813748	best: 0.0813748 (1500)	total: 11.8s	remaining: 9d 2h 53s
1800:	learn: 0.0769634	test: 0.0791094	best: 0.0791094 (1800)	total: 14.1s	remaining: 9d 1h 14m 24s
2100:	learn: 0.0745756	test: 0.0773530	best: 0.0773530 (2100)	total: 16.4s	remaining: 9d 1h 28m 43s
2400:	learn: 0.0726236	test: 0.0760158	best: 0.0760158 (2400)	total: 18.7s	remaining: 9d 52m 17s
2700:	learn: 0.0710117	test: 0.0749512	best: 0.0749512 (2700)	total: 21.1s	remaining: 9d 1h 20m 41s
3000:	learn: 0.0696651	test: 0.0740821	best: 0.0740821 (3000)	total: 23.4s	remaining: 9d 42m 37s
3300:	learn: 0.0683999	test: 0.0732912	best: 0.0732912 (3300)	total: 25.7s	remaining: 9d 36m 5s
3600:	learn: 0.0672643	test: 0.0725768	best: 0.0725768 (3600)	total: 28.2s	remaining: 9d 1h 35m 6s
3900:	learn: 0.0662798	test: 0.0720410	best: 0.0720410 (3900)	total: 30.5s	remaining: 9d 1h 23m 21s
4200:	learn: 0.0653962	test: 0.0715296	best: 0.0715290 (4199)	total: 32.8s	remaining: 9d 59m 29s
4500:	learn: 0.0645506	test: 0.0710711	best: 0.0710702 (4499)	total: 35.1s	remaining: 9d 39m 49s
4800:	learn: 0.0638006	test: 0.0707143	best: 0.0707143 (4800)	total: 37.4s	remaining: 9d 24m 28s
5100:	learn: 0.0631117	test: 0.0703557	best: 0.0703557 (5100)	total: 39.7s	remaining: 9d 8m 23s
5400:	learn: 0.0624823	test: 0.0700630	best: 0.0700630 (5400)	total: 42s	remaining: 8d 23h 48m 33s
5700:	learn: 0.0618715	test: 0.0697759	best: 0.0697747 (5698)	total: 44.2s	remaining: 8d 23h 32m 47s
6000:	learn: 0.0612957	test: 0.0695047	best: 0.0695047 (6000)	total: 46.5s	remaining: 8d 23h 22m 47s
6300:	learn: 0.0607480	test: 0.0692596	best: 0.0692596 (6300)	total: 48.8s	remaining: 8d 23h 11m 6s
6600:	learn: 0.0602535	test: 0.0690356	best: 0.0690356 (6600)	total: 51.1s	remaining: 8d 22h 57m 7s
6900:	learn: 0.0597632	test: 0.0688048	best: 0.0688048 (6900)	total: 53.4s	remaining: 8d 22h 49m 33s
7200:	learn: 0.0593145	test: 0.0686176	best: 0.0686176 (7200)	total: 55.7s	remaining: 8d 22h 49m 19s
7500:	learn: 0.0588885	test: 0.0684659	best: 0.0684659 (7500)	total: 58s	remaining: 8d 22h 35m 26s
7800:	learn: 0.0584671	test: 0.0682989	best: 0.0682983 (7799)	total: 1m	remaining: 8d 22h 27m 8s
8100:	learn: 0.0580815	test: 0.0681701	best: 0.0681701 (8100)	total: 1m 2s	remaining: 8d 22h 18m 5s
8400:	learn: 0.0577151	test: 0.0680345	best: 0.0680345 (8400)	total: 1m 4s	remaining: 8d 22h 15m 35s
8700:	learn: 0.0573468	test: 0.0679070	best: 0.0679070 (8700)	total: 1m 7s	remaining: 8d 22h 9m 14s
9000:	learn: 0.0569912	test: 0.0677940	best: 0.0677940 (9000)	total: 1m 9s	remaining: 8d 22h 1m 31s
9300:	learn: 0.0566503	test: 0.0676810	best: 0.0676801 (9299)	total: 1m 11s	remaining: 8d 21h 54m 27s
9600:	learn: 0.0563184	test: 0.0675550	best: 0.0675550 (9600)	total: 1m 13s	remaining: 8d 21h 51m 16s
9900:	learn: 0.0560047	test: 0.0674526	best: 0.0674526 (9900)	total: 1m 16s	remaining: 8d 21h 46m 33s
10200:	learn: 0.0557128	test: 0.0673504	best: 0.0673504 (10200)	total: 1m 18s	remaining: 8d 21h 38m 13s
10500:	learn: 0.0554218	test: 0.0672733	best: 0.0672733 (10500)	total: 1m 20s	remaining: 8d 21h 32m 20s
10800:	learn: 0.0551422	test: 0.0671890	best: 0.0671890 (10800)	total: 1m 23s	remaining: 8d 21h 45m 37s
11100:	learn: 0.0548776	test: 0.0671023	best: 0.0671023 (11100)	total: 1m 25s	remaining: 8d 21h 42m 19s
11400:	learn: 0.0546209	test: 0.0670324	best: 0.0670311 (11395)	total: 1m 27s	remaining: 8d 21h 35m 2s
11700:	learn: 0.0543703	test: 0.0669625	best: 0.0669607 (11697)	total: 1m 29s	remaining: 8d 21h 32m 52s
12000:	learn: 0.0541418	test: 0.0668976	best: 0.0668967 (11995)	total: 1m 32s	remaining: 8d 21h 26m 13s
12300:	learn: 0.0539147	test: 0.0668386	best: 0.0668386 (12284)	total: 1m 34s	remaining: 8d 21h 30m 22s
12600:	learn: 0.0536856	test: 0.0667841	best: 0.0667837 (12597)	total: 1m 36s	remaining: 8d 21h 25m 56s
12900:	learn: 0.0534675	test: 0.0667207	best: 0.0667207 (12899)	total: 1m 39s	remaining: 8d 21h 19m 1s
13200:	learn: 0.0532581	test: 0.0666546	best: 0.0666546 (13200)	total: 1m 41s	remaining: 8d 21h 16m 1s
13500:	learn: 0.0530671	test: 0.0665968	best: 0.0665968 (13500)	total: 1m 43s	remaining: 8d 21h 11m 35s
13800:	learn: 0.0528775	test: 0.0665422	best: 0.0665422 (13800)	total: 1m 45s	remaining: 8d 21h 12m 53s
14100:	learn: 0.0526983	test: 0.0664999	best: 0.0664998 (14096)	total: 1m 48s	remaining: 8d 21h 6m 49s
14400:	learn: 0.0525260	test: 0.0664606	best: 0.0664606 (14400)	total: 1m 50s	remaining: 8d 21h 1m 36s
14700:	learn: 0.0523512	test: 0.0664148	best: 0.0664148 (14700)	total: 1m 52s	remaining: 8d 21h 1m 4s
15000:	learn: 0.0521928	test: 0.0663664	best: 0.0663658 (14999)	total: 1m 55s	remaining: 8d 20h 55m 52s
15300:	learn: 0.0520237	test: 0.0663351	best: 0.0663348 (15298)	total: 1m 57s	remaining: 8d 20h 53m 39s
15600:	learn: 0.0518420	test: 0.0662898	best: 0.0662898 (15600)	total: 1m 59s	remaining: 8d 20h 51m 36s
15900:	learn: 0.0516760	test: 0.0662604	best: 0.0662602 (15897)	total: 2m 1s	remaining: 8d 20h 48m 18s
16200:	learn: 0.0515183	test: 0.0662187	best: 0.0662173 (16189)	total: 2m 4s	remaining: 8d 20h 42m 26s
16500:	learn: 0.0513631	test: 0.0661924	best: 0.0661915 (16492)	total: 2m 6s	remaining: 8d 20h 41m 53s
16800:	learn: 0.0512109	test: 0.0661557	best: 0.0661550 (16788)	total: 2m 8s	remaining: 8d 20h 37m 46s
17100:	learn: 0.0510522	test: 0.0661220	best: 0.0661210 (17096)	total: 2m 10s	remaining: 8d 20h 32m 53s
17400:	learn: 0.0509136	test: 0.0660909	best: 0.0660909 (17400)	total: 2m 13s	remaining: 8d 20h 30m 34s
17700:	learn: 0.0507726	test: 0.0660690	best: 0.0660687 (17696)	total: 2m 15s	remaining: 8d 20h 29m 10s
18000:	learn: 0.0506521	test: 0.0660386	best: 0.0660386 (18000)	total: 2m 17s	remaining: 8d 20h 24m 13s
18300:	learn: 0.0505216	test: 0.0660138	best: 0.0660138 (18300)	total: 2m 19s	remaining: 8d 20h 21m 24s
18600:	learn: 0.0504025	test: 0.0659889	best: 0.0659886 (18591)	total: 2m 22s	remaining: 8d 20h 15m 42s
18900:	learn: 0.0502810	test: 0.0659581	best: 0.0659577 (18896)	total: 2m 24s	remaining: 8d 20h 15m 26s
19200:	learn: 0.0501423	test: 0.0659251	best: 0.0659251 (19200)	total: 2m 26s	remaining: 8d 20h 18m 48s
19500:	learn: 0.0500063	test: 0.0658976	best: 0.0658975 (19496)	total: 2m 29s	remaining: 8d 20h 18m 20s
19800:	learn: 0.0498880	test: 0.0658744	best: 0.0658723 (19781)	total: 2m 31s	remaining: 8d 20h 14m 58s
20100:	learn: 0.0497703	test: 0.0658451	best: 0.0658450 (20097)	total: 2m 33s	remaining: 8d 20h 9m
20400:	learn: 0.0496502	test: 0.0658232	best: 0.0658232 (20400)	total: 2m 35s	remaining: 8d 20h 8m 26s
20700:	learn: 0.0495341	test: 0.0657972	best: 0.0657972 (20695)	total: 2m 38s	remaining: 8d 20h 6m 14s
21000:	learn: 0.0494109	test: 0.0657790	best: 0.0657787 (20962)	total: 2m 40s	remaining: 8d 20h 3m 39s
21300:	learn: 0.0492941	test: 0.0657549	best: 0.0657549 (21300)	total: 2m 42s	remaining: 8d 20h 45s
21600:	learn: 0.0491739	test: 0.0657349	best: 0.0657349 (21600)	total: 2m 44s	remaining: 8d 19h 59m 37s
21900:	learn: 0.0490549	test: 0.0657002	best: 0.0657000 (21898)	total: 2m 47s	remaining: 8d 19h 56m 46s
22200:	learn: 0.0489477	test: 0.0656814	best: 0.0656814 (22200)	total: 2m 49s	remaining: 8d 19h 55m 29s
22500:	learn: 0.0488369	test: 0.0656526	best: 0.0656526 (22500)	total: 2m 51s	remaining: 8d 19h 52m 23s
22800:	learn: 0.0487305	test: 0.0656275	best: 0.0656275 (22800)	total: 2m 53s	remaining: 8d 19h 51m 8s
23100:	learn: 0.0486184	test: 0.0655942	best: 0.0655942 (23100)	total: 2m 56s	remaining: 8d 19h 49m 42s
23400:	learn: 0.0485180	test: 0.0655800	best: 0.0655787 (23379)	total: 2m 58s	remaining: 8d 19h 48m 26s
23700:	learn: 0.0484109	test: 0.0655510	best: 0.0655510 (23700)	total: 3m	remaining: 8d 19h 45m 6s
24000:	learn: 0.0483312	test: 0.0655416	best: 0.0655411 (23995)	total: 3m 2s	remaining: 8d 19h 40m 23s
24300:	learn: 0.0482390	test: 0.0655202	best: 0.0655197 (24295)	total: 3m 5s	remaining: 8d 19h 44m 36s
24600:	learn: 0.0481465	test: 0.0654948	best: 0.0654948 (24600)	total: 3m 7s	remaining: 8d 19h 41m 41s
24900:	learn: 0.0480585	test: 0.0654694	best: 0.0654694 (24900)	total: 3m 9s	remaining: 8d 19h 39m 36s
25200:	learn: 0.0479837	test: 0.0654567	best: 0.0654567 (25200)	total: 3m 12s	remaining: 8d 19h 36m 21s
25500:	learn: 0.0479010	test: 0.0654388	best: 0.0654384 (25499)	total: 3m 14s	remaining: 8d 19h 36m 19s
25800:	learn: 0.0478110	test: 0.0654084	best: 0.0654084 (25800)	total: 3m 16s	remaining: 8d 19h 33m 42s
26100:	learn: 0.0477261	test: 0.0653873	best: 0.0653864 (26060)	total: 3m 18s	remaining: 8d 19h 31m 15s
26400:	learn: 0.0476485	test: 0.0653744	best: 0.0653731 (26387)	total: 3m 21s	remaining: 8d 19h 28m 56s
26700:	learn: 0.0475563	test: 0.0653497	best: 0.0653497 (26700)	total: 3m 23s	remaining: 8d 19h 28m 23s
27000:	learn: 0.0474743	test: 0.0653357	best: 0.0653344 (26993)	total: 3m 25s	remaining: 8d 19h 26m 51s
27300:	learn: 0.0473926	test: 0.0653176	best: 0.0653172 (27284)	total: 3m 27s	remaining: 8d 19h 25m 34s
27600:	learn: 0.0473137	test: 0.0653010	best: 0.0653009 (27567)	total: 3m 30s	remaining: 8d 19h 23m 8s
27900:	learn: 0.0472363	test: 0.0652943	best: 0.0652929 (27770)	total: 3m 32s	remaining: 8d 19h 22m 3s
28200:	learn: 0.0471482	test: 0.0652772	best: 0.0652760 (28192)	total: 3m 34s	remaining: 8d 19h 21m 19s
28500:	learn: 0.0470583	test: 0.0652589	best: 0.0652589 (28500)	total: 3m 36s	remaining: 8d 19h 19m 37s
28800:	learn: 0.0469746	test: 0.0652393	best: 0.0652390 (28798)	total: 3m 39s	remaining: 8d 19h 20m 5s
29100:	learn: 0.0468947	test: 0.0652101	best: 0.0652099 (29099)	total: 3m 41s	remaining: 8d 19h 18m 36s
29400:	learn: 0.0468106	test: 0.0652049	best: 0.0652042 (29395)	total: 3m 43s	remaining: 8d 19h 17m 45s
29700:	learn: 0.0467243	test: 0.0651879	best: 0.0651879 (29700)	total: 3m 45s	remaining: 8d 19h 16m 22s
30000:	learn: 0.0466426	test: 0.0651739	best: 0.0651731 (29983)	total: 3m 48s	remaining: 8d 19h 15m 27s
30300:	learn: 0.0465764	test: 0.0651584	best: 0.0651584 (30300)	total: 3m 50s	remaining: 8d 19h 13m 21s
30600:	learn: 0.0465075	test: 0.0651453	best: 0.0651442 (30552)	total: 3m 52s	remaining: 8d 19h 14m 27s
30900:	learn: 0.0464350	test: 0.0651309	best: 0.0651302 (30892)	total: 3m 55s	remaining: 8d 19h 13m 18s
31200:	learn: 0.0463719	test: 0.0651276	best: 0.0651258 (30996)	total: 3m 57s	remaining: 8d 19h 12m 46s
31500:	learn: 0.0463076	test: 0.0651169	best: 0.0651161 (31462)	total: 3m 59s	remaining: 8d 19h 14m 35s
31800:	learn: 0.0462450	test: 0.0651052	best: 0.0651052 (31800)	total: 4m 1s	remaining: 8d 19h 13m 23s
32100:	learn: 0.0461781	test: 0.0650987	best: 0.0650967 (32053)	total: 4m 4s	remaining: 8d 19h 13m 37s
32400:	learn: 0.0461146	test: 0.0650838	best: 0.0650837 (32397)	total: 4m 6s	remaining: 8d 19h 12m 50s
32700:	learn: 0.0460401	test: 0.0650695	best: 0.0650680 (32642)	total: 4m 8s	remaining: 8d 19h 11m 57s
33000:	learn: 0.0459713	test: 0.0650576	best: 0.0650571 (32981)	total: 4m 10s	remaining: 8d 19h 10m 34s
33300:	learn: 0.0459026	test: 0.0650442	best: 0.0650442 (33299)	total: 4m 13s	remaining: 8d 19h 12m 3s
33600:	learn: 0.0458410	test: 0.0650343	best: 0.0650329 (33590)	total: 4m 15s	remaining: 8d 19h 9m 23s
33900:	learn: 0.0457806	test: 0.0650150	best: 0.0650150 (33900)	total: 4m 17s	remaining: 8d 19h 8m 58s
34200:	learn: 0.0457189	test: 0.0650044	best: 0.0650042 (34183)	total: 4m 20s	remaining: 8d 19h 6m 45s
34500:	learn: 0.0456586	test: 0.0649883	best: 0.0649879 (34499)	total: 4m 22s	remaining: 8d 19h 5m 31s
34800:	learn: 0.0456047	test: 0.0649744	best: 0.0649721 (34778)	total: 4m 24s	remaining: 8d 19h 5m 43s
35100:	learn: 0.0455413	test: 0.0649608	best: 0.0649607 (35098)	total: 4m 26s	remaining: 8d 19h 3m 46s
35400:	learn: 0.0454832	test: 0.0649597	best: 0.0649575 (35197)	total: 4m 29s	remaining: 8d 19h 2m 21s
35700:	learn: 0.0454271	test: 0.0649484	best: 0.0649476 (35655)	total: 4m 31s	remaining: 8d 19h 5m 40s
36000:	learn: 0.0453668	test: 0.0649383	best: 0.0649381 (35992)	total: 4m 33s	remaining: 8d 19h 6m 48s
36300:	learn: 0.0453096	test: 0.0649261	best: 0.0649251 (36291)	total: 4m 35s	remaining: 8d 19h 5m 15s
36600:	learn: 0.0452600	test: 0.0649196	best: 0.0649188 (36587)	total: 4m 38s	remaining: 8d 19h 4m 14s
36900:	learn: 0.0452093	test: 0.0649147	best: 0.0649143 (36899)	total: 4m 40s	remaining: 8d 19h 2m 47s
37200:	learn: 0.0451578	test: 0.0649122	best: 0.0649120 (37184)	total: 4m 42s	remaining: 8d 19h 1m 20s
37500:	learn: 0.0451084	test: 0.0649083	best: 0.0649083 (37500)	total: 4m 44s	remaining: 8d 18h 59m 40s
37800:	learn: 0.0450525	test: 0.0649005	best: 0.0648998 (37797)	total: 4m 47s	remaining: 8d 18h 58m 2s
38100:	learn: 0.0449958	test: 0.0648949	best: 0.0648932 (38008)	total: 4m 49s	remaining: 8d 18h 55m 44s
38400:	learn: 0.0449395	test: 0.0648857	best: 0.0648853 (38377)	total: 4m 51s	remaining: 8d 18h 54m 36s
38700:	learn: 0.0448827	test: 0.0648777	best: 0.0648764 (38673)	total: 4m 53s	remaining: 8d 18h 53m 3s
39000:	learn: 0.0448247	test: 0.0648687	best: 0.0648687 (39000)	total: 4m 56s	remaining: 8d 18h 52m 51s
39300:	learn: 0.0447701	test: 0.0648608	best: 0.0648608 (39300)	total: 4m 58s	remaining: 8d 18h 54m 3s
39600:	learn: 0.0447154	test: 0.0648494	best: 0.0648492 (39593)	total: 5m	remaining: 8d 18h 52m 15s
39900:	learn: 0.0446579	test: 0.0648412	best: 0.0648412 (39900)	total: 5m 3s	remaining: 8d 18h 51m 20s
40200:	learn: 0.0446057	test: 0.0648356	best: 0.0648329 (40086)	total: 5m 5s	remaining: 8d 18h 49m 39s
40500:	learn: 0.0445553	test: 0.0648277	best: 0.0648277 (40500)	total: 5m 7s	remaining: 8d 18h 48m 35s
40800:	learn: 0.0445050	test: 0.0648189	best: 0.0648188 (40799)	total: 5m 9s	remaining: 8d 18h 46m 27s
41100:	learn: 0.0444470	test: 0.0648060	best: 0.0648060 (41100)	total: 5m 11s	remaining: 8d 18h 45m 48s
41400:	learn: 0.0443925	test: 0.0647940	best: 0.0647928 (41380)	total: 5m 14s	remaining: 8d 18h 45m 11s
41700:	learn: 0.0443378	test: 0.0647821	best: 0.0647821 (41700)	total: 5m 16s	remaining: 8d 18h 44m 13s
42000:	learn: 0.0442844	test: 0.0647714	best: 0.0647713 (41981)	total: 5m 18s	remaining: 8d 18h 44m 4s
42300:	learn: 0.0442331	test: 0.0647654	best: 0.0647644 (42260)	total: 5m 21s	remaining: 8d 18h 46m 13s
42600:	learn: 0.0441813	test: 0.0647530	best: 0.0647530 (42596)	total: 5m 23s	remaining: 8d 18h 45m 58s
42900:	learn: 0.0441278	test: 0.0647437	best: 0.0647437 (42882)	total: 5m 25s	remaining: 8d 18h 45m 51s
43200:	learn: 0.0440804	test: 0.0647363	best: 0.0647363 (43200)	total: 5m 27s	remaining: 8d 18h 45m 20s
43500:	learn: 0.0440301	test: 0.0647287	best: 0.0647287 (43500)	total: 5m 30s	remaining: 8d 18h 44m 16s
43800:	learn: 0.0439836	test: 0.0647218	best: 0.0647214 (43770)	total: 5m 32s	remaining: 8d 18h 43m 52s
44100:	learn: 0.0439347	test: 0.0647107	best: 0.0647107 (44100)	total: 5m 34s	remaining: 8d 18h 42m 5s
44400:	learn: 0.0438888	test: 0.0647062	best: 0.0647062 (44398)	total: 5m 36s	remaining: 8d 18h 41m 59s
44700:	learn: 0.0438428	test: 0.0646988	best: 0.0646986 (44660)	total: 5m 39s	remaining: 8d 18h 40m 30s
45000:	learn: 0.0437994	test: 0.0646912	best: 0.0646909 (44996)	total: 5m 41s	remaining: 8d 18h 39m 11s
45300:	learn: 0.0437483	test: 0.0646811	best: 0.0646811 (45300)	total: 5m 43s	remaining: 8d 18h 37m 52s
45600:	learn: 0.0437075	test: 0.0646801	best: 0.0646782 (45572)	total: 5m 46s	remaining: 8d 18h 44m 5s
45900:	learn: 0.0436638	test: 0.0646703	best: 0.0646695 (45848)	total: 5m 48s	remaining: 8d 18h 43m 15s
46200:	learn: 0.0436186	test: 0.0646667	best: 0.0646663 (46164)	total: 5m 50s	remaining: 8d 18h 42m 10s
46500:	learn: 0.0435752	test: 0.0646578	best: 0.0646566 (46418)	total: 5m 52s	remaining: 8d 18h 41m 21s
46800:	learn: 0.0435328	test: 0.0646523	best: 0.0646511 (46695)	total: 5m 55s	remaining: 8d 18h 40m 3s
47100:	learn: 0.0434908	test: 0.0646491	best: 0.0646474 (46996)	total: 5m 57s	remaining: 8d 18h 40m 42s
47400:	learn: 0.0434456	test: 0.0646440	best: 0.0646425 (47307)	total: 5m 59s	remaining: 8d 18h 39m 17s
47700:	learn: 0.0434061	test: 0.0646364	best: 0.0646359 (47664)	total: 6m 1s	remaining: 8d 18h 38m 28s
48000:	learn: 0.0433634	test: 0.0646311	best: 0.0646311 (47958)	total: 6m 4s	remaining: 8d 18h 43m 43s
48300:	learn: 0.0433234	test: 0.0646265	best: 0.0646258 (48285)	total: 6m 6s	remaining: 8d 18h 44m 22s
48600:	learn: 0.0432814	test: 0.0646218	best: 0.0646217 (48599)	total: 6m 8s	remaining: 8d 18h 44m 20s
48900:	learn: 0.0432388	test: 0.0646155	best: 0.0646153 (48845)	total: 6m 11s	remaining: 8d 18h 43m 47s
49200:	learn: 0.0431989	test: 0.0646081	best: 0.0646074 (49197)	total: 6m 13s	remaining: 8d 18h 42m 22s
49500:	learn: 0.0431573	test: 0.0645947	best: 0.0645947 (49500)	total: 6m 15s	remaining: 8d 18h 40m 32s
49800:	learn: 0.0431176	test: 0.0645850	best: 0.0645848 (49785)	total: 6m 17s	remaining: 8d 18h 39m 31s
50100:	learn: 0.0430798	test: 0.0645768	best: 0.0645768 (50100)	total: 6m 20s	remaining: 8d 18h 39m 47s
50400:	learn: 0.0430437	test: 0.0645728	best: 0.0645717 (50383)	total: 6m 22s	remaining: 8d 18h 40m 8s
50700:	learn: 0.0430074	test: 0.0645634	best: 0.0645630 (50696)	total: 6m 24s	remaining: 8d 18h 38m 42s
51000:	learn: 0.0429685	test: 0.0645603	best: 0.0645596 (50937)	total: 6m 26s	remaining: 8d 18h 37m 23s
51300:	learn: 0.0429270	test: 0.0645584	best: 0.0645577 (51299)	total: 6m 29s	remaining: 8d 18h 35m 55s
51600:	learn: 0.0428866	test: 0.0645465	best: 0.0645465 (51600)	total: 6m 31s	remaining: 8d 18h 35m 24s
51900:	learn: 0.0428480	test: 0.0645411	best: 0.0645402 (51871)	total: 6m 33s	remaining: 8d 18h 33m 48s
52200:	learn: 0.0428096	test: 0.0645375	best: 0.0645368 (52192)	total: 6m 35s	remaining: 8d 18h 33m 13s
52500:	learn: 0.0427748	test: 0.0645344	best: 0.0645340 (52496)	total: 6m 38s	remaining: 8d 18h 31m 57s
52800:	learn: 0.0427395	test: 0.0645315	best: 0.0645310 (52794)	total: 6m 40s	remaining: 8d 18h 32m 10s
53100:	learn: 0.0427039	test: 0.0645251	best: 0.0645248 (52977)	total: 6m 42s	remaining: 8d 18h 30m 58s
53400:	learn: 0.0426709	test: 0.0645271	best: 0.0645243 (53202)	total: 6m 44s	remaining: 8d 18h 29m 17s
53700:	learn: 0.0426350	test: 0.0645216	best: 0.0645216 (53700)	total: 6m 47s	remaining: 8d 18h 29m 36s
54000:	learn: 0.0426006	test: 0.0645153	best: 0.0645151 (53979)	total: 6m 49s	remaining: 8d 18h 29m 21s
54300:	learn: 0.0425661	test: 0.0645123	best: 0.0645122 (54290)	total: 6m 51s	remaining: 8d 18h 28m 19s
54600:	learn: 0.0425288	test: 0.0645057	best: 0.0645057 (54600)	total: 6m 53s	remaining: 8d 18h 26m 57s
54900:	learn: 0.0424955	test: 0.0644962	best: 0.0644962 (54900)	total: 6m 56s	remaining: 8d 18h 28m 38s
55200:	learn: 0.0424603	test: 0.0644950	best: 0.0644950 (55198)	total: 6m 58s	remaining: 8d 18h 27m 28s
55500:	learn: 0.0424253	test: 0.0644915	best: 0.0644912 (55491)	total: 7m	remaining: 8d 18h 27m 30s
55800:	learn: 0.0423833	test: 0.0644856	best: 0.0644849 (55714)	total: 7m 3s	remaining: 8d 18h 27m 51s
56100:	learn: 0.0423479	test: 0.0644813	best: 0.0644800 (56061)	total: 7m 5s	remaining: 8d 18h 26m 38s
56400:	learn: 0.0423083	test: 0.0644681	best: 0.0644681 (56400)	total: 7m 7s	remaining: 8d 18h 25m 54s
56700:	learn: 0.0422722	test: 0.0644660	best: 0.0644644 (56626)	total: 7m 9s	remaining: 8d 18h 26m 9s
57000:	learn: 0.0422378	test: 0.0644622	best: 0.0644621 (56992)	total: 7m 12s	remaining: 8d 18h 24m 51s
57300:	learn: 0.0422055	test: 0.0644584	best: 0.0644551 (57128)	total: 7m 14s	remaining: 8d 18h 23m 45s
57600:	learn: 0.0421705	test: 0.0644512	best: 0.0644495 (57581)	total: 7m 16s	remaining: 8d 18h 22m 57s
57900:	learn: 0.0421372	test: 0.0644501	best: 0.0644493 (57873)	total: 7m 18s	remaining: 8d 18h 22m 23s
58200:	learn: 0.0421012	test: 0.0644424	best: 0.0644424 (58200)	total: 7m 21s	remaining: 8d 18h 21m 46s
58500:	learn: 0.0420704	test: 0.0644380	best: 0.0644376 (58458)	total: 7m 23s	remaining: 8d 18h 21m 10s
58800:	learn: 0.0420369	test: 0.0644393	best: 0.0644365 (58573)	total: 7m 25s	remaining: 8d 18h 20m 11s
59100:	learn: 0.0420035	test: 0.0644285	best: 0.0644276 (59091)	total: 7m 27s	remaining: 8d 18h 20m 8s
59400:	learn: 0.0419763	test: 0.0644252	best: 0.0644235 (59285)	total: 7m 30s	remaining: 8d 18h 19m 34s
59700:	learn: 0.0419459	test: 0.0644222	best: 0.0644203 (59653)	total: 7m 32s	remaining: 8d 18h 18m 28s
60000:	learn: 0.0419145	test: 0.0644147	best: 0.0644147 (59965)	total: 7m 34s	remaining: 8d 18h 17m 2s
60300:	learn: 0.0418821	test: 0.0644103	best: 0.0644103 (60299)	total: 7m 36s	remaining: 8d 18h 16m 6s
60600:	learn: 0.0418543	test: 0.0644052	best: 0.0644052 (60600)	total: 7m 38s	remaining: 8d 18h 14m 56s
60900:	learn: 0.0418238	test: 0.0644002	best: 0.0643987 (60810)	total: 7m 41s	remaining: 8d 18h 14m 4s
61200:	learn: 0.0417936	test: 0.0643948	best: 0.0643948 (61200)	total: 7m 43s	remaining: 8d 18h 13m 40s
61500:	learn: 0.0417636	test: 0.0643886	best: 0.0643872 (61492)	total: 7m 45s	remaining: 8d 18h 13m 22s
61800:	learn: 0.0417315	test: 0.0643828	best: 0.0643819 (61696)	total: 7m 48s	remaining: 8d 18h 13m 37s
62100:	learn: 0.0417036	test: 0.0643805	best: 0.0643786 (62058)	total: 7m 50s	remaining: 8d 18h 13m 8s
62400:	learn: 0.0416739	test: 0.0643749	best: 0.0643742 (62319)	total: 7m 52s	remaining: 8d 18h 11m 41s
62700:	learn: 0.0416428	test: 0.0643728	best: 0.0643728 (62699)	total: 7m 54s	remaining: 8d 18h 10m 32s
63000:	learn: 0.0416142	test: 0.0643705	best: 0.0643702 (62985)	total: 7m 56s	remaining: 8d 18h 9m 33s
63300:	learn: 0.0415856	test: 0.0643657	best: 0.0643653 (63269)	total: 7m 59s	remaining: 8d 18h 8m 54s
63600:	learn: 0.0415554	test: 0.0643596	best: 0.0643590 (63596)	total: 8m 1s	remaining: 8d 18h 9m 28s
63900:	learn: 0.0415258	test: 0.0643520	best: 0.0643505 (63850)	total: 8m 3s	remaining: 8d 18h 8m 35s
64200:	learn: 0.0414942	test: 0.0643577	best: 0.0643505 (63850)	total: 8m 5s	remaining: 8d 18h 8m 7s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.06435051157
bestIteration = 63850

Shrink model to first 63851 iterations.
fold n°2
0:	learn: 0.5693995	test: 0.5708002	best: 0.5708002 (0)	total: 8.98ms	remaining: 10d 9h 32m 42s
300:	learn: 0.1338584	test: 0.1330689	best: 0.1330689 (300)	total: 2.42s	remaining: 9d 7h 8m 19s
600:	learn: 0.0982821	test: 0.0991658	best: 0.0991658 (600)	total: 4.65s	remaining: 8d 22h 56m 43s
900:	learn: 0.0891938	test: 0.0906791	best: 0.0906791 (900)	total: 6.94s	remaining: 8d 21h 57m 2s
1200:	learn: 0.0839276	test: 0.0861570	best: 0.0861570 (1200)	total: 9.41s	remaining: 9d 1h 38m 39s
1500:	learn: 0.0799398	test: 0.0830911	best: 0.0830911 (1500)	total: 11.8s	remaining: 9d 3h 14m 55s
1800:	learn: 0.0768492	test: 0.0809053	best: 0.0809053 (1800)	total: 14.1s	remaining: 9d 2h 11m 57s
2100:	learn: 0.0745170	test: 0.0793608	best: 0.0793608 (2100)	total: 16.5s	remaining: 9d 1h 39m 39s
2400:	learn: 0.0725743	test: 0.0781139	best: 0.0781139 (2400)	total: 18.8s	remaining: 9d 1h 27m 35s
2700:	learn: 0.0709607	test: 0.0770891	best: 0.0770891 (2700)	total: 21.2s	remaining: 9d 1h 34m 32s
3000:	learn: 0.0695239	test: 0.0762177	best: 0.0762177 (3000)	total: 23.5s	remaining: 9d 1h 4m 56s
3300:	learn: 0.0682964	test: 0.0755667	best: 0.0755667 (3300)	total: 25.8s	remaining: 9d 58m 11s
3600:	learn: 0.0671821	test: 0.0749780	best: 0.0749780 (3600)	total: 28.1s	remaining: 9d 48m 3s
3900:	learn: 0.0662066	test: 0.0744623	best: 0.0744623 (3900)	total: 30.4s	remaining: 9d 37m 2s
4200:	learn: 0.0653241	test: 0.0739886	best: 0.0739886 (4200)	total: 32.7s	remaining: 9d 20m
4500:	learn: 0.0645231	test: 0.0736106	best: 0.0736106 (4500)	total: 35s	remaining: 9d 12m 38s
4800:	learn: 0.0637592	test: 0.0732359	best: 0.0732359 (4800)	total: 37.4s	remaining: 9d 9m 36s
5100:	learn: 0.0630507	test: 0.0729034	best: 0.0729034 (5100)	total: 39.7s	remaining: 8d 23h 56m 23s
5400:	learn: 0.0623966	test: 0.0726213	best: 0.0726212 (5398)	total: 41.9s	remaining: 8d 23h 41m 51s
5700:	learn: 0.0617828	test: 0.0723494	best: 0.0723494 (5700)	total: 44.2s	remaining: 8d 23h 30m 55s
6000:	learn: 0.0612181	test: 0.0721043	best: 0.0721043 (6000)	total: 46.5s	remaining: 8d 23h 25m 47s
6300:	learn: 0.0606598	test: 0.0718836	best: 0.0718836 (6300)	total: 48.8s	remaining: 8d 23h 17m 2s
6600:	learn: 0.0601609	test: 0.0716754	best: 0.0716754 (6600)	total: 51.1s	remaining: 8d 23h 4m 38s
6900:	learn: 0.0596693	test: 0.0714862	best: 0.0714862 (6900)	total: 53.4s	remaining: 8d 22h 55m 31s
7200:	learn: 0.0592087	test: 0.0712881	best: 0.0712881 (7200)	total: 55.7s	remaining: 8d 22h 57m 39s
7500:	learn: 0.0587880	test: 0.0711134	best: 0.0711129 (7496)	total: 58.1s	remaining: 8d 23h 18m 8s
7800:	learn: 0.0583697	test: 0.0709401	best: 0.0709401 (7800)	total: 1m	remaining: 8d 23h 13m 25s
8100:	learn: 0.0579768	test: 0.0707887	best: 0.0707882 (8099)	total: 1m 2s	remaining: 8d 23h 4m 44s
8400:	learn: 0.0575905	test: 0.0706272	best: 0.0706272 (8400)	total: 1m 5s	remaining: 8d 23h 1m 28s
8700:	learn: 0.0572224	test: 0.0704880	best: 0.0704880 (8700)	total: 1m 7s	remaining: 8d 22h 59m 39s
9000:	learn: 0.0568803	test: 0.0703561	best: 0.0703551 (8998)	total: 1m 9s	remaining: 8d 22h 53m 29s
9300:	learn: 0.0565518	test: 0.0702200	best: 0.0702200 (9300)	total: 1m 11s	remaining: 8d 22h 48m 37s
9600:	learn: 0.0562238	test: 0.0701042	best: 0.0701040 (9590)	total: 1m 14s	remaining: 8d 22h 49m 59s
9900:	learn: 0.0559155	test: 0.0699950	best: 0.0699950 (9900)	total: 1m 16s	remaining: 8d 22h 48m 17s
10200:	learn: 0.0556167	test: 0.0698860	best: 0.0698860 (10200)	total: 1m 18s	remaining: 8d 22h 43m 5s
10500:	learn: 0.0553464	test: 0.0698130	best: 0.0698123 (10496)	total: 1m 21s	remaining: 8d 22h 37m 27s
10800:	learn: 0.0550875	test: 0.0697245	best: 0.0697245 (10800)	total: 1m 23s	remaining: 8d 22h 30m 32s
11100:	learn: 0.0548286	test: 0.0696492	best: 0.0696492 (11100)	total: 1m 25s	remaining: 8d 22h 26m 40s
11400:	learn: 0.0545903	test: 0.0695617	best: 0.0695617 (11400)	total: 1m 28s	remaining: 8d 22h 23m
11700:	learn: 0.0543349	test: 0.0694722	best: 0.0694722 (11700)	total: 1m 30s	remaining: 8d 22h 18m 33s
12000:	learn: 0.0540927	test: 0.0693927	best: 0.0693927 (12000)	total: 1m 32s	remaining: 8d 22h 13m 2s
12300:	learn: 0.0538737	test: 0.0693198	best: 0.0693195 (12299)	total: 1m 34s	remaining: 8d 22h 10m 55s
12600:	learn: 0.0536791	test: 0.0692477	best: 0.0692469 (12592)	total: 1m 37s	remaining: 8d 22h 7m 40s
12900:	learn: 0.0534696	test: 0.0691938	best: 0.0691938 (12900)	total: 1m 39s	remaining: 8d 22h 3m 8s
13200:	learn: 0.0532614	test: 0.0691216	best: 0.0691206 (13199)	total: 1m 41s	remaining: 8d 21h 57m 41s
13500:	learn: 0.0530656	test: 0.0690689	best: 0.0690689 (13500)	total: 1m 43s	remaining: 8d 21h 54m 3s
13800:	learn: 0.0528856	test: 0.0689985	best: 0.0689985 (13800)	total: 1m 46s	remaining: 8d 21h 56m 14s
14100:	learn: 0.0526914	test: 0.0689371	best: 0.0689364 (14085)	total: 1m 48s	remaining: 8d 21h 53m 7s
14400:	learn: 0.0525138	test: 0.0688810	best: 0.0688789 (14388)	total: 1m 50s	remaining: 8d 21h 48m 10s
14700:	learn: 0.0523314	test: 0.0688278	best: 0.0688278 (14700)	total: 1m 53s	remaining: 8d 21h 44m 5s
15000:	learn: 0.0521534	test: 0.0687797	best: 0.0687797 (15000)	total: 1m 55s	remaining: 8d 21h 46m 40s
15300:	learn: 0.0519711	test: 0.0687227	best: 0.0687227 (15300)	total: 1m 57s	remaining: 8d 21h 43m 19s
15600:	learn: 0.0518000	test: 0.0686695	best: 0.0686682 (15586)	total: 2m	remaining: 8d 21h 43m 8s
15900:	learn: 0.0516404	test: 0.0686229	best: 0.0686228 (15899)	total: 2m 2s	remaining: 8d 21h 38m 31s
16200:	learn: 0.0514844	test: 0.0685746	best: 0.0685740 (16197)	total: 2m 4s	remaining: 8d 21h 36m 41s
16500:	learn: 0.0513301	test: 0.0685257	best: 0.0685250 (16485)	total: 2m 6s	remaining: 8d 21h 39m 52s
16800:	learn: 0.0511755	test: 0.0684676	best: 0.0684676 (16800)	total: 2m 9s	remaining: 8d 21h 40m 33s
17100:	learn: 0.0510198	test: 0.0684135	best: 0.0684135 (17100)	total: 2m 11s	remaining: 8d 21h 41m 9s
17400:	learn: 0.0508658	test: 0.0683666	best: 0.0683666 (17400)	total: 2m 13s	remaining: 8d 21h 37m 37s
17700:	learn: 0.0507187	test: 0.0683335	best: 0.0683324 (17687)	total: 2m 16s	remaining: 8d 21h 39m 32s
18000:	learn: 0.0505768	test: 0.0682910	best: 0.0682909 (17999)	total: 2m 18s	remaining: 8d 21h 36m
18300:	learn: 0.0504386	test: 0.0682367	best: 0.0682367 (18300)	total: 2m 20s	remaining: 8d 21h 32m 17s
18600:	learn: 0.0502996	test: 0.0681940	best: 0.0681934 (18599)	total: 2m 23s	remaining: 8d 21h 31m 2s
18900:	learn: 0.0501799	test: 0.0681650	best: 0.0681650 (18900)	total: 2m 25s	remaining: 8d 21h 30m 48s
19200:	learn: 0.0500552	test: 0.0681286	best: 0.0681284 (19199)	total: 2m 27s	remaining: 8d 21h 27m 28s
19500:	learn: 0.0499400	test: 0.0680942	best: 0.0680942 (19500)	total: 2m 29s	remaining: 8d 21h 30m 30s
19800:	learn: 0.0498119	test: 0.0680641	best: 0.0680641 (19800)	total: 2m 32s	remaining: 8d 21h 27m 20s
20100:	learn: 0.0496990	test: 0.0680267	best: 0.0680267 (20100)	total: 2m 34s	remaining: 8d 21h 24m 57s
20400:	learn: 0.0495899	test: 0.0680030	best: 0.0680030 (20399)	total: 2m 36s	remaining: 8d 21h 22m 44s
20700:	learn: 0.0494685	test: 0.0679651	best: 0.0679651 (20700)	total: 2m 39s	remaining: 8d 21h 21m 33s
21000:	learn: 0.0493610	test: 0.0679326	best: 0.0679321 (20991)	total: 2m 41s	remaining: 8d 21h 20m 28s
21300:	learn: 0.0492513	test: 0.0679141	best: 0.0679132 (21232)	total: 2m 43s	remaining: 8d 21h 16m 54s
21600:	learn: 0.0491516	test: 0.0678956	best: 0.0678954 (21588)	total: 2m 45s	remaining: 8d 21h 14m 28s
21900:	learn: 0.0490474	test: 0.0678666	best: 0.0678664 (21897)	total: 2m 48s	remaining: 8d 21h 15m 16s
22200:	learn: 0.0489410	test: 0.0678371	best: 0.0678365 (22195)	total: 2m 50s	remaining: 8d 21h 11m 53s
22500:	learn: 0.0488314	test: 0.0678115	best: 0.0678105 (22476)	total: 2m 52s	remaining: 8d 21h 10m 31s
22800:	learn: 0.0487283	test: 0.0677869	best: 0.0677869 (22800)	total: 2m 55s	remaining: 8d 21h 11m 58s
23100:	learn: 0.0486441	test: 0.0677770	best: 0.0677762 (23099)	total: 2m 57s	remaining: 8d 21h 7m 48s
23400:	learn: 0.0485462	test: 0.0677552	best: 0.0677545 (23372)	total: 2m 59s	remaining: 8d 21h 7m 8s
23700:	learn: 0.0484551	test: 0.0677421	best: 0.0677406 (23646)	total: 3m 1s	remaining: 8d 21h 3m 9s
24000:	learn: 0.0483692	test: 0.0677142	best: 0.0677141 (23998)	total: 3m 4s	remaining: 8d 21h 2m 20s
24300:	learn: 0.0482701	test: 0.0676923	best: 0.0676923 (24299)	total: 3m 6s	remaining: 8d 21h 12s
24600:	learn: 0.0481782	test: 0.0676699	best: 0.0676694 (24597)	total: 3m 8s	remaining: 8d 20h 57m 14s
24900:	learn: 0.0480853	test: 0.0676454	best: 0.0676453 (24880)	total: 3m 10s	remaining: 8d 20h 55m 5s
25200:	learn: 0.0479977	test: 0.0676237	best: 0.0676237 (25200)	total: 3m 13s	remaining: 8d 20h 52m 21s
25500:	learn: 0.0479172	test: 0.0675987	best: 0.0675980 (25497)	total: 3m 15s	remaining: 8d 20h 53m 27s
25800:	learn: 0.0478422	test: 0.0675791	best: 0.0675790 (25798)	total: 3m 17s	remaining: 8d 20h 51m 48s
26100:	learn: 0.0477664	test: 0.0675579	best: 0.0675578 (26098)	total: 3m 20s	remaining: 8d 20h 48m 21s
26400:	learn: 0.0476884	test: 0.0675323	best: 0.0675322 (26397)	total: 3m 22s	remaining: 8d 20h 45m 39s
26700:	learn: 0.0476037	test: 0.0675017	best: 0.0675014 (26698)	total: 3m 24s	remaining: 8d 21h 3m 35s
27000:	learn: 0.0475331	test: 0.0674841	best: 0.0674841 (27000)	total: 3m 27s	remaining: 8d 21h 2m 34s
27300:	learn: 0.0474507	test: 0.0674627	best: 0.0674627 (27293)	total: 3m 29s	remaining: 8d 21h 13m 45s
27600:	learn: 0.0473700	test: 0.0674458	best: 0.0674449 (27597)	total: 3m 31s	remaining: 8d 21h 13m 45s
27900:	learn: 0.0472852	test: 0.0674231	best: 0.0674223 (27889)	total: 3m 34s	remaining: 8d 21h 16m 51s
28200:	learn: 0.0472020	test: 0.0674021	best: 0.0674021 (28199)	total: 3m 36s	remaining: 8d 21h 16m 59s
28500:	learn: 0.0471234	test: 0.0673808	best: 0.0673796 (28478)	total: 3m 38s	remaining: 8d 21h 17m 33s
28800:	learn: 0.0470493	test: 0.0673652	best: 0.0673646 (28782)	total: 3m 41s	remaining: 8d 21h 16m 39s
29100:	learn: 0.0469669	test: 0.0673410	best: 0.0673407 (29099)	total: 3m 43s	remaining: 8d 21h 21m 58s
29400:	learn: 0.0468965	test: 0.0673107	best: 0.0673107 (29400)	total: 3m 45s	remaining: 8d 21h 22m 52s
29700:	learn: 0.0468191	test: 0.0672889	best: 0.0672886 (29696)	total: 3m 48s	remaining: 8d 21h 24m 43s
30000:	learn: 0.0467487	test: 0.0672686	best: 0.0672684 (29998)	total: 3m 50s	remaining: 8d 21h 25m 14s
30300:	learn: 0.0466812	test: 0.0672502	best: 0.0672502 (30300)	total: 3m 52s	remaining: 8d 21h 23m 10s
30600:	learn: 0.0466119	test: 0.0672383	best: 0.0672382 (30597)	total: 3m 55s	remaining: 8d 21h 23m 56s
30900:	learn: 0.0465380	test: 0.0672193	best: 0.0672192 (30897)	total: 3m 57s	remaining: 8d 21h 24m 9s
31200:	learn: 0.0464654	test: 0.0671986	best: 0.0671968 (31193)	total: 3m 59s	remaining: 8d 21h 24m 31s
31500:	learn: 0.0463980	test: 0.0671807	best: 0.0671799 (31479)	total: 4m 2s	remaining: 8d 21h 24m 56s
31800:	learn: 0.0463346	test: 0.0671731	best: 0.0671728 (31795)	total: 4m 4s	remaining: 8d 21h 27m 5s
32100:	learn: 0.0462646	test: 0.0671570	best: 0.0671561 (32092)	total: 4m 6s	remaining: 8d 21h 27m 5s
32400:	learn: 0.0461934	test: 0.0671439	best: 0.0671437 (32398)	total: 4m 9s	remaining: 8d 21h 27m 46s
32700:	learn: 0.0461338	test: 0.0671257	best: 0.0671257 (32700)	total: 4m 11s	remaining: 8d 21h 28m 42s
33000:	learn: 0.0460784	test: 0.0671193	best: 0.0671190 (32984)	total: 4m 13s	remaining: 8d 21h 31m 37s
33300:	learn: 0.0460227	test: 0.0671147	best: 0.0671142 (33282)	total: 4m 16s	remaining: 8d 21h 30m 48s
33600:	learn: 0.0459586	test: 0.0671069	best: 0.0671068 (33549)	total: 4m 18s	remaining: 8d 21h 30m 22s
33900:	learn: 0.0458943	test: 0.0670957	best: 0.0670955 (33890)	total: 4m 20s	remaining: 8d 21h 31m 2s
34200:	learn: 0.0458278	test: 0.0670782	best: 0.0670774 (34191)	total: 4m 23s	remaining: 8d 21h 31m 57s
34500:	learn: 0.0457667	test: 0.0670717	best: 0.0670710 (34486)	total: 4m 25s	remaining: 8d 21h 32m 36s
34800:	learn: 0.0457054	test: 0.0670591	best: 0.0670587 (34791)	total: 4m 27s	remaining: 8d 21h 34m 33s
35100:	learn: 0.0456476	test: 0.0670445	best: 0.0670432 (35078)	total: 4m 30s	remaining: 8d 21h 35m 57s
35400:	learn: 0.0455876	test: 0.0670304	best: 0.0670290 (35393)	total: 4m 32s	remaining: 8d 21h 36m 56s
35700:	learn: 0.0455281	test: 0.0670167	best: 0.0670161 (35690)	total: 4m 34s	remaining: 8d 21h 40m 42s
36000:	learn: 0.0454707	test: 0.0670055	best: 0.0670050 (35967)	total: 4m 37s	remaining: 8d 21h 40m 25s
36300:	learn: 0.0454158	test: 0.0669956	best: 0.0669936 (36271)	total: 4m 39s	remaining: 8d 21h 40m 17s
36600:	learn: 0.0453544	test: 0.0669879	best: 0.0669861 (36562)	total: 4m 41s	remaining: 8d 21h 41m 5s
36900:	learn: 0.0452940	test: 0.0669737	best: 0.0669734 (36878)	total: 4m 44s	remaining: 8d 21h 52m 56s
37200:	learn: 0.0452393	test: 0.0669667	best: 0.0669667 (37200)	total: 4m 46s	remaining: 8d 21h 59m 45s
37500:	learn: 0.0451824	test: 0.0669596	best: 0.0669585 (37487)	total: 4m 49s	remaining: 8d 22h 10s
37800:	learn: 0.0451284	test: 0.0669540	best: 0.0669538 (37793)	total: 4m 51s	remaining: 8d 22h 58s
38100:	learn: 0.0450681	test: 0.0669474	best: 0.0669471 (38095)	total: 4m 53s	remaining: 8d 22h 3m 20s
38400:	learn: 0.0450145	test: 0.0669458	best: 0.0669458 (38400)	total: 4m 56s	remaining: 8d 22h 5m 31s
38700:	learn: 0.0449596	test: 0.0669337	best: 0.0669328 (38688)	total: 4m 58s	remaining: 8d 22h 6m 51s
39000:	learn: 0.0449086	test: 0.0669254	best: 0.0669252 (38993)	total: 5m	remaining: 8d 22h 7m 14s
39300:	learn: 0.0448569	test: 0.0669134	best: 0.0669134 (39300)	total: 5m 3s	remaining: 8d 22h 15m 18s
39600:	learn: 0.0448004	test: 0.0669078	best: 0.0669066 (39558)	total: 5m 5s	remaining: 8d 22h 15m 43s
39900:	learn: 0.0447459	test: 0.0669032	best: 0.0669032 (39900)	total: 5m 7s	remaining: 8d 22h 14m 36s
40200:	learn: 0.0446888	test: 0.0668944	best: 0.0668921 (40148)	total: 5m 10s	remaining: 8d 22h 14m 14s
40500:	learn: 0.0446335	test: 0.0668877	best: 0.0668877 (40496)	total: 5m 12s	remaining: 8d 22h 14m
40800:	learn: 0.0445813	test: 0.0668753	best: 0.0668753 (40800)	total: 5m 14s	remaining: 8d 22h 15m 35s
41100:	learn: 0.0445303	test: 0.0668696	best: 0.0668696 (41098)	total: 5m 17s	remaining: 8d 22h 20m 25s
41400:	learn: 0.0444752	test: 0.0668547	best: 0.0668524 (41357)	total: 5m 19s	remaining: 8d 22h 20m 38s
41700:	learn: 0.0444214	test: 0.0668466	best: 0.0668460 (41698)	total: 5m 21s	remaining: 8d 22h 21m 44s
42000:	learn: 0.0443759	test: 0.0668397	best: 0.0668397 (42000)	total: 5m 24s	remaining: 8d 22h 21m 40s
42300:	learn: 0.0443342	test: 0.0668329	best: 0.0668316 (42292)	total: 5m 26s	remaining: 8d 22h 20m 51s
42600:	learn: 0.0442904	test: 0.0668241	best: 0.0668240 (42599)	total: 5m 28s	remaining: 8d 22h 18m 54s
42900:	learn: 0.0442461	test: 0.0668119	best: 0.0668118 (42865)	total: 5m 31s	remaining: 8d 22h 19m 44s
43200:	learn: 0.0442069	test: 0.0668056	best: 0.0668051 (43192)	total: 5m 33s	remaining: 8d 22h 20m 22s
43500:	learn: 0.0441599	test: 0.0667929	best: 0.0667929 (43500)	total: 5m 35s	remaining: 8d 22h 19m 11s
43800:	learn: 0.0441150	test: 0.0667809	best: 0.0667809 (43800)	total: 5m 38s	remaining: 8d 22h 19m 46s
44100:	learn: 0.0440680	test: 0.0667751	best: 0.0667751 (44098)	total: 5m 40s	remaining: 8d 22h 19m 17s
44400:	learn: 0.0440284	test: 0.0667694	best: 0.0667691 (44395)	total: 5m 42s	remaining: 8d 22h 19m 13s
44700:	learn: 0.0439833	test: 0.0667636	best: 0.0667632 (44608)	total: 5m 45s	remaining: 8d 22h 17m 48s
45000:	learn: 0.0439422	test: 0.0667560	best: 0.0667548 (44987)	total: 5m 47s	remaining: 8d 22h 17m 23s
45300:	learn: 0.0438985	test: 0.0667498	best: 0.0667481 (45267)	total: 5m 49s	remaining: 8d 22h 16m 28s
45600:	learn: 0.0438569	test: 0.0667424	best: 0.0667410 (45534)	total: 5m 51s	remaining: 8d 22h 18m 53s
45900:	learn: 0.0438129	test: 0.0667308	best: 0.0667284 (45863)	total: 5m 54s	remaining: 8d 22h 20m 24s
46200:	learn: 0.0437701	test: 0.0667188	best: 0.0667185 (46191)	total: 5m 56s	remaining: 8d 22h 19m 39s
46500:	learn: 0.0437217	test: 0.0667156	best: 0.0667130 (46319)	total: 5m 58s	remaining: 8d 22h 18m 47s
46800:	learn: 0.0436774	test: 0.0667118	best: 0.0667095 (46728)	total: 6m 1s	remaining: 8d 22h 22m 6s
47100:	learn: 0.0436350	test: 0.0667085	best: 0.0667082 (47088)	total: 6m 3s	remaining: 8d 22h 28m 48s
47400:	learn: 0.0435939	test: 0.0667078	best: 0.0667066 (47183)	total: 6m 6s	remaining: 8d 22h 29m 55s
47700:	learn: 0.0435513	test: 0.0667079	best: 0.0667065 (47513)	total: 6m 8s	remaining: 8d 22h 30m 36s
48000:	learn: 0.0435105	test: 0.0666998	best: 0.0666995 (47988)	total: 6m 10s	remaining: 8d 22h 33m 17s
48300:	learn: 0.0434657	test: 0.0666971	best: 0.0666933 (48243)	total: 6m 13s	remaining: 8d 22h 34m 35s
48600:	learn: 0.0434217	test: 0.0666865	best: 0.0666855 (48539)	total: 6m 15s	remaining: 8d 22h 35m 12s
48900:	learn: 0.0433779	test: 0.0666761	best: 0.0666755 (48894)	total: 6m 18s	remaining: 8d 22h 37m 11s
49200:	learn: 0.0433351	test: 0.0666731	best: 0.0666730 (49098)	total: 6m 20s	remaining: 8d 22h 38m 29s
49500:	learn: 0.0432946	test: 0.0666654	best: 0.0666652 (49493)	total: 6m 22s	remaining: 8d 22h 44m 55s
49800:	learn: 0.0432614	test: 0.0666612	best: 0.0666611 (49799)	total: 6m 25s	remaining: 8d 22h 44m 6s
50100:	learn: 0.0432256	test: 0.0666505	best: 0.0666501 (50097)	total: 6m 27s	remaining: 8d 22h 43m 28s
50400:	learn: 0.0431807	test: 0.0666423	best: 0.0666423 (50400)	total: 6m 29s	remaining: 8d 22h 42m 30s
50700:	learn: 0.0431389	test: 0.0666428	best: 0.0666418 (50412)	total: 6m 32s	remaining: 8d 22h 44m 29s
51000:	learn: 0.0430972	test: 0.0666380	best: 0.0666380 (51000)	total: 6m 34s	remaining: 8d 22h 43m 13s
51300:	learn: 0.0430594	test: 0.0666308	best: 0.0666301 (51198)	total: 6m 36s	remaining: 8d 22h 44m 52s
51600:	learn: 0.0430211	test: 0.0666232	best: 0.0666228 (51589)	total: 6m 39s	remaining: 8d 22h 43m 29s
51900:	learn: 0.0429814	test: 0.0666181	best: 0.0666180 (51896)	total: 6m 41s	remaining: 8d 22h 43m 2s
52200:	learn: 0.0429438	test: 0.0666119	best: 0.0666106 (52123)	total: 6m 43s	remaining: 8d 22h 43m 9s
52500:	learn: 0.0429010	test: 0.0666064	best: 0.0666064 (52499)	total: 6m 46s	remaining: 8d 22h 42m 38s
52800:	learn: 0.0428608	test: 0.0665971	best: 0.0665967 (52792)	total: 6m 48s	remaining: 8d 22h 42m 13s
53100:	learn: 0.0428201	test: 0.0665941	best: 0.0665925 (53012)	total: 6m 50s	remaining: 8d 22h 44m 11s
53400:	learn: 0.0427832	test: 0.0665857	best: 0.0665855 (53398)	total: 6m 53s	remaining: 8d 22h 43m 21s
53700:	learn: 0.0427443	test: 0.0665813	best: 0.0665809 (53599)	total: 6m 55s	remaining: 8d 22h 44m 13s
54000:	learn: 0.0427046	test: 0.0665697	best: 0.0665694 (53993)	total: 6m 57s	remaining: 8d 22h 46m 12s
54300:	learn: 0.0426687	test: 0.0665699	best: 0.0665680 (54104)	total: 7m	remaining: 8d 22h 48m 28s
54600:	learn: 0.0426337	test: 0.0665609	best: 0.0665608 (54593)	total: 7m 2s	remaining: 8d 22h 48m 15s
54900:	learn: 0.0425970	test: 0.0665563	best: 0.0665538 (54808)	total: 7m 4s	remaining: 8d 22h 47m 29s
55200:	learn: 0.0425566	test: 0.0665464	best: 0.0665455 (55167)	total: 7m 7s	remaining: 8d 22h 54m 15s
55500:	learn: 0.0425162	test: 0.0665335	best: 0.0665335 (55500)	total: 7m 9s	remaining: 8d 22h 55m 34s
55800:	learn: 0.0424741	test: 0.0665316	best: 0.0665316 (55800)	total: 7m 12s	remaining: 8d 22h 56m 45s
56100:	learn: 0.0424379	test: 0.0665258	best: 0.0665258 (56100)	total: 7m 14s	remaining: 8d 22h 57m 22s
56400:	learn: 0.0424008	test: 0.0665215	best: 0.0665198 (56284)	total: 7m 16s	remaining: 8d 22h 57m 30s
56700:	learn: 0.0423653	test: 0.0665198	best: 0.0665196 (56695)	total: 7m 19s	remaining: 8d 22h 59m 28s
57000:	learn: 0.0423257	test: 0.0665120	best: 0.0665118 (56999)	total: 7m 21s	remaining: 8d 23h 25s
57300:	learn: 0.0422867	test: 0.0665085	best: 0.0665055 (57264)	total: 7m 23s	remaining: 8d 23h 1m 27s
57600:	learn: 0.0422540	test: 0.0665007	best: 0.0665006 (57598)	total: 7m 26s	remaining: 8d 23h 2m 27s
57900:	learn: 0.0422224	test: 0.0664996	best: 0.0664982 (57858)	total: 7m 28s	remaining: 8d 23h 3m 17s
58200:	learn: 0.0421905	test: 0.0664889	best: 0.0664889 (58200)	total: 7m 30s	remaining: 8d 23h 2m 27s
58500:	learn: 0.0421520	test: 0.0664765	best: 0.0664756 (58446)	total: 7m 33s	remaining: 8d 23h 1m 44s
58800:	learn: 0.0421132	test: 0.0664567	best: 0.0664567 (58800)	total: 7m 35s	remaining: 8d 23h 1m 36s
59100:	learn: 0.0420789	test: 0.0664443	best: 0.0664442 (59099)	total: 7m 37s	remaining: 8d 23h 9s
59400:	learn: 0.0420419	test: 0.0664373	best: 0.0664371 (59398)	total: 7m 40s	remaining: 8d 23h 1m 46s
59700:	learn: 0.0420054	test: 0.0664341	best: 0.0664326 (59467)	total: 7m 42s	remaining: 8d 23h 2m 2s
60000:	learn: 0.0419705	test: 0.0664314	best: 0.0664287 (59902)	total: 7m 44s	remaining: 8d 23h 42s
60300:	learn: 0.0419347	test: 0.0664286	best: 0.0664286 (60300)	total: 7m 46s	remaining: 8d 22h 59m 24s
60600:	learn: 0.0419046	test: 0.0664240	best: 0.0664239 (60593)	total: 7m 49s	remaining: 8d 22h 59m 14s
60900:	learn: 0.0418707	test: 0.0664136	best: 0.0664133 (60878)	total: 7m 51s	remaining: 8d 22h 58m 36s
61200:	learn: 0.0418369	test: 0.0664067	best: 0.0664064 (61182)	total: 7m 53s	remaining: 8d 22h 58m 11s
61500:	learn: 0.0418039	test: 0.0664019	best: 0.0664013 (61445)	total: 7m 56s	remaining: 8d 22h 59m 21s
61800:	learn: 0.0417694	test: 0.0664004	best: 0.0663982 (61603)	total: 7m 58s	remaining: 8d 22h 58m 42s
62100:	learn: 0.0417304	test: 0.0663921	best: 0.0663907 (62078)	total: 8m	remaining: 8d 23h 52s
62400:	learn: 0.0416952	test: 0.0663878	best: 0.0663861 (62396)	total: 8m 3s	remaining: 8d 23h 16s
62700:	learn: 0.0416628	test: 0.0663877	best: 0.0663831 (62609)	total: 8m 5s	remaining: 8d 22h 59m 57s
63000:	learn: 0.0416275	test: 0.0663855	best: 0.0663831 (62609)	total: 8m 7s	remaining: 8d 22h 59m 14s
63300:	learn: 0.0415943	test: 0.0663796	best: 0.0663775 (63263)	total: 8m 10s	remaining: 8d 23h 4m 12s
63600:	learn: 0.0415624	test: 0.0663762	best: 0.0663762 (63600)	total: 8m 12s	remaining: 8d 23h 4m 13s
63900:	learn: 0.0415300	test: 0.0663677	best: 0.0663676 (63896)	total: 8m 15s	remaining: 8d 23h 4m 29s
64200:	learn: 0.0414975	test: 0.0663657	best: 0.0663639 (64176)	total: 8m 17s	remaining: 8d 23h 4m 14s
64500:	learn: 0.0414690	test: 0.0663635	best: 0.0663632 (64396)	total: 8m 19s	remaining: 8d 23h 5m 58s
64800:	learn: 0.0414396	test: 0.0663626	best: 0.0663592 (64723)	total: 8m 22s	remaining: 8d 23h 6m 33s
65100:	learn: 0.0414096	test: 0.0663632	best: 0.0663592 (64723)	total: 8m 24s	remaining: 8d 23h 7m 18s
65400:	learn: 0.0413812	test: 0.0663579	best: 0.0663568 (65338)	total: 8m 26s	remaining: 8d 23h 7m 21s
65700:	learn: 0.0413522	test: 0.0663491	best: 0.0663486 (65696)	total: 8m 29s	remaining: 8d 23h 11m 13s
66000:	learn: 0.0413202	test: 0.0663486	best: 0.0663469 (65790)	total: 8m 31s	remaining: 8d 23h 11m 50s
66300:	learn: 0.0412856	test: 0.0663423	best: 0.0663423 (66300)	total: 8m 33s	remaining: 8d 23h 12m 11s
66600:	learn: 0.0412561	test: 0.0663391	best: 0.0663374 (66558)	total: 8m 36s	remaining: 8d 23h 12m 25s
66900:	learn: 0.0412241	test: 0.0663339	best: 0.0663326 (66897)	total: 8m 38s	remaining: 8d 23h 12m 29s
67200:	learn: 0.0411949	test: 0.0663349	best: 0.0663315 (66954)	total: 8m 40s	remaining: 8d 23h 12m 7s
67500:	learn: 0.0411663	test: 0.0663333	best: 0.0663315 (66954)	total: 8m 43s	remaining: 8d 23h 12m 35s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.06633154954
bestIteration = 66954

Shrink model to first 66955 iterations.
fold n°3
0:	learn: 0.5685732	test: 0.5784631	best: 0.5784631 (0)	total: 11.5ms	remaining: 13d 6h 7m 31s
300:	learn: 0.1334941	test: 0.1359600	best: 0.1359600 (300)	total: 2.46s	remaining: 9d 10h 49m 30s
600:	learn: 0.0978265	test: 0.0998736	best: 0.0998736 (600)	total: 4.74s	remaining: 9d 2h 51m 43s
900:	learn: 0.0889275	test: 0.0910818	best: 0.0910818 (900)	total: 7.02s	remaining: 9d 30m 17s
1200:	learn: 0.0837890	test: 0.0864116	best: 0.0864116 (1200)	total: 9.31s	remaining: 8d 23h 16m 2s
1500:	learn: 0.0798488	test: 0.0833124	best: 0.0833124 (1500)	total: 11.7s	remaining: 8d 23h 59m 34s
1800:	learn: 0.0769332	test: 0.0810945	best: 0.0810945 (1800)	total: 14.1s	remaining: 9d 1h 5m 39s
2100:	learn: 0.0745586	test: 0.0793984	best: 0.0793984 (2100)	total: 16.4s	remaining: 9d 52m 49s
2400:	learn: 0.0725842	test: 0.0780652	best: 0.0780652 (2400)	total: 18.8s	remaining: 9d 1h 14m 36s
2700:	learn: 0.0709400	test: 0.0769863	best: 0.0769863 (2700)	total: 21.1s	remaining: 9d 1h 5m 34s
3000:	learn: 0.0695065	test: 0.0761725	best: 0.0761725 (3000)	total: 23.5s	remaining: 9d 1h 16m 26s
3300:	learn: 0.0682138	test: 0.0753991	best: 0.0753991 (3300)	total: 25.9s	remaining: 9d 1h 59m 52s
3600:	learn: 0.0670835	test: 0.0748181	best: 0.0748181 (3600)	total: 28.4s	remaining: 9d 3h 12m 10s
3900:	learn: 0.0660966	test: 0.0743124	best: 0.0743124 (3900)	total: 30.8s	remaining: 9d 3h 15m 15s
4200:	learn: 0.0651715	test: 0.0738322	best: 0.0738322 (4200)	total: 33.2s	remaining: 9d 3h 45m 4s
4500:	learn: 0.0643292	test: 0.0734373	best: 0.0734373 (4500)	total: 35.6s	remaining: 9d 3h 58m 36s
4800:	learn: 0.0635584	test: 0.0730834	best: 0.0730834 (4800)	total: 38.1s	remaining: 9d 4h 11m 30s
5100:	learn: 0.0628695	test: 0.0727449	best: 0.0727421 (5098)	total: 40.4s	remaining: 9d 4h 6m 5s
5400:	learn: 0.0621793	test: 0.0724235	best: 0.0724235 (5400)	total: 42.8s	remaining: 9d 4h 12m 34s
5700:	learn: 0.0615683	test: 0.0721544	best: 0.0721544 (5700)	total: 45.2s	remaining: 9d 4h 22m 20s
6000:	learn: 0.0609971	test: 0.0719221	best: 0.0719221 (6000)	total: 47.8s	remaining: 9d 5h 3m 22s
6300:	learn: 0.0604623	test: 0.0717103	best: 0.0717088 (6297)	total: 50.1s	remaining: 9d 5h 44s
6600:	learn: 0.0599640	test: 0.0714884	best: 0.0714884 (6600)	total: 52.5s	remaining: 9d 4h 56m 46s
6900:	learn: 0.0594717	test: 0.0712870	best: 0.0712870 (6900)	total: 54.9s	remaining: 9d 4h 46m 1s
7200:	learn: 0.0590168	test: 0.0710831	best: 0.0710830 (7199)	total: 57.3s	remaining: 9d 4h 50m 46s
7500:	learn: 0.0585908	test: 0.0709166	best: 0.0709166 (7500)	total: 59.6s	remaining: 9d 4h 34m 1s
7800:	learn: 0.0581760	test: 0.0707304	best: 0.0707304 (7800)	total: 1m 2s	remaining: 9d 5h 3m 54s
8100:	learn: 0.0578021	test: 0.0705950	best: 0.0705950 (8100)	total: 1m 4s	remaining: 9d 4h 49m 8s
8400:	learn: 0.0574263	test: 0.0704667	best: 0.0704667 (8400)	total: 1m 6s	remaining: 9d 4h 31m 9s
8700:	learn: 0.0570728	test: 0.0703376	best: 0.0703376 (8700)	total: 1m 8s	remaining: 9d 4h 8m 4s
9000:	learn: 0.0567208	test: 0.0702082	best: 0.0702082 (9000)	total: 1m 11s	remaining: 9d 4h 3m 49s
9300:	learn: 0.0563830	test: 0.0700963	best: 0.0700963 (9300)	total: 1m 13s	remaining: 9d 3h 53m 31s
9600:	learn: 0.0560525	test: 0.0699950	best: 0.0699950 (9600)	total: 1m 15s	remaining: 9d 3h 43m 1s
9900:	learn: 0.0557536	test: 0.0698966	best: 0.0698964 (9899)	total: 1m 18s	remaining: 9d 3h 27m 46s
10200:	learn: 0.0554811	test: 0.0697943	best: 0.0697942 (10199)	total: 1m 20s	remaining: 9d 3h 16m 18s
10500:	learn: 0.0552175	test: 0.0697095	best: 0.0697095 (10500)	total: 1m 22s	remaining: 9d 2h 59m 46s
10800:	learn: 0.0549409	test: 0.0696141	best: 0.0696139 (10799)	total: 1m 25s	remaining: 9d 2h 49m 53s
11100:	learn: 0.0546881	test: 0.0695197	best: 0.0695197 (11100)	total: 1m 27s	remaining: 9d 2h 37m 36s
11400:	learn: 0.0544570	test: 0.0694398	best: 0.0694398 (11400)	total: 1m 29s	remaining: 9d 2h 31m 17s
11700:	learn: 0.0542228	test: 0.0693608	best: 0.0693606 (11699)	total: 1m 31s	remaining: 9d 2h 21m 39s
12000:	learn: 0.0539965	test: 0.0692994	best: 0.0692993 (11999)	total: 1m 34s	remaining: 9d 2h 15m 47s
12300:	learn: 0.0537797	test: 0.0692327	best: 0.0692327 (12300)	total: 1m 36s	remaining: 9d 2h 4m 54s
12600:	learn: 0.0535736	test: 0.0691704	best: 0.0691704 (12600)	total: 1m 38s	remaining: 9d 1h 52m 15s
12900:	learn: 0.0533658	test: 0.0691000	best: 0.0691000 (12900)	total: 1m 41s	remaining: 9d 1h 46m 35s
13200:	learn: 0.0531622	test: 0.0690314	best: 0.0690302 (13180)	total: 1m 43s	remaining: 9d 1h 36m 23s
13500:	learn: 0.0529697	test: 0.0689721	best: 0.0689701 (13482)	total: 1m 45s	remaining: 9d 1h 29m 35s
13800:	learn: 0.0527910	test: 0.0689138	best: 0.0689124 (13794)	total: 1m 48s	remaining: 9d 1h 22m 18s
14100:	learn: 0.0526065	test: 0.0688542	best: 0.0688542 (14100)	total: 1m 50s	remaining: 9d 1h 16m 55s
14400:	learn: 0.0524366	test: 0.0687889	best: 0.0687889 (14400)	total: 1m 52s	remaining: 9d 1h 6m 42s
14700:	learn: 0.0522607	test: 0.0687344	best: 0.0687340 (14696)	total: 1m 54s	remaining: 9d 1h 3m 58s
15000:	learn: 0.0520847	test: 0.0686866	best: 0.0686866 (15000)	total: 1m 57s	remaining: 9d 55m 58s
15300:	learn: 0.0519174	test: 0.0686369	best: 0.0686369 (15300)	total: 1m 59s	remaining: 9d 47m 12s
15600:	learn: 0.0517524	test: 0.0685834	best: 0.0685834 (15600)	total: 2m 1s	remaining: 9d 44m 4s
15900:	learn: 0.0515899	test: 0.0685320	best: 0.0685317 (15898)	total: 2m 4s	remaining: 9d 37m 7s
16200:	learn: 0.0514333	test: 0.0684877	best: 0.0684873 (16196)	total: 2m 6s	remaining: 9d 32m 35s
16500:	learn: 0.0512832	test: 0.0684406	best: 0.0684399 (16493)	total: 2m 8s	remaining: 9d 24m 34s
16800:	learn: 0.0511351	test: 0.0683849	best: 0.0683840 (16798)	total: 2m 10s	remaining: 9d 20m 50s
17100:	learn: 0.0509973	test: 0.0683540	best: 0.0683536 (17099)	total: 2m 13s	remaining: 9d 26m 6s
17400:	learn: 0.0508528	test: 0.0683134	best: 0.0683133 (17399)	total: 2m 15s	remaining: 9d 21m 15s
17700:	learn: 0.0507211	test: 0.0682694	best: 0.0682692 (17696)	total: 2m 17s	remaining: 9d 12m 32s
18000:	learn: 0.0505848	test: 0.0682285	best: 0.0682281 (17998)	total: 2m 20s	remaining: 9d 9m 2s
18300:	learn: 0.0504514	test: 0.0681914	best: 0.0681914 (18300)	total: 2m 22s	remaining: 9d 2m 56s
18600:	learn: 0.0503336	test: 0.0681461	best: 0.0681461 (18600)	total: 2m 24s	remaining: 8d 23h 57m 37s
18900:	learn: 0.0502194	test: 0.0681323	best: 0.0681280 (18856)	total: 2m 26s	remaining: 8d 23h 50m 22s
19200:	learn: 0.0500956	test: 0.0680993	best: 0.0680993 (19200)	total: 2m 29s	remaining: 8d 23h 44m 30s
19500:	learn: 0.0499756	test: 0.0680599	best: 0.0680597 (19495)	total: 2m 31s	remaining: 8d 23h 41m 36s
19800:	learn: 0.0498514	test: 0.0680241	best: 0.0680241 (19800)	total: 2m 33s	remaining: 8d 23h 36m 57s
20100:	learn: 0.0497469	test: 0.0680092	best: 0.0680091 (20099)	total: 2m 36s	remaining: 8d 23h 33m 49s
20400:	learn: 0.0496365	test: 0.0679784	best: 0.0679782 (20398)	total: 2m 38s	remaining: 8d 23h 28m 34s
20700:	learn: 0.0495260	test: 0.0679347	best: 0.0679347 (20700)	total: 2m 40s	remaining: 8d 23h 29m 31s
21000:	learn: 0.0494160	test: 0.0679050	best: 0.0679050 (21000)	total: 2m 42s	remaining: 8d 23h 23m 25s
21300:	learn: 0.0493011	test: 0.0678807	best: 0.0678795 (21293)	total: 2m 45s	remaining: 8d 23h 20m 57s
21600:	learn: 0.0491897	test: 0.0678531	best: 0.0678531 (21600)	total: 2m 47s	remaining: 8d 23h 16m 43s
21900:	learn: 0.0490875	test: 0.0678242	best: 0.0678239 (21898)	total: 2m 49s	remaining: 8d 23h 12m 13s
22200:	learn: 0.0489901	test: 0.0678110	best: 0.0678108 (22194)	total: 2m 51s	remaining: 8d 23h 6m 44s
22500:	learn: 0.0488874	test: 0.0677819	best: 0.0677816 (22499)	total: 2m 54s	remaining: 8d 23h 3m 35s
22800:	learn: 0.0487883	test: 0.0677478	best: 0.0677476 (22799)	total: 2m 56s	remaining: 8d 23h 17s
23100:	learn: 0.0486902	test: 0.0677231	best: 0.0677231 (23100)	total: 2m 58s	remaining: 8d 22h 57m 14s
23400:	learn: 0.0486062	test: 0.0677009	best: 0.0676999 (23386)	total: 3m 1s	remaining: 8d 22h 52m 41s
23700:	learn: 0.0485134	test: 0.0676801	best: 0.0676801 (23700)	total: 3m 3s	remaining: 8d 22h 49m 37s
24000:	learn: 0.0484191	test: 0.0676555	best: 0.0676549 (23989)	total: 3m 5s	remaining: 8d 22h 47m 21s
24300:	learn: 0.0483205	test: 0.0676241	best: 0.0676232 (24296)	total: 3m 7s	remaining: 8d 22h 44m 25s
24600:	learn: 0.0482262	test: 0.0676114	best: 0.0676061 (24547)	total: 3m 10s	remaining: 8d 22h 47m 40s
24900:	learn: 0.0481385	test: 0.0675862	best: 0.0675861 (24896)	total: 3m 12s	remaining: 8d 22h 46m 12s
25200:	learn: 0.0480494	test: 0.0675655	best: 0.0675654 (25198)	total: 3m 14s	remaining: 8d 22h 45m 23s
25500:	learn: 0.0479663	test: 0.0675557	best: 0.0675549 (25493)	total: 3m 17s	remaining: 8d 22h 40m 23s
25800:	learn: 0.0478816	test: 0.0675341	best: 0.0675326 (25757)	total: 3m 19s	remaining: 8d 22h 39m 32s
26100:	learn: 0.0478011	test: 0.0675206	best: 0.0675206 (26100)	total: 3m 21s	remaining: 8d 22h 35m 33s
26400:	learn: 0.0477246	test: 0.0675119	best: 0.0675106 (26373)	total: 3m 23s	remaining: 8d 22h 32m 10s
26700:	learn: 0.0476541	test: 0.0674983	best: 0.0674975 (26690)	total: 3m 26s	remaining: 8d 22h 27m 48s
27000:	learn: 0.0475773	test: 0.0674823	best: 0.0674822 (26999)	total: 3m 28s	remaining: 8d 22h 25m 21s
27300:	learn: 0.0474984	test: 0.0674657	best: 0.0674657 (27299)	total: 3m 30s	remaining: 8d 22h 21m 54s
27600:	learn: 0.0474127	test: 0.0674445	best: 0.0674445 (27600)	total: 3m 33s	remaining: 8d 22h 23m 58s
27900:	learn: 0.0473430	test: 0.0674295	best: 0.0674281 (27893)	total: 3m 35s	remaining: 8d 22h 20m 20s
28200:	learn: 0.0472793	test: 0.0674160	best: 0.0674160 (28200)	total: 3m 37s	remaining: 8d 22h 16m 37s
28500:	learn: 0.0472083	test: 0.0673960	best: 0.0673960 (28500)	total: 3m 39s	remaining: 8d 22h 13m 45s
28800:	learn: 0.0471289	test: 0.0673766	best: 0.0673756 (28757)	total: 3m 42s	remaining: 8d 22h 9m 42s
29100:	learn: 0.0470602	test: 0.0673636	best: 0.0673635 (29097)	total: 3m 44s	remaining: 8d 22h 7m 18s
29400:	learn: 0.0469939	test: 0.0673473	best: 0.0673468 (29398)	total: 3m 46s	remaining: 8d 22h 3m 10s
29700:	learn: 0.0469215	test: 0.0673306	best: 0.0673305 (29697)	total: 3m 48s	remaining: 8d 22h 53s
30000:	learn: 0.0468528	test: 0.0673223	best: 0.0673223 (29998)	total: 3m 51s	remaining: 8d 21h 58m 31s
30300:	learn: 0.0467856	test: 0.0672985	best: 0.0672981 (30298)	total: 3m 53s	remaining: 8d 21h 55m 35s
30600:	learn: 0.0467199	test: 0.0672834	best: 0.0672834 (30600)	total: 3m 55s	remaining: 8d 21h 51m 45s
30900:	learn: 0.0466580	test: 0.0672696	best: 0.0672687 (30879)	total: 3m 57s	remaining: 8d 21h 49m 30s
31200:	learn: 0.0465975	test: 0.0672673	best: 0.0672657 (31156)	total: 4m	remaining: 8d 21h 47m 35s
31500:	learn: 0.0465268	test: 0.0672480	best: 0.0672466 (31481)	total: 4m 2s	remaining: 8d 21h 46m 23s
31800:	learn: 0.0464704	test: 0.0672368	best: 0.0672368 (31800)	total: 4m 4s	remaining: 8d 21h 44m 51s
32100:	learn: 0.0464021	test: 0.0672262	best: 0.0672262 (32100)	total: 4m 7s	remaining: 8d 21h 43m 6s
32400:	learn: 0.0463349	test: 0.0672053	best: 0.0672050 (32399)	total: 4m 9s	remaining: 8d 21h 41m 17s
32700:	learn: 0.0462794	test: 0.0671915	best: 0.0671915 (32700)	total: 4m 11s	remaining: 8d 21h 37m 28s
33000:	learn: 0.0462143	test: 0.0671697	best: 0.0671697 (33000)	total: 4m 13s	remaining: 8d 21h 37m 37s
33300:	learn: 0.0461505	test: 0.0671516	best: 0.0671516 (33300)	total: 4m 16s	remaining: 8d 21h 35m 10s
33600:	learn: 0.0460908	test: 0.0671390	best: 0.0671380 (33508)	total: 4m 18s	remaining: 8d 21h 33m 17s
33900:	learn: 0.0460316	test: 0.0671219	best: 0.0671215 (33896)	total: 4m 20s	remaining: 8d 21h 30m 52s
34200:	learn: 0.0459783	test: 0.0671173	best: 0.0671171 (34199)	total: 4m 22s	remaining: 8d 21h 27m 37s
34500:	learn: 0.0459215	test: 0.0671115	best: 0.0671084 (34474)	total: 4m 25s	remaining: 8d 21h 25m 7s
34800:	learn: 0.0458626	test: 0.0670935	best: 0.0670929 (34782)	total: 4m 27s	remaining: 8d 21h 23m 51s
35100:	learn: 0.0458138	test: 0.0670859	best: 0.0670859 (35097)	total: 4m 29s	remaining: 8d 21h 20m 27s
35400:	learn: 0.0457592	test: 0.0670752	best: 0.0670750 (35392)	total: 4m 31s	remaining: 8d 21h 17m 29s
35700:	learn: 0.0457036	test: 0.0670631	best: 0.0670630 (35698)	total: 4m 34s	remaining: 8d 21h 16m 54s
36000:	learn: 0.0456486	test: 0.0670515	best: 0.0670502 (35959)	total: 4m 36s	remaining: 8d 21h 16m 32s
36300:	learn: 0.0455890	test: 0.0670402	best: 0.0670398 (36122)	total: 4m 38s	remaining: 8d 21h 14m 45s
36600:	learn: 0.0455293	test: 0.0670332	best: 0.0670328 (36596)	total: 4m 41s	remaining: 8d 21h 12m 30s
36900:	learn: 0.0454685	test: 0.0670197	best: 0.0670188 (36892)	total: 4m 43s	remaining: 8d 21h 11m 33s
37200:	learn: 0.0454150	test: 0.0670089	best: 0.0670085 (37187)	total: 4m 45s	remaining: 8d 21h 9m 38s
37500:	learn: 0.0453537	test: 0.0669956	best: 0.0669956 (37499)	total: 4m 47s	remaining: 8d 21h 9m 21s
37800:	learn: 0.0453041	test: 0.0669821	best: 0.0669821 (37800)	total: 4m 50s	remaining: 8d 21h 8m 39s
38100:	learn: 0.0452493	test: 0.0669769	best: 0.0669768 (38054)	total: 4m 52s	remaining: 8d 21h 9m 14s
38400:	learn: 0.0451892	test: 0.0669637	best: 0.0669637 (38400)	total: 4m 54s	remaining: 8d 21h 16m 36s
38700:	learn: 0.0451342	test: 0.0669508	best: 0.0669508 (38699)	total: 4m 58s	remaining: 8d 22h 46s
39000:	learn: 0.0450859	test: 0.0669389	best: 0.0669389 (39000)	total: 5m	remaining: 8d 22h 3m 12s
39300:	learn: 0.0450272	test: 0.0669321	best: 0.0669317 (39297)	total: 5m 2s	remaining: 8d 22h 2m 41s
39600:	learn: 0.0449696	test: 0.0669177	best: 0.0669168 (39566)	total: 5m 5s	remaining: 8d 22h 54s
39900:	learn: 0.0449157	test: 0.0669087	best: 0.0669081 (39813)	total: 5m 7s	remaining: 8d 22h 40s
40200:	learn: 0.0448656	test: 0.0669086	best: 0.0669051 (40044)	total: 5m 9s	remaining: 8d 21h 59m 33s
40500:	learn: 0.0448198	test: 0.0668953	best: 0.0668953 (40500)	total: 5m 12s	remaining: 8d 21h 57m 15s
40800:	learn: 0.0447664	test: 0.0668847	best: 0.0668841 (40798)	total: 5m 14s	remaining: 8d 21h 55m 32s
41100:	learn: 0.0447097	test: 0.0668745	best: 0.0668736 (41076)	total: 5m 16s	remaining: 8d 22h 27s
41400:	learn: 0.0446584	test: 0.0668698	best: 0.0668678 (41376)	total: 5m 19s	remaining: 8d 22h 51s
41700:	learn: 0.0446074	test: 0.0668660	best: 0.0668641 (41648)	total: 5m 21s	remaining: 8d 21h 58m 36s
42000:	learn: 0.0445601	test: 0.0668539	best: 0.0668537 (41993)	total: 5m 23s	remaining: 8d 21h 57m 5s
42300:	learn: 0.0445079	test: 0.0668417	best: 0.0668417 (42300)	total: 5m 25s	remaining: 8d 21h 55m 31s
42600:	learn: 0.0444594	test: 0.0668313	best: 0.0668313 (42599)	total: 5m 28s	remaining: 8d 21h 56m 41s
42900:	learn: 0.0444108	test: 0.0668226	best: 0.0668218 (42845)	total: 5m 30s	remaining: 8d 21h 56m 21s
43200:	learn: 0.0443696	test: 0.0668133	best: 0.0668131 (43196)	total: 5m 32s	remaining: 8d 21h 59m 34s
43500:	learn: 0.0443216	test: 0.0668017	best: 0.0668013 (43478)	total: 5m 35s	remaining: 8d 22h 10m 17s
43800:	learn: 0.0442728	test: 0.0667921	best: 0.0667915 (43790)	total: 5m 37s	remaining: 8d 22h 13m 56s
44100:	learn: 0.0442319	test: 0.0667825	best: 0.0667815 (44086)	total: 5m 40s	remaining: 8d 22h 11m 9s
44400:	learn: 0.0441817	test: 0.0667657	best: 0.0667645 (44386)	total: 5m 42s	remaining: 8d 22h 9m 34s
44700:	learn: 0.0441356	test: 0.0667570	best: 0.0667570 (44700)	total: 5m 44s	remaining: 8d 22h 7m 7s
45000:	learn: 0.0440884	test: 0.0667471	best: 0.0667465 (44979)	total: 5m 46s	remaining: 8d 22h 5m 42s
45300:	learn: 0.0440440	test: 0.0667340	best: 0.0667338 (45299)	total: 5m 49s	remaining: 8d 22h 3m 33s
45600:	learn: 0.0439948	test: 0.0667281	best: 0.0667264 (45546)	total: 5m 51s	remaining: 8d 22h 1m 24s
45900:	learn: 0.0439497	test: 0.0667168	best: 0.0667168 (45894)	total: 5m 53s	remaining: 8d 21h 59m 49s
46200:	learn: 0.0439032	test: 0.0667111	best: 0.0667103 (46075)	total: 5m 56s	remaining: 8d 21h 59m 9s
46500:	learn: 0.0438612	test: 0.0667030	best: 0.0667027 (46490)	total: 5m 58s	remaining: 8d 21h 56m 27s
46800:	learn: 0.0438223	test: 0.0666954	best: 0.0666954 (46798)	total: 6m	remaining: 8d 21h 54m 24s
47100:	learn: 0.0437808	test: 0.0666894	best: 0.0666892 (47090)	total: 6m 2s	remaining: 8d 21h 54m 36s
47400:	learn: 0.0437368	test: 0.0666842	best: 0.0666834 (47353)	total: 6m 5s	remaining: 8d 21h 52m 18s
47700:	learn: 0.0436910	test: 0.0666716	best: 0.0666713 (47656)	total: 6m 7s	remaining: 8d 21h 51m 54s
48000:	learn: 0.0436443	test: 0.0666653	best: 0.0666648 (47985)	total: 6m 9s	remaining: 8d 21h 49m 42s
48300:	learn: 0.0435982	test: 0.0666549	best: 0.0666548 (48298)	total: 6m 11s	remaining: 8d 21h 48m 25s
48600:	learn: 0.0435564	test: 0.0666516	best: 0.0666506 (48510)	total: 6m 14s	remaining: 8d 21h 47m 13s
48900:	learn: 0.0435175	test: 0.0666433	best: 0.0666429 (48895)	total: 6m 16s	remaining: 8d 21h 46m 34s
49200:	learn: 0.0434762	test: 0.0666358	best: 0.0666358 (49200)	total: 6m 18s	remaining: 8d 21h 44m 41s
49500:	learn: 0.0434390	test: 0.0666309	best: 0.0666309 (49500)	total: 6m 21s	remaining: 8d 21h 42m 42s
49800:	learn: 0.0433959	test: 0.0666219	best: 0.0666219 (49800)	total: 6m 23s	remaining: 8d 21h 42m 57s
50100:	learn: 0.0433566	test: 0.0666056	best: 0.0666056 (50100)	total: 6m 25s	remaining: 8d 21h 41m 37s
50400:	learn: 0.0433186	test: 0.0666025	best: 0.0666020 (50396)	total: 6m 27s	remaining: 8d 21h 41m 7s
50700:	learn: 0.0432851	test: 0.0665977	best: 0.0665977 (50700)	total: 6m 30s	remaining: 8d 21h 41m 59s
51000:	learn: 0.0432438	test: 0.0665833	best: 0.0665828 (50995)	total: 6m 32s	remaining: 8d 21h 51m 44s
51300:	learn: 0.0432066	test: 0.0665735	best: 0.0665734 (51298)	total: 6m 35s	remaining: 8d 21h 56m 56s
51600:	learn: 0.0431678	test: 0.0665675	best: 0.0665675 (51600)	total: 6m 37s	remaining: 8d 22h 6m 52s
51900:	learn: 0.0431311	test: 0.0665586	best: 0.0665583 (51888)	total: 6m 40s	remaining: 8d 22h 18m 11s
52200:	learn: 0.0430935	test: 0.0665445	best: 0.0665441 (52174)	total: 6m 43s	remaining: 8d 22h 20m 46s
52500:	learn: 0.0430535	test: 0.0665381	best: 0.0665376 (52485)	total: 6m 45s	remaining: 8d 22h 23m 34s
52800:	learn: 0.0430153	test: 0.0665280	best: 0.0665280 (52799)	total: 6m 48s	remaining: 8d 22h 33m 54s
53100:	learn: 0.0429767	test: 0.0665189	best: 0.0665185 (53096)	total: 6m 50s	remaining: 8d 22h 40m 13s
53400:	learn: 0.0429355	test: 0.0665126	best: 0.0665103 (53348)	total: 6m 53s	remaining: 8d 22h 50m 19s
53700:	learn: 0.0428920	test: 0.0665086	best: 0.0665078 (53509)	total: 6m 55s	remaining: 8d 23h 18s
54000:	learn: 0.0428514	test: 0.0664985	best: 0.0664981 (53996)	total: 6m 58s	remaining: 8d 23h 4m 24s
54300:	learn: 0.0428197	test: 0.0664944	best: 0.0664933 (54256)	total: 7m	remaining: 8d 23h 1m 37s
54600:	learn: 0.0427842	test: 0.0664888	best: 0.0664878 (54540)	total: 7m 2s	remaining: 8d 23h 4m 6s
54900:	learn: 0.0427434	test: 0.0664831	best: 0.0664803 (54873)	total: 7m 5s	remaining: 8d 23h 4m 55s
55200:	learn: 0.0427009	test: 0.0664782	best: 0.0664778 (55197)	total: 7m 7s	remaining: 8d 23h 4m 43s
55500:	learn: 0.0426667	test: 0.0664789	best: 0.0664776 (55232)	total: 7m 9s	remaining: 8d 23h 2m 49s
55800:	learn: 0.0426298	test: 0.0664741	best: 0.0664726 (55775)	total: 7m 12s	remaining: 8d 23h 1m 13s
56100:	learn: 0.0426021	test: 0.0664759	best: 0.0664726 (55775)	total: 7m 14s	remaining: 8d 22h 59m 17s
56400:	learn: 0.0425665	test: 0.0664713	best: 0.0664713 (56400)	total: 7m 16s	remaining: 8d 22h 56m 54s
56700:	learn: 0.0425348	test: 0.0664653	best: 0.0664653 (56700)	total: 7m 18s	remaining: 8d 22h 54m 34s
57000:	learn: 0.0425016	test: 0.0664547	best: 0.0664547 (57000)	total: 7m 21s	remaining: 8d 22h 52m 10s
57300:	learn: 0.0424662	test: 0.0664418	best: 0.0664417 (57299)	total: 7m 23s	remaining: 8d 22h 50m 43s
57600:	learn: 0.0424338	test: 0.0664391	best: 0.0664379 (57584)	total: 7m 25s	remaining: 8d 22h 49m 37s
57900:	learn: 0.0423952	test: 0.0664348	best: 0.0664348 (57900)	total: 7m 27s	remaining: 8d 22h 48m
58200:	learn: 0.0423598	test: 0.0664352	best: 0.0664335 (58132)	total: 7m 30s	remaining: 8d 22h 45m 59s
58500:	learn: 0.0423273	test: 0.0664297	best: 0.0664290 (58482)	total: 7m 32s	remaining: 8d 22h 43m 54s
58800:	learn: 0.0422938	test: 0.0664215	best: 0.0664215 (58800)	total: 7m 34s	remaining: 8d 22h 42m 13s
59100:	learn: 0.0422584	test: 0.0664133	best: 0.0664133 (59100)	total: 7m 37s	remaining: 8d 22h 40m 22s
59400:	learn: 0.0422235	test: 0.0664068	best: 0.0664066 (59395)	total: 7m 39s	remaining: 8d 22h 38m 23s
59700:	learn: 0.0421900	test: 0.0663997	best: 0.0663995 (59654)	total: 7m 41s	remaining: 8d 22h 37m 14s
60000:	learn: 0.0421577	test: 0.0663952	best: 0.0663940 (59981)	total: 7m 43s	remaining: 8d 22h 35m 59s
60300:	learn: 0.0421185	test: 0.0663866	best: 0.0663863 (60294)	total: 7m 46s	remaining: 8d 22h 33m 54s
60600:	learn: 0.0420843	test: 0.0663803	best: 0.0663791 (60576)	total: 7m 48s	remaining: 8d 22h 32m 22s
60900:	learn: 0.0420541	test: 0.0663736	best: 0.0663728 (60885)	total: 7m 50s	remaining: 8d 22h 31m 13s
61200:	learn: 0.0420231	test: 0.0663663	best: 0.0663662 (61199)	total: 7m 52s	remaining: 8d 22h 29m 18s
61500:	learn: 0.0419872	test: 0.0663549	best: 0.0663548 (61499)	total: 7m 55s	remaining: 8d 22h 28m 51s
61800:	learn: 0.0419523	test: 0.0663534	best: 0.0663518 (61663)	total: 7m 57s	remaining: 8d 22h 28m 44s
62100:	learn: 0.0419200	test: 0.0663466	best: 0.0663461 (62083)	total: 7m 59s	remaining: 8d 22h 27m 34s
62400:	learn: 0.0418853	test: 0.0663425	best: 0.0663417 (62391)	total: 8m 2s	remaining: 8d 22h 26m 42s
62700:	learn: 0.0418558	test: 0.0663377	best: 0.0663366 (62676)	total: 8m 4s	remaining: 8d 22h 26m 13s
63000:	learn: 0.0418234	test: 0.0663254	best: 0.0663253 (62999)	total: 8m 6s	remaining: 8d 22h 24m 27s
63300:	learn: 0.0417883	test: 0.0663227	best: 0.0663202 (63165)	total: 8m 8s	remaining: 8d 22h 23m 39s
63600:	learn: 0.0417545	test: 0.0663159	best: 0.0663156 (63587)	total: 8m 11s	remaining: 8d 22h 22m 37s
63900:	learn: 0.0417229	test: 0.0663092	best: 0.0663086 (63889)	total: 8m 13s	remaining: 8d 22h 21m 43s
64200:	learn: 0.0416901	test: 0.0663017	best: 0.0663017 (64200)	total: 8m 15s	remaining: 8d 22h 20m 3s
64500:	learn: 0.0416583	test: 0.0663028	best: 0.0662993 (64239)	total: 8m 17s	remaining: 8d 22h 18m 1s
64800:	learn: 0.0416263	test: 0.0662906	best: 0.0662899 (64758)	total: 8m 20s	remaining: 8d 22h 16m 13s
65100:	learn: 0.0415943	test: 0.0662851	best: 0.0662848 (65091)	total: 8m 22s	remaining: 8d 22h 16m 53s
65400:	learn: 0.0415662	test: 0.0662785	best: 0.0662774 (65377)	total: 8m 24s	remaining: 8d 22h 16m 20s
65700:	learn: 0.0415375	test: 0.0662698	best: 0.0662687 (65671)	total: 8m 27s	remaining: 8d 22h 14m 40s
66000:	learn: 0.0415043	test: 0.0662660	best: 0.0662638 (65844)	total: 8m 29s	remaining: 8d 22h 13m 5s
66300:	learn: 0.0414709	test: 0.0662613	best: 0.0662600 (66288)	total: 8m 31s	remaining: 8d 22h 12m 47s
66600:	learn: 0.0414381	test: 0.0662595	best: 0.0662563 (66557)	total: 8m 33s	remaining: 8d 22h 11m 27s
66900:	learn: 0.0414077	test: 0.0662522	best: 0.0662522 (66900)	total: 8m 36s	remaining: 8d 22h 12m 42s
67200:	learn: 0.0413796	test: 0.0662503	best: 0.0662499 (66937)	total: 8m 38s	remaining: 8d 22h 19m 15s
67500:	learn: 0.0413514	test: 0.0662421	best: 0.0662419 (67490)	total: 8m 41s	remaining: 8d 22h 21m 27s
67800:	learn: 0.0413254	test: 0.0662410	best: 0.0662395 (67729)	total: 8m 44s	remaining: 8d 22h 41m 15s
68100:	learn: 0.0412949	test: 0.0662351	best: 0.0662351 (68100)	total: 8m 47s	remaining: 8d 22h 51m 59s
68400:	learn: 0.0412676	test: 0.0662349	best: 0.0662323 (68330)	total: 8m 49s	remaining: 8d 22h 55m 47s
68700:	learn: 0.0412423	test: 0.0662266	best: 0.0662266 (68700)	total: 8m 52s	remaining: 8d 23h 1m 41s
69000:	learn: 0.0412165	test: 0.0662255	best: 0.0662244 (68782)	total: 8m 54s	remaining: 8d 23h 2m 23s
69300:	learn: 0.0411867	test: 0.0662236	best: 0.0662218 (69116)	total: 8m 57s	remaining: 8d 23h 13m 35s
69600:	learn: 0.0411547	test: 0.0662173	best: 0.0662172 (69599)	total: 8m 59s	remaining: 8d 23h 19m 49s
69900:	learn: 0.0411250	test: 0.0662129	best: 0.0662127 (69844)	total: 9m 2s	remaining: 8d 23h 19m 53s
70200:	learn: 0.0410964	test: 0.0662019	best: 0.0662017 (70198)	total: 9m 4s	remaining: 8d 23h 20m 1s
70500:	learn: 0.0410658	test: 0.0661920	best: 0.0661918 (70484)	total: 9m 6s	remaining: 8d 23h 19m 35s
70800:	learn: 0.0410373	test: 0.0661925	best: 0.0661901 (70637)	total: 9m 9s	remaining: 8d 23h 19m 16s
71100:	learn: 0.0410066	test: 0.0661831	best: 0.0661824 (71093)	total: 9m 11s	remaining: 8d 23h 20m 41s
71400:	learn: 0.0409784	test: 0.0661760	best: 0.0661759 (71398)	total: 9m 13s	remaining: 8d 23h 20m 33s
71700:	learn: 0.0409515	test: 0.0661691	best: 0.0661680 (71689)	total: 9m 16s	remaining: 8d 23h 19m 48s
72000:	learn: 0.0409258	test: 0.0661730	best: 0.0661680 (71689)	total: 9m 18s	remaining: 8d 23h 20m 32s
72300:	learn: 0.0408942	test: 0.0661654	best: 0.0661637 (72231)	total: 9m 20s	remaining: 8d 23h 22m 21s
72600:	learn: 0.0408689	test: 0.0661639	best: 0.0661637 (72231)	total: 9m 23s	remaining: 8d 23h 23m 57s
72900:	learn: 0.0408432	test: 0.0661660	best: 0.0661634 (72605)	total: 9m 25s	remaining: 8d 23h 26m 45s
73200:	learn: 0.0408167	test: 0.0661563	best: 0.0661557 (73184)	total: 9m 28s	remaining: 8d 23h 30m 24s
73500:	learn: 0.0407917	test: 0.0661547	best: 0.0661546 (73493)	total: 9m 30s	remaining: 8d 23h 32m 58s
73800:	learn: 0.0407720	test: 0.0661488	best: 0.0661472 (73686)	total: 9m 33s	remaining: 8d 23h 37m 8s
74100:	learn: 0.0407459	test: 0.0661370	best: 0.0661370 (74100)	total: 9m 35s	remaining: 8d 23h 40m 41s
74400:	learn: 0.0407219	test: 0.0661330	best: 0.0661330 (74360)	total: 9m 38s	remaining: 8d 23h 44m 43s
74700:	learn: 0.0406967	test: 0.0661219	best: 0.0661219 (74700)	total: 9m 40s	remaining: 8d 23h 48m 42s
75000:	learn: 0.0406676	test: 0.0661171	best: 0.0661170 (74998)	total: 9m 43s	remaining: 8d 23h 52m 51s
75300:	learn: 0.0406432	test: 0.0661101	best: 0.0661099 (75290)	total: 9m 45s	remaining: 8d 23h 55m 10s
75600:	learn: 0.0406200	test: 0.0661082	best: 0.0661071 (75370)	total: 9m 48s	remaining: 8d 23h 55m 54s
75900:	learn: 0.0405954	test: 0.0661002	best: 0.0660997 (75893)	total: 9m 50s	remaining: 8d 23h 55m 54s
76200:	learn: 0.0405686	test: 0.0660963	best: 0.0660958 (76126)	total: 9m 52s	remaining: 8d 23h 54m 44s
76500:	learn: 0.0405452	test: 0.0660932	best: 0.0660912 (76439)	total: 9m 55s	remaining: 8d 23h 53m 19s
76800:	learn: 0.0405190	test: 0.0660895	best: 0.0660879 (76718)	total: 9m 57s	remaining: 8d 23h 51m 34s
77100:	learn: 0.0404948	test: 0.0660811	best: 0.0660807 (77096)	total: 9m 59s	remaining: 8d 23h 50m 53s
77400:	learn: 0.0404696	test: 0.0660779	best: 0.0660756 (77295)	total: 10m 1s	remaining: 8d 23h 50m 4s
77700:	learn: 0.0404447	test: 0.0660720	best: 0.0660718 (77686)	total: 10m 4s	remaining: 8d 23h 49m 9s
78000:	learn: 0.0404215	test: 0.0660701	best: 0.0660684 (77967)	total: 10m 6s	remaining: 8d 23h 47m 44s
78300:	learn: 0.0403976	test: 0.0660673	best: 0.0660650 (78228)	total: 10m 8s	remaining: 8d 23h 46m 31s
78600:	learn: 0.0403735	test: 0.0660675	best: 0.0660650 (78228)	total: 10m 11s	remaining: 8d 23h 46m 8s
78900:	learn: 0.0403498	test: 0.0660562	best: 0.0660562 (78900)	total: 10m 13s	remaining: 8d 23h 46m 31s
79200:	learn: 0.0403247	test: 0.0660518	best: 0.0660518 (79200)	total: 10m 15s	remaining: 8d 23h 46m 56s
79500:	learn: 0.0403023	test: 0.0660518	best: 0.0660505 (79224)	total: 10m 18s	remaining: 8d 23h 47m 3s
79800:	learn: 0.0402790	test: 0.0660504	best: 0.0660503 (79571)	total: 10m 20s	remaining: 8d 23h 46m 13s
80100:	learn: 0.0402526	test: 0.0660479	best: 0.0660476 (80094)	total: 10m 22s	remaining: 8d 23h 47m 57s
80400:	learn: 0.0402298	test: 0.0660452	best: 0.0660422 (80268)	total: 10m 25s	remaining: 8d 23h 50m 44s
80700:	learn: 0.0402070	test: 0.0660433	best: 0.0660419 (80522)	total: 10m 27s	remaining: 8d 23h 50m 22s
81000:	learn: 0.0401853	test: 0.0660407	best: 0.0660406 (80998)	total: 10m 29s	remaining: 8d 23h 48m 55s
81300:	learn: 0.0401619	test: 0.0660390	best: 0.0660389 (81299)	total: 10m 32s	remaining: 8d 23h 49m 26s
81600:	learn: 0.0401373	test: 0.0660413	best: 0.0660388 (81306)	total: 10m 34s	remaining: 8d 23h 47m 58s
81900:	learn: 0.0401115	test: 0.0660418	best: 0.0660388 (81306)	total: 10m 36s	remaining: 8d 23h 46m 22s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.06603882964
bestIteration = 81306

Shrink model to first 81307 iterations.
fold n°4
0:	learn: 0.5683598	test: 0.5800404	best: 0.5800404 (0)	total: 8.11ms	remaining: 9d 9h 18m 25s
300:	learn: 0.1332653	test: 0.1409192	best: 0.1409192 (300)	total: 2.44s	remaining: 9d 8h 54m 41s
600:	learn: 0.0978413	test: 0.1031752	best: 0.1031752 (600)	total: 4.79s	remaining: 9d 5h 25m 32s
900:	learn: 0.0891291	test: 0.0940757	best: 0.0940757 (900)	total: 7.03s	remaining: 9d 44m 50s
1200:	learn: 0.0838000	test: 0.0889065	best: 0.0889065 (1200)	total: 9.33s	remaining: 8d 23h 46m
1500:	learn: 0.0798122	test: 0.0853840	best: 0.0853840 (1500)	total: 11.7s	remaining: 9d 20m 28s
1800:	learn: 0.0767983	test: 0.0829579	best: 0.0829579 (1800)	total: 14s	remaining: 9d 34m 38s
2100:	learn: 0.0744656	test: 0.0811198	best: 0.0811198 (2100)	total: 16.4s	remaining: 9d 27m 47s
2400:	learn: 0.0725048	test: 0.0797391	best: 0.0797391 (2400)	total: 18.7s	remaining: 9d 47m 34s
2700:	learn: 0.0708897	test: 0.0786103	best: 0.0786103 (2700)	total: 21.1s	remaining: 9d 1h 23m 40s
3000:	learn: 0.0694607	test: 0.0776266	best: 0.0776266 (3000)	total: 23.6s	remaining: 9d 2h 1m 41s
3300:	learn: 0.0681291	test: 0.0767532	best: 0.0767532 (3300)	total: 26s	remaining: 9d 2h 26m 16s
3600:	learn: 0.0669781	test: 0.0760710	best: 0.0760710 (3600)	total: 28.3s	remaining: 9d 2h 36m 45s
3900:	learn: 0.0659507	test: 0.0754886	best: 0.0754886 (3900)	total: 30.8s	remaining: 9d 3h 37m 8s
4200:	learn: 0.0650226	test: 0.0750054	best: 0.0750054 (4200)	total: 33.3s	remaining: 9d 4h 4m 44s
4500:	learn: 0.0641916	test: 0.0745800	best: 0.0745792 (4495)	total: 35.7s	remaining: 9d 4h 25m 23s
4800:	learn: 0.0634477	test: 0.0742120	best: 0.0742120 (4800)	total: 38.1s	remaining: 9d 4h 12m 45s
5100:	learn: 0.0627216	test: 0.0738780	best: 0.0738780 (5100)	total: 40.5s	remaining: 9d 4h 43m 49s
5400:	learn: 0.0620434	test: 0.0735730	best: 0.0735730 (5400)	total: 42.9s	remaining: 9d 4h 37m
5700:	learn: 0.0614404	test: 0.0732959	best: 0.0732959 (5700)	total: 45.3s	remaining: 9d 4h 43m 17s
6000:	learn: 0.0608649	test: 0.0730367	best: 0.0730359 (5999)	total: 47.7s	remaining: 9d 4h 50m
6300:	learn: 0.0603218	test: 0.0728568	best: 0.0728561 (6296)	total: 50.1s	remaining: 9d 5h 2m 7s
6600:	learn: 0.0598112	test: 0.0726130	best: 0.0726130 (6600)	total: 52.5s	remaining: 9d 4h 48m 20s
6900:	learn: 0.0593446	test: 0.0724203	best: 0.0724203 (6900)	total: 54.8s	remaining: 9d 4h 44m 1s
7200:	learn: 0.0588987	test: 0.0722058	best: 0.0722058 (7200)	total: 57.2s	remaining: 9d 4h 37m 42s
7500:	learn: 0.0584685	test: 0.0720180	best: 0.0720179 (7499)	total: 59.5s	remaining: 9d 4h 23m 29s
7800:	learn: 0.0580633	test: 0.0718592	best: 0.0718592 (7800)	total: 1m 1s	remaining: 9d 4h 26m 47s
8100:	learn: 0.0576678	test: 0.0717061	best: 0.0717061 (8100)	total: 1m 4s	remaining: 9d 4h 26m
8400:	learn: 0.0572818	test: 0.0715441	best: 0.0715441 (8400)	total: 1m 6s	remaining: 9d 4h 29m 34s
8700:	learn: 0.0569058	test: 0.0713891	best: 0.0713881 (8699)	total: 1m 9s	remaining: 9d 4h 21m 53s
9000:	learn: 0.0565747	test: 0.0712523	best: 0.0712523 (9000)	total: 1m 11s	remaining: 9d 4h 40m 46s
9300:	learn: 0.0562520	test: 0.0711364	best: 0.0711364 (9299)	total: 1m 13s	remaining: 9d 4h 36m 32s
9600:	learn: 0.0559309	test: 0.0710514	best: 0.0710514 (9600)	total: 1m 16s	remaining: 9d 4h 49m 33s
9900:	learn: 0.0556181	test: 0.0709468	best: 0.0709460 (9895)	total: 1m 18s	remaining: 9d 4h 46m 59s
10200:	learn: 0.0553226	test: 0.0708716	best: 0.0708716 (10200)	total: 1m 21s	remaining: 9d 5h 8m 27s
10500:	learn: 0.0550354	test: 0.0707960	best: 0.0707955 (10498)	total: 1m 23s	remaining: 9d 5h 30m 25s
10800:	learn: 0.0547570	test: 0.0706948	best: 0.0706944 (10797)	total: 1m 26s	remaining: 9d 5h 29m 6s
11100:	learn: 0.0544800	test: 0.0706077	best: 0.0706077 (11100)	total: 1m 28s	remaining: 9d 5h 27m 27s
11400:	learn: 0.0542276	test: 0.0705348	best: 0.0705348 (11400)	total: 1m 30s	remaining: 9d 5h 19m 29s
11700:	learn: 0.0539892	test: 0.0704451	best: 0.0704449 (11698)	total: 1m 33s	remaining: 9d 5h 6m 24s
12000:	learn: 0.0537481	test: 0.0703563	best: 0.0703548 (11995)	total: 1m 35s	remaining: 9d 4h 55m 1s
12300:	learn: 0.0535183	test: 0.0702803	best: 0.0702802 (12299)	total: 1m 37s	remaining: 9d 4h 43m 11s
12600:	learn: 0.0532856	test: 0.0701957	best: 0.0701957 (12600)	total: 1m 40s	remaining: 9d 4h 35m 30s
12900:	learn: 0.0530760	test: 0.0701427	best: 0.0701422 (12878)	total: 1m 42s	remaining: 9d 4h 25m 19s
13200:	learn: 0.0528601	test: 0.0700703	best: 0.0700703 (13200)	total: 1m 44s	remaining: 9d 4h 20m 54s
13500:	learn: 0.0526448	test: 0.0700081	best: 0.0700081 (13500)	total: 1m 47s	remaining: 9d 4h 21m 34s
13800:	learn: 0.0524573	test: 0.0699489	best: 0.0699489 (13800)	total: 1m 49s	remaining: 9d 4h 12m 26s
14100:	learn: 0.0522692	test: 0.0698993	best: 0.0698990 (14095)	total: 1m 51s	remaining: 9d 4h 4m 33s
14400:	learn: 0.0520719	test: 0.0698375	best: 0.0698361 (14395)	total: 1m 54s	remaining: 9d 3h 57m 2s
14700:	learn: 0.0518900	test: 0.0697835	best: 0.0697835 (14700)	total: 1m 56s	remaining: 9d 3h 48m 4s
15000:	learn: 0.0517141	test: 0.0697292	best: 0.0697292 (15000)	total: 1m 58s	remaining: 9d 3h 41m 53s
15300:	learn: 0.0515385	test: 0.0696858	best: 0.0696848 (15292)	total: 2m	remaining: 9d 3h 37m 1s
15600:	learn: 0.0513727	test: 0.0696362	best: 0.0696362 (15600)	total: 2m 3s	remaining: 9d 3h 43m 59s
15900:	learn: 0.0512202	test: 0.0695905	best: 0.0695897 (15896)	total: 2m 5s	remaining: 9d 3h 39m 41s
16200:	learn: 0.0510599	test: 0.0695489	best: 0.0695485 (16187)	total: 2m 8s	remaining: 9d 3h 32m 32s
16500:	learn: 0.0509030	test: 0.0695070	best: 0.0695069 (16495)	total: 2m 10s	remaining: 9d 3h 27m 37s
16800:	learn: 0.0507514	test: 0.0694671	best: 0.0694671 (16800)	total: 2m 12s	remaining: 9d 3h 21m
17100:	learn: 0.0506163	test: 0.0694378	best: 0.0694373 (17096)	total: 2m 14s	remaining: 9d 3h 13m 17s
17400:	learn: 0.0504673	test: 0.0694029	best: 0.0694029 (17400)	total: 2m 17s	remaining: 9d 3h 6m 11s
17700:	learn: 0.0503229	test: 0.0693714	best: 0.0693714 (17700)	total: 2m 19s	remaining: 9d 3h 4m 26s
18000:	learn: 0.0501872	test: 0.0693386	best: 0.0693386 (18000)	total: 2m 22s	remaining: 9d 3h 11m 44s
18300:	learn: 0.0500558	test: 0.0693095	best: 0.0693092 (18298)	total: 2m 24s	remaining: 9d 3h 5m 26s
18600:	learn: 0.0499310	test: 0.0692663	best: 0.0692657 (18595)	total: 2m 26s	remaining: 9d 3h 3m 54s
18900:	learn: 0.0498031	test: 0.0692254	best: 0.0692250 (18895)	total: 2m 29s	remaining: 9d 2h 58m 50s
19200:	learn: 0.0496728	test: 0.0691941	best: 0.0691933 (19189)	total: 2m 31s	remaining: 9d 2h 53m 36s
19500:	learn: 0.0495479	test: 0.0691731	best: 0.0691731 (19500)	total: 2m 33s	remaining: 9d 2h 48m 8s
19800:	learn: 0.0494309	test: 0.0691443	best: 0.0691430 (19783)	total: 2m 35s	remaining: 9d 2h 42m 59s
20100:	learn: 0.0493138	test: 0.0691231	best: 0.0691228 (20074)	total: 2m 38s	remaining: 9d 2h 41m 2s
20400:	learn: 0.0492070	test: 0.0691022	best: 0.0691013 (20384)	total: 2m 40s	remaining: 9d 2h 37m 3s
20700:	learn: 0.0491043	test: 0.0690819	best: 0.0690800 (20646)	total: 2m 42s	remaining: 9d 2h 37m 39s
21000:	learn: 0.0489988	test: 0.0690544	best: 0.0690543 (20999)	total: 2m 45s	remaining: 9d 2h 35m 49s
21300:	learn: 0.0488897	test: 0.0690248	best: 0.0690234 (21293)	total: 2m 47s	remaining: 9d 2h 30m 37s
21600:	learn: 0.0487877	test: 0.0689946	best: 0.0689946 (21600)	total: 2m 49s	remaining: 9d 2h 29m 35s
21900:	learn: 0.0486875	test: 0.0689738	best: 0.0689715 (21882)	total: 2m 52s	remaining: 9d 2h 27m 13s
22200:	learn: 0.0485884	test: 0.0689554	best: 0.0689542 (22116)	total: 2m 54s	remaining: 9d 2h 29m 21s
22500:	learn: 0.0484813	test: 0.0689300	best: 0.0689300 (22500)	total: 2m 57s	remaining: 9d 2h 29m 21s
22800:	learn: 0.0483856	test: 0.0689130	best: 0.0689130 (22800)	total: 2m 59s	remaining: 9d 2h 30m 9s
23100:	learn: 0.0482791	test: 0.0688774	best: 0.0688758 (23077)	total: 3m 1s	remaining: 9d 2h 25m 34s
23400:	learn: 0.0481727	test: 0.0688529	best: 0.0688529 (23400)	total: 3m 4s	remaining: 9d 2h 27m 31s
23700:	learn: 0.0480764	test: 0.0688324	best: 0.0688313 (23699)	total: 3m 6s	remaining: 9d 2h 27m 7s
24000:	learn: 0.0479837	test: 0.0688139	best: 0.0688138 (23999)	total: 3m 8s	remaining: 9d 2h 23m 14s
24300:	learn: 0.0478918	test: 0.0687971	best: 0.0687964 (24263)	total: 3m 11s	remaining: 9d 2h 18m 46s
24600:	learn: 0.0477974	test: 0.0687769	best: 0.0687769 (24600)	total: 3m 13s	remaining: 9d 2h 13m 47s
24900:	learn: 0.0477083	test: 0.0687589	best: 0.0687589 (24900)	total: 3m 15s	remaining: 9d 2h 9m 38s
25200:	learn: 0.0476190	test: 0.0687361	best: 0.0687357 (25199)	total: 3m 17s	remaining: 9d 2h 8m 46s
25500:	learn: 0.0475349	test: 0.0687140	best: 0.0687128 (25455)	total: 3m 20s	remaining: 9d 2h 18m 8s
25800:	learn: 0.0474595	test: 0.0687063	best: 0.0687059 (25795)	total: 3m 22s	remaining: 9d 2h 15m 45s
26100:	learn: 0.0473660	test: 0.0686792	best: 0.0686789 (26094)	total: 3m 25s	remaining: 9d 2h 11m 57s
26400:	learn: 0.0472804	test: 0.0686612	best: 0.0686612 (26400)	total: 3m 27s	remaining: 9d 2h 10m 1s
26700:	learn: 0.0471903	test: 0.0686545	best: 0.0686531 (26660)	total: 3m 29s	remaining: 9d 2h 6m 50s
27000:	learn: 0.0471120	test: 0.0686425	best: 0.0686416 (26990)	total: 3m 32s	remaining: 9d 2h 2m 24s
27300:	learn: 0.0470361	test: 0.0686291	best: 0.0686291 (27300)	total: 3m 34s	remaining: 9d 1h 57m 10s
27600:	learn: 0.0469518	test: 0.0686089	best: 0.0686086 (27596)	total: 3m 36s	remaining: 9d 1h 54m 5s
27900:	learn: 0.0468798	test: 0.0685995	best: 0.0685983 (27883)	total: 3m 38s	remaining: 9d 1h 50m 12s
28200:	learn: 0.0468003	test: 0.0685881	best: 0.0685881 (28200)	total: 3m 41s	remaining: 9d 1h 49m 48s
28500:	learn: 0.0467156	test: 0.0685813	best: 0.0685809 (28470)	total: 3m 43s	remaining: 9d 1h 46m 46s
28800:	learn: 0.0466357	test: 0.0685737	best: 0.0685733 (28792)	total: 3m 45s	remaining: 9d 1h 44m
29100:	learn: 0.0465538	test: 0.0685570	best: 0.0685567 (29095)	total: 3m 48s	remaining: 9d 1h 42m 46s
29400:	learn: 0.0464761	test: 0.0685381	best: 0.0685381 (29400)	total: 3m 50s	remaining: 9d 1h 42m 58s
29700:	learn: 0.0464010	test: 0.0685173	best: 0.0685162 (29698)	total: 3m 52s	remaining: 9d 1h 47m 43s
30000:	learn: 0.0463323	test: 0.0685021	best: 0.0685015 (29994)	total: 3m 55s	remaining: 9d 1h 50m 22s
30300:	learn: 0.0462600	test: 0.0684823	best: 0.0684823 (30300)	total: 3m 57s	remaining: 9d 1h 54m 42s
30600:	learn: 0.0461864	test: 0.0684704	best: 0.0684696 (30574)	total: 4m	remaining: 9d 1h 54m 23s
30900:	learn: 0.0461144	test: 0.0684540	best: 0.0684540 (30900)	total: 4m 2s	remaining: 9d 1h 58m 1s
31200:	learn: 0.0460474	test: 0.0684377	best: 0.0684362 (31194)	total: 4m 4s	remaining: 9d 1h 56m 43s
31500:	learn: 0.0459810	test: 0.0684255	best: 0.0684255 (31500)	total: 4m 7s	remaining: 9d 1h 56m 27s
31800:	learn: 0.0459114	test: 0.0684126	best: 0.0684125 (31742)	total: 4m 9s	remaining: 9d 1h 55m 42s
32100:	learn: 0.0458534	test: 0.0684052	best: 0.0684052 (32100)	total: 4m 11s	remaining: 9d 1h 54m 53s
32400:	learn: 0.0457878	test: 0.0683961	best: 0.0683961 (32400)	total: 4m 14s	remaining: 9d 1h 52m 51s
32700:	learn: 0.0457276	test: 0.0683886	best: 0.0683882 (32696)	total: 4m 16s	remaining: 9d 1h 54m 6s
33000:	learn: 0.0456656	test: 0.0683783	best: 0.0683761 (32967)	total: 4m 19s	remaining: 9d 1h 59m 56s
33300:	learn: 0.0455996	test: 0.0683737	best: 0.0683735 (33299)	total: 4m 21s	remaining: 9d 2h 1m 49s
33600:	learn: 0.0455369	test: 0.0683528	best: 0.0683526 (33598)	total: 4m 23s	remaining: 9d 1h 59m 58s
33900:	learn: 0.0454726	test: 0.0683366	best: 0.0683363 (33899)	total: 4m 26s	remaining: 9d 2h 2m 23s
34200:	learn: 0.0454135	test: 0.0683255	best: 0.0683250 (34194)	total: 4m 28s	remaining: 9d 2h 3m 23s
34500:	learn: 0.0453538	test: 0.0683137	best: 0.0683137 (34500)	total: 4m 31s	remaining: 9d 2h 9m 3s
34800:	learn: 0.0452953	test: 0.0682975	best: 0.0682969 (34793)	total: 4m 33s	remaining: 9d 2h 12m 22s
35100:	learn: 0.0452390	test: 0.0682900	best: 0.0682889 (35064)	total: 4m 35s	remaining: 9d 2h 17m 38s
35400:	learn: 0.0451885	test: 0.0682708	best: 0.0682707 (35382)	total: 4m 38s	remaining: 9d 2h 17m 24s
35700:	learn: 0.0451318	test: 0.0682584	best: 0.0682584 (35696)	total: 4m 40s	remaining: 9d 2h 16m 45s
36000:	learn: 0.0450807	test: 0.0682491	best: 0.0682483 (35968)	total: 4m 43s	remaining: 9d 2h 25m 37s
36300:	learn: 0.0450232	test: 0.0682359	best: 0.0682351 (36277)	total: 4m 45s	remaining: 9d 2h 24m 5s
36600:	learn: 0.0449601	test: 0.0682243	best: 0.0682239 (36597)	total: 4m 47s	remaining: 9d 2h 24m 36s
36900:	learn: 0.0449049	test: 0.0682127	best: 0.0682116 (36788)	total: 4m 50s	remaining: 9d 2h 28m 41s
37200:	learn: 0.0448524	test: 0.0682007	best: 0.0682002 (37190)	total: 4m 52s	remaining: 9d 2h 29m 32s
37500:	learn: 0.0448016	test: 0.0681915	best: 0.0681903 (37463)	total: 4m 55s	remaining: 9d 2h 33m 1s
37800:	learn: 0.0447517	test: 0.0681851	best: 0.0681841 (37617)	total: 4m 57s	remaining: 9d 2h 38m 7s
38100:	learn: 0.0447003	test: 0.0681766	best: 0.0681765 (38092)	total: 5m	remaining: 9d 2h 46m 42s
38400:	learn: 0.0446434	test: 0.0681689	best: 0.0681682 (38399)	total: 5m 2s	remaining: 9d 2h 57m 9s
38700:	learn: 0.0445826	test: 0.0681614	best: 0.0681614 (38700)	total: 5m 5s	remaining: 9d 2h 59m 15s
39000:	learn: 0.0445300	test: 0.0681442	best: 0.0681423 (38977)	total: 5m 7s	remaining: 9d 3h 3m 15s
39300:	learn: 0.0444754	test: 0.0681281	best: 0.0681281 (39300)	total: 5m 10s	remaining: 9d 3h 5m 18s
39600:	learn: 0.0444223	test: 0.0681202	best: 0.0681192 (39517)	total: 5m 12s	remaining: 9d 3h 7m 52s
39900:	learn: 0.0443642	test: 0.0681062	best: 0.0681061 (39898)	total: 5m 14s	remaining: 9d 3h 9m 25s
40200:	learn: 0.0443133	test: 0.0681036	best: 0.0681031 (40175)	total: 5m 17s	remaining: 9d 3h 13m 13s
40500:	learn: 0.0442611	test: 0.0680968	best: 0.0680964 (40499)	total: 5m 19s	remaining: 9d 3h 16m 52s
40800:	learn: 0.0442061	test: 0.0680835	best: 0.0680834 (40798)	total: 5m 22s	remaining: 9d 3h 17m 13s
41100:	learn: 0.0441548	test: 0.0680721	best: 0.0680721 (41100)	total: 5m 24s	remaining: 9d 3h 18m 4s
41400:	learn: 0.0441084	test: 0.0680633	best: 0.0680632 (41387)	total: 5m 27s	remaining: 9d 3h 19m 50s
41700:	learn: 0.0440606	test: 0.0680565	best: 0.0680543 (41573)	total: 5m 29s	remaining: 9d 3h 24m 14s
42000:	learn: 0.0440124	test: 0.0680509	best: 0.0680495 (41928)	total: 5m 31s	remaining: 9d 3h 25m 58s
42300:	learn: 0.0439680	test: 0.0680458	best: 0.0680438 (42191)	total: 5m 34s	remaining: 9d 3h 25m 53s
42600:	learn: 0.0439176	test: 0.0680326	best: 0.0680317 (42598)	total: 5m 36s	remaining: 9d 3h 28m 27s
42900:	learn: 0.0438695	test: 0.0680265	best: 0.0680246 (42882)	total: 5m 39s	remaining: 9d 3h 28m 26s
43200:	learn: 0.0438204	test: 0.0680172	best: 0.0680164 (43162)	total: 5m 41s	remaining: 9d 3h 32m 54s
43500:	learn: 0.0437776	test: 0.0680136	best: 0.0680116 (43470)	total: 5m 43s	remaining: 9d 3h 30m 22s
43800:	learn: 0.0437268	test: 0.0680034	best: 0.0680034 (43800)	total: 5m 46s	remaining: 9d 3h 28m 32s
44100:	learn: 0.0436844	test: 0.0680054	best: 0.0680024 (43910)	total: 5m 48s	remaining: 9d 3h 29m 31s
44400:	learn: 0.0436355	test: 0.0679970	best: 0.0679970 (44400)	total: 5m 51s	remaining: 9d 3h 30m 33s
44700:	learn: 0.0435894	test: 0.0679901	best: 0.0679891 (44585)	total: 5m 53s	remaining: 9d 3h 29m 14s
45000:	learn: 0.0435442	test: 0.0679830	best: 0.0679817 (44991)	total: 5m 55s	remaining: 9d 3h 28m 8s
45300:	learn: 0.0434980	test: 0.0679743	best: 0.0679740 (45290)	total: 5m 58s	remaining: 9d 3h 29m 53s
45600:	learn: 0.0434476	test: 0.0679639	best: 0.0679631 (45593)	total: 6m	remaining: 9d 3h 29m 22s
45900:	learn: 0.0434033	test: 0.0679547	best: 0.0679545 (45897)	total: 6m 2s	remaining: 9d 3h 28m 9s
46200:	learn: 0.0433561	test: 0.0679443	best: 0.0679436 (46151)	total: 6m 5s	remaining: 9d 3h 26m 40s
46500:	learn: 0.0433128	test: 0.0679401	best: 0.0679383 (46443)	total: 6m 7s	remaining: 9d 3h 26m 40s
46800:	learn: 0.0432716	test: 0.0679353	best: 0.0679346 (46787)	total: 6m 9s	remaining: 9d 3h 25m 42s
47100:	learn: 0.0432301	test: 0.0679255	best: 0.0679253 (47075)	total: 6m 12s	remaining: 9d 3h 23m 30s
47400:	learn: 0.0431883	test: 0.0679229	best: 0.0679228 (47392)	total: 6m 14s	remaining: 9d 3h 25m 1s
47700:	learn: 0.0431429	test: 0.0679150	best: 0.0679138 (47656)	total: 6m 16s	remaining: 9d 3h 23m 54s
48000:	learn: 0.0431017	test: 0.0679183	best: 0.0679138 (47656)	total: 6m 19s	remaining: 9d 3h 22m 31s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.06791375458
bestIteration = 47656

Shrink model to first 47657 iterations.
fold n°5
0:	learn: 0.5704620	test: 0.5632603	best: 0.5632603 (0)	total: 14.4ms	remaining: 16d 17h 24m 23s
300:	learn: 0.1342345	test: 0.1316169	best: 0.1316169 (300)	total: 2.43s	remaining: 9d 8h 6m 36s
600:	learn: 0.0982854	test: 0.0967770	best: 0.0967770 (600)	total: 4.84s	remaining: 9d 7h 50m 5s
900:	learn: 0.0893372	test: 0.0884149	best: 0.0884149 (900)	total: 7.23s	remaining: 9d 7h 2m 43s
1200:	learn: 0.0839032	test: 0.0837529	best: 0.0837529 (1200)	total: 9.7s	remaining: 9d 8h 20m
1500:	learn: 0.0799449	test: 0.0808512	best: 0.0808512 (1500)	total: 12.2s	remaining: 9d 9h 28m 29s
1800:	learn: 0.0769596	test: 0.0787205	best: 0.0787205 (1800)	total: 14.6s	remaining: 9d 8h 36m 28s
2100:	learn: 0.0745316	test: 0.0771482	best: 0.0771482 (2100)	total: 17.1s	remaining: 9d 10h 3m 9s
2400:	learn: 0.0725361	test: 0.0759035	best: 0.0759035 (2400)	total: 19.6s	remaining: 9d 10h 10m 35s
2700:	learn: 0.0708921	test: 0.0749278	best: 0.0749278 (2700)	total: 22.1s	remaining: 9d 10h 54m 49s
3000:	learn: 0.0694378	test: 0.0740462	best: 0.0740462 (3000)	total: 24.5s	remaining: 9d 11h 17s
3300:	learn: 0.0681862	test: 0.0733569	best: 0.0733569 (3300)	total: 26.9s	remaining: 9d 10h 3m 35s
3600:	learn: 0.0670404	test: 0.0727145	best: 0.0727145 (3600)	total: 29.2s	remaining: 9d 9h 33m 44s
3900:	learn: 0.0660575	test: 0.0721857	best: 0.0721857 (3900)	total: 31.7s	remaining: 9d 9h 54m 48s
4200:	learn: 0.0651449	test: 0.0717017	best: 0.0717017 (4200)	total: 34.2s	remaining: 9d 10h 26m 17s
4500:	learn: 0.0642765	test: 0.0712498	best: 0.0712498 (4500)	total: 36.7s	remaining: 9d 10h 18m 59s
4800:	learn: 0.0635148	test: 0.0708965	best: 0.0708953 (4798)	total: 39.2s	remaining: 9d 10h 46m 46s
5100:	learn: 0.0628189	test: 0.0705893	best: 0.0705893 (5100)	total: 41.6s	remaining: 9d 10h 29m 50s
5400:	learn: 0.0621586	test: 0.0702727	best: 0.0702727 (5400)	total: 44s	remaining: 9d 10h 5m 4s
5700:	learn: 0.0615398	test: 0.0699996	best: 0.0699996 (5700)	total: 46.4s	remaining: 9d 10h 4m 46s
6000:	learn: 0.0609690	test: 0.0697308	best: 0.0697308 (6000)	total: 48.9s	remaining: 9d 10h 11m 16s
6300:	learn: 0.0604237	test: 0.0695136	best: 0.0695130 (6296)	total: 51.3s	remaining: 9d 10h 27s
6600:	learn: 0.0599149	test: 0.0692922	best: 0.0692922 (6600)	total: 53.8s	remaining: 9d 10h 23m 50s
6900:	learn: 0.0594260	test: 0.0690914	best: 0.0690914 (6900)	total: 56.2s	remaining: 9d 10h 10m 4s
7200:	learn: 0.0589710	test: 0.0688794	best: 0.0688794 (7200)	total: 58.5s	remaining: 9d 9h 44m 27s
7500:	learn: 0.0585414	test: 0.0687035	best: 0.0687035 (7500)	total: 1m	remaining: 9d 9h 24m 5s
7800:	learn: 0.0581403	test: 0.0685370	best: 0.0685370 (7799)	total: 1m 3s	remaining: 9d 8h 59m 5s
8100:	learn: 0.0577341	test: 0.0683922	best: 0.0683922 (8100)	total: 1m 5s	remaining: 9d 8h 36m 54s
8400:	learn: 0.0573650	test: 0.0682385	best: 0.0682385 (8400)	total: 1m 7s	remaining: 9d 8h 10m 38s
8700:	learn: 0.0570213	test: 0.0681203	best: 0.0681200 (8699)	total: 1m 10s	remaining: 9d 8h 10m 33s
9000:	learn: 0.0566829	test: 0.0680078	best: 0.0680078 (9000)	total: 1m 12s	remaining: 9d 8h 13m 26s
9300:	learn: 0.0563478	test: 0.0679014	best: 0.0679011 (9298)	total: 1m 15s	remaining: 9d 8h 11m 39s
9600:	learn: 0.0560178	test: 0.0677856	best: 0.0677837 (9598)	total: 1m 17s	remaining: 9d 8h 20m 48s
9900:	learn: 0.0557167	test: 0.0676743	best: 0.0676736 (9897)	total: 1m 20s	remaining: 9d 8h 32m 33s
10200:	learn: 0.0554268	test: 0.0675660	best: 0.0675655 (10199)	total: 1m 22s	remaining: 9d 8h 16m 37s
10500:	learn: 0.0551414	test: 0.0674778	best: 0.0674771 (10495)	total: 1m 24s	remaining: 9d 8h 8m 15s
10800:	learn: 0.0548738	test: 0.0673796	best: 0.0673796 (10800)	total: 1m 27s	remaining: 9d 8h 8m 43s
11100:	learn: 0.0546045	test: 0.0672934	best: 0.0672926 (11098)	total: 1m 29s	remaining: 9d 8h 2m
11400:	learn: 0.0543749	test: 0.0672032	best: 0.0672028 (11399)	total: 1m 31s	remaining: 9d 7h 51m 56s
11700:	learn: 0.0541428	test: 0.0671328	best: 0.0671328 (11700)	total: 1m 34s	remaining: 9d 7h 46m 2s
12000:	learn: 0.0539090	test: 0.0670478	best: 0.0670478 (12000)	total: 1m 36s	remaining: 9d 7h 39m 27s
12300:	learn: 0.0536973	test: 0.0669916	best: 0.0669916 (12300)	total: 1m 39s	remaining: 9d 7h 33m 18s
12600:	learn: 0.0534748	test: 0.0669008	best: 0.0668996 (12596)	total: 1m 41s	remaining: 9d 7h 36m 23s
12900:	learn: 0.0532692	test: 0.0668310	best: 0.0668307 (12884)	total: 1m 43s	remaining: 9d 7h 29m 23s
13200:	learn: 0.0530699	test: 0.0667674	best: 0.0667669 (13198)	total: 1m 46s	remaining: 9d 7h 16m 8s
13500:	learn: 0.0528796	test: 0.0667031	best: 0.0667031 (13500)	total: 1m 48s	remaining: 9d 7h 14m 11s
13800:	learn: 0.0527135	test: 0.0666578	best: 0.0666577 (13799)	total: 1m 50s	remaining: 9d 7h 19m 9s
14100:	learn: 0.0525237	test: 0.0666078	best: 0.0666078 (14100)	total: 1m 53s	remaining: 9d 7h 20m 26s
14400:	learn: 0.0523419	test: 0.0665584	best: 0.0665581 (14398)	total: 1m 55s	remaining: 9d 7h 17m
14700:	learn: 0.0521491	test: 0.0664952	best: 0.0664952 (14700)	total: 1m 58s	remaining: 9d 7h 10m 53s
15000:	learn: 0.0519792	test: 0.0664417	best: 0.0664417 (15000)	total: 2m	remaining: 9d 7h 12m 35s
15300:	learn: 0.0518205	test: 0.0663880	best: 0.0663879 (15299)	total: 2m 2s	remaining: 9d 7h 7m 55s
15600:	learn: 0.0516629	test: 0.0663567	best: 0.0663554 (15580)	total: 2m 5s	remaining: 9d 7h 4m 4s
15900:	learn: 0.0515040	test: 0.0663155	best: 0.0663155 (15900)	total: 2m 7s	remaining: 9d 6h 52m 28s
16200:	learn: 0.0513721	test: 0.0662832	best: 0.0662832 (16200)	total: 2m 9s	remaining: 9d 6h 39m
16500:	learn: 0.0512146	test: 0.0662393	best: 0.0662393 (16500)	total: 2m 12s	remaining: 9d 6h 29m 37s
16800:	learn: 0.0510742	test: 0.0662207	best: 0.0662203 (16796)	total: 2m 14s	remaining: 9d 6h 18m 34s
17100:	learn: 0.0509354	test: 0.0661743	best: 0.0661742 (17099)	total: 2m 16s	remaining: 9d 6h 6m 32s
17400:	learn: 0.0507975	test: 0.0661395	best: 0.0661372 (17381)	total: 2m 19s	remaining: 9d 5h 59m 33s
17700:	learn: 0.0506510	test: 0.0661059	best: 0.0661059 (17700)	total: 2m 21s	remaining: 9d 5h 52m
18000:	learn: 0.0505127	test: 0.0660714	best: 0.0660714 (18000)	total: 2m 23s	remaining: 9d 5h 46m 3s
18300:	learn: 0.0503869	test: 0.0660436	best: 0.0660423 (18281)	total: 2m 26s	remaining: 9d 5h 50m 31s
18600:	learn: 0.0502494	test: 0.0660040	best: 0.0660038 (18598)	total: 2m 28s	remaining: 9d 5h 52m 4s
18900:	learn: 0.0501203	test: 0.0659723	best: 0.0659709 (18881)	total: 2m 30s	remaining: 9d 5h 45m 34s
19200:	learn: 0.0499925	test: 0.0659440	best: 0.0659440 (19200)	total: 2m 33s	remaining: 9d 5h 36m 58s
19500:	learn: 0.0498656	test: 0.0659129	best: 0.0659117 (19493)	total: 2m 35s	remaining: 9d 5h 30m 16s
19800:	learn: 0.0497435	test: 0.0658803	best: 0.0658800 (19770)	total: 2m 37s	remaining: 9d 5h 22m 27s
20100:	learn: 0.0496206	test: 0.0658379	best: 0.0658379 (20100)	total: 2m 40s	remaining: 9d 5h 15m 56s
20400:	learn: 0.0495020	test: 0.0658148	best: 0.0658147 (20391)	total: 2m 42s	remaining: 9d 5h 7m 45s
20700:	learn: 0.0493847	test: 0.0657863	best: 0.0657863 (20700)	total: 2m 44s	remaining: 9d 5h 1m 9s
21000:	learn: 0.0492733	test: 0.0657565	best: 0.0657565 (21000)	total: 2m 47s	remaining: 9d 4h 53m 58s
21300:	learn: 0.0491645	test: 0.0657319	best: 0.0657319 (21300)	total: 2m 49s	remaining: 9d 4h 51m 58s
21600:	learn: 0.0490504	test: 0.0657032	best: 0.0657032 (21600)	total: 2m 51s	remaining: 9d 4h 58m 40s
21900:	learn: 0.0489372	test: 0.0656724	best: 0.0656710 (21889)	total: 2m 54s	remaining: 9d 4h 57m 26s
22200:	learn: 0.0488308	test: 0.0656526	best: 0.0656521 (22192)	total: 2m 56s	remaining: 9d 4h 53m 39s
22500:	learn: 0.0487287	test: 0.0656202	best: 0.0656199 (22498)	total: 2m 59s	remaining: 9d 4h 56m 2s
22800:	learn: 0.0486272	test: 0.0655917	best: 0.0655917 (22800)	total: 3m 1s	remaining: 9d 4h 57m 7s
23100:	learn: 0.0485224	test: 0.0655537	best: 0.0655537 (23100)	total: 3m 3s	remaining: 9d 4h 54m 17s
23400:	learn: 0.0484216	test: 0.0655284	best: 0.0655282 (23399)	total: 3m 6s	remaining: 9d 4h 52m 58s
23700:	learn: 0.0483169	test: 0.0655021	best: 0.0655011 (23694)	total: 3m 8s	remaining: 9d 4h 55m 53s
24000:	learn: 0.0482171	test: 0.0654750	best: 0.0654750 (24000)	total: 3m 10s	remaining: 9d 4h 51m 13s
24300:	learn: 0.0481243	test: 0.0654579	best: 0.0654546 (24283)	total: 3m 13s	remaining: 9d 4h 47m 12s
24600:	learn: 0.0480253	test: 0.0654413	best: 0.0654403 (24590)	total: 3m 15s	remaining: 9d 4h 44m 2s
24900:	learn: 0.0479359	test: 0.0654193	best: 0.0654191 (24895)	total: 3m 17s	remaining: 9d 4h 40m 56s
25200:	learn: 0.0478499	test: 0.0654020	best: 0.0654019 (25199)	total: 3m 20s	remaining: 9d 4h 38m 7s
25500:	learn: 0.0477656	test: 0.0653770	best: 0.0653770 (25500)	total: 3m 22s	remaining: 9d 4h 37m 34s
25800:	learn: 0.0476907	test: 0.0653531	best: 0.0653530 (25793)	total: 3m 24s	remaining: 9d 4h 38m 21s
26100:	learn: 0.0476064	test: 0.0653366	best: 0.0653341 (26095)	total: 3m 27s	remaining: 9d 4h 42m 31s
26400:	learn: 0.0475260	test: 0.0653270	best: 0.0653248 (26386)	total: 3m 29s	remaining: 9d 4h 37m 53s
26700:	learn: 0.0474492	test: 0.0653057	best: 0.0653057 (26700)	total: 3m 32s	remaining: 9d 4h 41m 5s
27000:	learn: 0.0473723	test: 0.0652862	best: 0.0652861 (26999)	total: 3m 34s	remaining: 9d 4h 39m 5s
27300:	learn: 0.0473051	test: 0.0652652	best: 0.0652652 (27300)	total: 3m 36s	remaining: 9d 4h 33m 52s
27600:	learn: 0.0472195	test: 0.0652468	best: 0.0652463 (27598)	total: 3m 39s	remaining: 9d 4h 29m 52s
27900:	learn: 0.0471365	test: 0.0652355	best: 0.0652355 (27900)	total: 3m 41s	remaining: 9d 4h 29m 15s
28200:	learn: 0.0470639	test: 0.0652242	best: 0.0652241 (28199)	total: 3m 43s	remaining: 9d 4h 25m 19s
28500:	learn: 0.0469878	test: 0.0652122	best: 0.0652099 (28415)	total: 3m 46s	remaining: 9d 4h 21m 33s
28800:	learn: 0.0469112	test: 0.0651939	best: 0.0651932 (28736)	total: 3m 48s	remaining: 9d 4h 21m 36s
29100:	learn: 0.0468399	test: 0.0651756	best: 0.0651756 (29098)	total: 3m 50s	remaining: 9d 4h 19m 33s
29400:	learn: 0.0467735	test: 0.0651552	best: 0.0651552 (29400)	total: 3m 53s	remaining: 9d 4h 16m 1s
29700:	learn: 0.0466991	test: 0.0651319	best: 0.0651306 (29688)	total: 3m 55s	remaining: 9d 4h 14m 14s
30000:	learn: 0.0466232	test: 0.0651100	best: 0.0651097 (29996)	total: 3m 57s	remaining: 9d 4h 12m 24s
30300:	learn: 0.0465545	test: 0.0650915	best: 0.0650915 (30299)	total: 4m	remaining: 9d 4h 12m 36s
30600:	learn: 0.0464912	test: 0.0650774	best: 0.0650773 (30593)	total: 4m 2s	remaining: 9d 4h 13m 39s
30900:	learn: 0.0464243	test: 0.0650634	best: 0.0650634 (30900)	total: 4m 5s	remaining: 9d 4h 15m 13s
31200:	learn: 0.0463606	test: 0.0650477	best: 0.0650477 (31199)	total: 4m 7s	remaining: 9d 4h 11m 49s
31500:	learn: 0.0462960	test: 0.0650322	best: 0.0650308 (31435)	total: 4m 9s	remaining: 9d 4h 7m 57s
31800:	learn: 0.0462267	test: 0.0650214	best: 0.0650198 (31782)	total: 4m 12s	remaining: 9d 4h 5m 5s
32100:	learn: 0.0461582	test: 0.0650031	best: 0.0650027 (32092)	total: 4m 14s	remaining: 9d 4h 4m 30s
32400:	learn: 0.0460870	test: 0.0649886	best: 0.0649877 (32385)	total: 4m 16s	remaining: 9d 4h 9m 32s
32700:	learn: 0.0460221	test: 0.0649813	best: 0.0649804 (32603)	total: 4m 19s	remaining: 9d 4h 4m 56s
33000:	learn: 0.0459626	test: 0.0649677	best: 0.0649674 (32987)	total: 4m 21s	remaining: 9d 4h 3m 16s
33300:	learn: 0.0459017	test: 0.0649534	best: 0.0649533 (33299)	total: 4m 23s	remaining: 9d 4h 2m 31s
33600:	learn: 0.0458434	test: 0.0649396	best: 0.0649385 (33573)	total: 4m 26s	remaining: 9d 4h 4m 38s
33900:	learn: 0.0457843	test: 0.0649285	best: 0.0649281 (33894)	total: 4m 28s	remaining: 9d 4h 9m 37s
34200:	learn: 0.0457255	test: 0.0649099	best: 0.0649097 (34197)	total: 4m 31s	remaining: 9d 4h 11m 6s
34500:	learn: 0.0456664	test: 0.0648985	best: 0.0648983 (34498)	total: 4m 33s	remaining: 9d 4h 12m 45s
34800:	learn: 0.0456047	test: 0.0648838	best: 0.0648838 (34799)	total: 4m 36s	remaining: 9d 4h 23m 13s
35100:	learn: 0.0455515	test: 0.0648693	best: 0.0648693 (35100)	total: 4m 38s	remaining: 9d 4h 27m 25s
35400:	learn: 0.0454884	test: 0.0648633	best: 0.0648626 (35302)	total: 4m 41s	remaining: 9d 4h 25m 53s
35700:	learn: 0.0454344	test: 0.0648546	best: 0.0648546 (35699)	total: 4m 43s	remaining: 9d 4h 22m 13s
36000:	learn: 0.0453776	test: 0.0648450	best: 0.0648449 (35998)	total: 4m 45s	remaining: 9d 4h 20m 37s
36300:	learn: 0.0453146	test: 0.0648252	best: 0.0648252 (36300)	total: 4m 48s	remaining: 9d 4h 22m 25s
36600:	learn: 0.0452576	test: 0.0648093	best: 0.0648091 (36594)	total: 4m 50s	remaining: 9d 4h 22m 40s
36900:	learn: 0.0452006	test: 0.0648020	best: 0.0648008 (36897)	total: 4m 52s	remaining: 9d 4h 20m 55s
37200:	learn: 0.0451443	test: 0.0647897	best: 0.0647895 (37199)	total: 4m 55s	remaining: 9d 4h 17m 13s
37500:	learn: 0.0450847	test: 0.0647789	best: 0.0647785 (37494)	total: 4m 57s	remaining: 9d 4h 13m
37800:	learn: 0.0450274	test: 0.0647717	best: 0.0647716 (37799)	total: 4m 59s	remaining: 9d 4h 10m 53s
38100:	learn: 0.0449688	test: 0.0647618	best: 0.0647605 (38057)	total: 5m 2s	remaining: 9d 4h 6m 18s
38400:	learn: 0.0449098	test: 0.0647436	best: 0.0647419 (38379)	total: 5m 4s	remaining: 9d 4h 7m 33s
38700:	learn: 0.0448553	test: 0.0647254	best: 0.0647253 (38678)	total: 5m 6s	remaining: 9d 4h 12m 44s
39000:	learn: 0.0448059	test: 0.0647100	best: 0.0647097 (38995)	total: 5m 9s	remaining: 9d 4h 9m 13s
39300:	learn: 0.0447536	test: 0.0647026	best: 0.0647026 (39297)	total: 5m 11s	remaining: 9d 4h 5m 49s
39600:	learn: 0.0446994	test: 0.0646898	best: 0.0646897 (39599)	total: 5m 13s	remaining: 9d 4h 7m 11s
39900:	learn: 0.0446495	test: 0.0646856	best: 0.0646840 (39861)	total: 5m 16s	remaining: 9d 4h 5m 40s
40200:	learn: 0.0445962	test: 0.0646774	best: 0.0646762 (40153)	total: 5m 18s	remaining: 9d 4h 1m 57s
40500:	learn: 0.0445487	test: 0.0646706	best: 0.0646693 (40491)	total: 5m 20s	remaining: 9d 3h 57m 38s
40800:	learn: 0.0444987	test: 0.0646608	best: 0.0646596 (40760)	total: 5m 23s	remaining: 9d 3h 54m 27s
41100:	learn: 0.0444517	test: 0.0646457	best: 0.0646457 (41099)	total: 5m 25s	remaining: 9d 3h 51m 46s
41400:	learn: 0.0443986	test: 0.0646361	best: 0.0646358 (41398)	total: 5m 27s	remaining: 9d 3h 49m 40s
41700:	learn: 0.0443465	test: 0.0646303	best: 0.0646301 (41697)	total: 5m 30s	remaining: 9d 3h 51m 58s
42000:	learn: 0.0442923	test: 0.0646240	best: 0.0646223 (41864)	total: 5m 32s	remaining: 9d 3h 53m 15s
42300:	learn: 0.0442364	test: 0.0646121	best: 0.0646119 (42283)	total: 5m 35s	remaining: 9d 3h 55m 9s
42600:	learn: 0.0441897	test: 0.0646005	best: 0.0646005 (42600)	total: 5m 37s	remaining: 9d 3h 55m 18s
42900:	learn: 0.0441480	test: 0.0645915	best: 0.0645910 (42882)	total: 5m 40s	remaining: 9d 4h 3m 6s
43200:	learn: 0.0441026	test: 0.0645852	best: 0.0645851 (43196)	total: 5m 42s	remaining: 9d 4h 7m 38s
43500:	learn: 0.0440576	test: 0.0645819	best: 0.0645805 (43410)	total: 5m 44s	remaining: 9d 4h 7m 28s
43800:	learn: 0.0440124	test: 0.0645779	best: 0.0645772 (43597)	total: 5m 47s	remaining: 9d 4h 5m 55s
44100:	learn: 0.0439673	test: 0.0645727	best: 0.0645724 (44081)	total: 5m 49s	remaining: 9d 4h 1m 35s
44400:	learn: 0.0439234	test: 0.0645650	best: 0.0645644 (44383)	total: 5m 51s	remaining: 9d 3h 58m 24s
44700:	learn: 0.0438812	test: 0.0645529	best: 0.0645506 (44679)	total: 5m 54s	remaining: 9d 3h 55m 8s
45000:	learn: 0.0438269	test: 0.0645416	best: 0.0645408 (44986)	total: 5m 56s	remaining: 9d 3h 51m 36s
45300:	learn: 0.0437766	test: 0.0645291	best: 0.0645290 (45294)	total: 5m 58s	remaining: 9d 3h 54m 57s
45600:	learn: 0.0437326	test: 0.0645190	best: 0.0645185 (45593)	total: 6m 1s	remaining: 9d 3h 53m 33s
45900:	learn: 0.0436862	test: 0.0645155	best: 0.0645119 (45795)	total: 6m 3s	remaining: 9d 3h 52m 26s
46200:	learn: 0.0436416	test: 0.0645090	best: 0.0645090 (46200)	total: 6m 5s	remaining: 9d 3h 50m 35s
46500:	learn: 0.0435961	test: 0.0645044	best: 0.0645032 (46474)	total: 6m 8s	remaining: 9d 3h 51m 32s
46800:	learn: 0.0435520	test: 0.0644998	best: 0.0644984 (46732)	total: 6m 10s	remaining: 9d 3h 54m 45s
47100:	learn: 0.0435079	test: 0.0644952	best: 0.0644944 (47065)	total: 6m 13s	remaining: 9d 3h 56m 50s
47400:	learn: 0.0434612	test: 0.0644853	best: 0.0644853 (47398)	total: 6m 15s	remaining: 9d 3h 59m 14s
47700:	learn: 0.0434168	test: 0.0644729	best: 0.0644729 (47700)	total: 6m 17s	remaining: 9d 3h 59m 10s
48000:	learn: 0.0433709	test: 0.0644632	best: 0.0644630 (47996)	total: 6m 20s	remaining: 9d 3h 57m 47s
48300:	learn: 0.0433320	test: 0.0644603	best: 0.0644590 (48135)	total: 6m 22s	remaining: 9d 3h 58m 49s
48600:	learn: 0.0432954	test: 0.0644507	best: 0.0644495 (48562)	total: 6m 24s	remaining: 9d 3h 55m 54s
48900:	learn: 0.0432564	test: 0.0644406	best: 0.0644403 (48876)	total: 6m 27s	remaining: 9d 3h 53m 42s
49200:	learn: 0.0432189	test: 0.0644310	best: 0.0644310 (49200)	total: 6m 29s	remaining: 9d 3h 50m 28s
49500:	learn: 0.0431782	test: 0.0644223	best: 0.0644221 (49494)	total: 6m 31s	remaining: 9d 3h 49m 3s
49800:	learn: 0.0431380	test: 0.0644119	best: 0.0644115 (49794)	total: 6m 34s	remaining: 9d 3h 49m 7s
50100:	learn: 0.0430980	test: 0.0643999	best: 0.0643992 (50096)	total: 6m 36s	remaining: 9d 3h 49m 2s
50400:	learn: 0.0430617	test: 0.0643912	best: 0.0643911 (50394)	total: 6m 38s	remaining: 9d 3h 45m 33s
50700:	learn: 0.0430252	test: 0.0643821	best: 0.0643818 (50692)	total: 6m 41s	remaining: 9d 3h 43m 47s
51000:	learn: 0.0429870	test: 0.0643706	best: 0.0643697 (50963)	total: 6m 43s	remaining: 9d 3h 41m 30s
51300:	learn: 0.0429534	test: 0.0643649	best: 0.0643649 (51300)	total: 6m 46s	remaining: 9d 3h 46m 5s
51600:	learn: 0.0429136	test: 0.0643582	best: 0.0643579 (51585)	total: 6m 48s	remaining: 9d 3h 46m 5s
51900:	learn: 0.0428730	test: 0.0643529	best: 0.0643529 (51900)	total: 6m 50s	remaining: 9d 3h 42m 37s
52200:	learn: 0.0428331	test: 0.0643407	best: 0.0643407 (52200)	total: 6m 53s	remaining: 9d 3h 39m 54s
52500:	learn: 0.0427940	test: 0.0643337	best: 0.0643332 (52490)	total: 6m 55s	remaining: 9d 3h 36m 54s
52800:	learn: 0.0427610	test: 0.0643268	best: 0.0643267 (52793)	total: 6m 57s	remaining: 9d 3h 36m 14s
53100:	learn: 0.0427231	test: 0.0643188	best: 0.0643180 (53080)	total: 6m 59s	remaining: 9d 3h 32m 33s
53400:	learn: 0.0426856	test: 0.0643124	best: 0.0643122 (53397)	total: 7m 2s	remaining: 9d 3h 30m 2s
53700:	learn: 0.0426465	test: 0.0643035	best: 0.0643035 (53699)	total: 7m 4s	remaining: 9d 3h 26m 57s
54000:	learn: 0.0426062	test: 0.0642957	best: 0.0642952 (53981)	total: 7m 6s	remaining: 9d 3h 25m 22s
54300:	learn: 0.0425689	test: 0.0642845	best: 0.0642840 (54239)	total: 7m 9s	remaining: 9d 3h 22m 20s
54600:	learn: 0.0425303	test: 0.0642766	best: 0.0642766 (54594)	total: 7m 11s	remaining: 9d 3h 20m 58s
54900:	learn: 0.0424944	test: 0.0642735	best: 0.0642730 (54819)	total: 7m 13s	remaining: 9d 3h 27m 21s
55200:	learn: 0.0424556	test: 0.0642636	best: 0.0642636 (55200)	total: 7m 16s	remaining: 9d 3h 25m 44s
55500:	learn: 0.0424156	test: 0.0642566	best: 0.0642563 (55461)	total: 7m 18s	remaining: 9d 3h 27m 50s
55800:	learn: 0.0423793	test: 0.0642490	best: 0.0642486 (55764)	total: 7m 21s	remaining: 9d 3h 30m 3s
56100:	learn: 0.0423453	test: 0.0642408	best: 0.0642399 (56057)	total: 7m 23s	remaining: 9d 3h 30m 43s
56400:	learn: 0.0423106	test: 0.0642365	best: 0.0642364 (56371)	total: 7m 25s	remaining: 9d 3h 30m 20s
56700:	learn: 0.0422764	test: 0.0642316	best: 0.0642316 (56700)	total: 7m 28s	remaining: 9d 3h 29m 4s
57000:	learn: 0.0422365	test: 0.0642252	best: 0.0642248 (56996)	total: 7m 30s	remaining: 9d 3h 29m 35s
57300:	learn: 0.0422029	test: 0.0642220	best: 0.0642218 (57190)	total: 7m 33s	remaining: 9d 3h 31m 9s
57600:	learn: 0.0421759	test: 0.0642183	best: 0.0642182 (57589)	total: 7m 35s	remaining: 9d 3h 28m 33s
57900:	learn: 0.0421406	test: 0.0642128	best: 0.0642127 (57898)	total: 7m 37s	remaining: 9d 3h 27m 24s
58200:	learn: 0.0421072	test: 0.0642050	best: 0.0642050 (58200)	total: 7m 40s	remaining: 9d 3h 27m 32s
58500:	learn: 0.0420778	test: 0.0642016	best: 0.0642014 (58491)	total: 7m 42s	remaining: 9d 3h 25m 42s
58800:	learn: 0.0420464	test: 0.0642002	best: 0.0641986 (58728)	total: 7m 44s	remaining: 9d 3h 27m 4s
59100:	learn: 0.0420144	test: 0.0641916	best: 0.0641914 (59041)	total: 7m 47s	remaining: 9d 3h 27m 34s
59400:	learn: 0.0419829	test: 0.0641855	best: 0.0641853 (59397)	total: 7m 49s	remaining: 9d 3h 25m 57s
59700:	learn: 0.0419515	test: 0.0641791	best: 0.0641786 (59661)	total: 7m 52s	remaining: 9d 3h 30m 1s
60000:	learn: 0.0419226	test: 0.0641718	best: 0.0641718 (60000)	total: 7m 54s	remaining: 9d 3h 31m 30s
60300:	learn: 0.0418918	test: 0.0641647	best: 0.0641641 (60294)	total: 7m 56s	remaining: 9d 3h 33m 4s
60600:	learn: 0.0418604	test: 0.0641584	best: 0.0641575 (60597)	total: 7m 59s	remaining: 9d 3h 34m 54s
60900:	learn: 0.0418316	test: 0.0641506	best: 0.0641506 (60900)	total: 8m 1s	remaining: 9d 3h 33m 30s
61200:	learn: 0.0418033	test: 0.0641463	best: 0.0641461 (61187)	total: 8m 4s	remaining: 9d 3h 36m 42s
61500:	learn: 0.0417698	test: 0.0641455	best: 0.0641440 (61418)	total: 8m 6s	remaining: 9d 3h 38m 53s
61800:	learn: 0.0417387	test: 0.0641449	best: 0.0641439 (61605)	total: 8m 9s	remaining: 9d 3h 39m 19s
62100:	learn: 0.0417109	test: 0.0641388	best: 0.0641387 (62079)	total: 8m 11s	remaining: 9d 3h 40m 16s
62400:	learn: 0.0416798	test: 0.0641333	best: 0.0641333 (62400)	total: 8m 13s	remaining: 9d 3h 39m 41s
62700:	learn: 0.0416536	test: 0.0641302	best: 0.0641286 (62604)	total: 8m 16s	remaining: 9d 3h 39m 43s
63000:	learn: 0.0416253	test: 0.0641265	best: 0.0641265 (62984)	total: 8m 18s	remaining: 9d 3h 40m 8s
63300:	learn: 0.0415972	test: 0.0641198	best: 0.0641181 (63247)	total: 8m 20s	remaining: 9d 3h 39m 50s
63600:	learn: 0.0415638	test: 0.0641111	best: 0.0641111 (63599)	total: 8m 23s	remaining: 9d 3h 41m 34s
63900:	learn: 0.0415374	test: 0.0641102	best: 0.0641101 (63899)	total: 8m 25s	remaining: 9d 3h 39m 6s
64200:	learn: 0.0415129	test: 0.0641073	best: 0.0641061 (64152)	total: 8m 27s	remaining: 9d 3h 39m 10s
64500:	learn: 0.0414887	test: 0.0641081	best: 0.0641061 (64152)	total: 8m 30s	remaining: 9d 3h 40m 36s
64800:	learn: 0.0414657	test: 0.0641010	best: 0.0641007 (64779)	total: 8m 32s	remaining: 9d 3h 41m 59s
65100:	learn: 0.0414371	test: 0.0640974	best: 0.0640974 (65096)	total: 8m 35s	remaining: 9d 3h 45m 3s
65400:	learn: 0.0414122	test: 0.0640954	best: 0.0640938 (65390)	total: 8m 37s	remaining: 9d 3h 45m 10s
65700:	learn: 0.0413821	test: 0.0640916	best: 0.0640894 (65670)	total: 8m 40s	remaining: 9d 3h 45m 51s
66000:	learn: 0.0413549	test: 0.0640882	best: 0.0640881 (65999)	total: 8m 42s	remaining: 9d 3h 48m 39s
66300:	learn: 0.0413264	test: 0.0640893	best: 0.0640856 (66143)	total: 8m 45s	remaining: 9d 3h 52m 29s
66600:	learn: 0.0412928	test: 0.0640800	best: 0.0640798 (66565)	total: 8m 47s	remaining: 9d 3h 51m 51s
66900:	learn: 0.0412617	test: 0.0640832	best: 0.0640798 (66565)	total: 8m 49s	remaining: 9d 3h 50m 17s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.0640798116
bestIteration = 66565

Shrink model to first 66566 iterations.
fold n°6
0:	learn: 0.5701489	test: 0.5659344	best: 0.5659344 (0)	total: 9.96ms	remaining: 11d 12h 36m 52s
300:	learn: 0.1340606	test: 0.1344216	best: 0.1344216 (300)	total: 2.55s	remaining: 9d 19h 8m 52s
600:	learn: 0.0979904	test: 0.1014665	best: 0.1014665 (600)	total: 4.82s	remaining: 9d 6h 55m 43s
900:	learn: 0.0892408	test: 0.0933619	best: 0.0933619 (900)	total: 7.25s	remaining: 9d 7h 28m 43s
1200:	learn: 0.0839643	test: 0.0885207	best: 0.0885207 (1200)	total: 9.58s	remaining: 9d 5h 37m 22s
1500:	learn: 0.0798463	test: 0.0847738	best: 0.0847738 (1500)	total: 11.9s	remaining: 9d 5h 4m 50s
1800:	learn: 0.0768368	test: 0.0821891	best: 0.0821891 (1800)	total: 14.3s	remaining: 9d 4h 32m 42s
2100:	learn: 0.0744985	test: 0.0804090	best: 0.0804090 (2100)	total: 16.7s	remaining: 9d 4h 54m 11s
2400:	learn: 0.0725628	test: 0.0789847	best: 0.0789847 (2400)	total: 19.1s	remaining: 9d 5h 28m 12s
2700:	learn: 0.0709068	test: 0.0778322	best: 0.0778322 (2700)	total: 21.6s	remaining: 9d 5h 40m 22s
3000:	learn: 0.0694726	test: 0.0768739	best: 0.0768739 (3000)	total: 23.9s	remaining: 9d 5h 12m 44s
3300:	learn: 0.0682254	test: 0.0760643	best: 0.0760643 (3300)	total: 26.2s	remaining: 9d 4h 46m 32s
3600:	learn: 0.0670883	test: 0.0753928	best: 0.0753928 (3600)	total: 28.8s	remaining: 9d 5h 52m 11s
3900:	learn: 0.0660462	test: 0.0747390	best: 0.0747390 (3900)	total: 31.2s	remaining: 9d 5h 50m 11s
4200:	learn: 0.0651035	test: 0.0741939	best: 0.0741932 (4199)	total: 33.6s	remaining: 9d 6h 26m 53s
4500:	learn: 0.0642613	test: 0.0737643	best: 0.0737643 (4500)	total: 36.1s	remaining: 9d 6h 36m 16s
4800:	learn: 0.0635092	test: 0.0733792	best: 0.0733792 (4800)	total: 38.7s	remaining: 9d 7h 48m 17s
5100:	learn: 0.0627964	test: 0.0730492	best: 0.0730492 (5100)	total: 41.1s	remaining: 9d 7h 36m 33s
5400:	learn: 0.0621433	test: 0.0727591	best: 0.0727591 (5400)	total: 43.5s	remaining: 9d 7h 56m 45s
5700:	learn: 0.0615410	test: 0.0724974	best: 0.0724969 (5699)	total: 46s	remaining: 9d 7h 56m 18s
6000:	learn: 0.0609288	test: 0.0721829	best: 0.0721829 (6000)	total: 48.4s	remaining: 9d 8h 14m 55s
6300:	learn: 0.0603904	test: 0.0719291	best: 0.0719291 (6300)	total: 50.9s	remaining: 9d 8h 23m 24s
6600:	learn: 0.0598998	test: 0.0717094	best: 0.0717093 (6598)	total: 53.4s	remaining: 9d 8h 29m 20s
6900:	learn: 0.0594047	test: 0.0714888	best: 0.0714886 (6898)	total: 55.7s	remaining: 9d 8h 19m 58s
7200:	learn: 0.0589606	test: 0.0713012	best: 0.0713012 (7200)	total: 58.1s	remaining: 9d 8h 8m 23s
7500:	learn: 0.0585385	test: 0.0711323	best: 0.0711323 (7500)	total: 1m	remaining: 9d 7h 54m 31s
7800:	learn: 0.0581350	test: 0.0709879	best: 0.0709879 (7800)	total: 1m 2s	remaining: 9d 7h 49m 7s
8100:	learn: 0.0577419	test: 0.0708318	best: 0.0708318 (8100)	total: 1m 5s	remaining: 9d 7h 43m 53s
8400:	learn: 0.0573601	test: 0.0706782	best: 0.0706782 (8400)	total: 1m 7s	remaining: 9d 7h 50m 6s
8700:	learn: 0.0569840	test: 0.0705604	best: 0.0705604 (8700)	total: 1m 10s	remaining: 9d 7h 39m 24s
9000:	learn: 0.0566229	test: 0.0704080	best: 0.0704080 (9000)	total: 1m 12s	remaining: 9d 7h 36m 8s
9300:	learn: 0.0562892	test: 0.0702825	best: 0.0702825 (9300)	total: 1m 14s	remaining: 9d 7h 36m
9600:	learn: 0.0559725	test: 0.0701728	best: 0.0701728 (9600)	total: 1m 17s	remaining: 9d 7h 41m 24s
9900:	learn: 0.0556664	test: 0.0700557	best: 0.0700557 (9900)	total: 1m 19s	remaining: 9d 7h 37m 4s
10200:	learn: 0.0553601	test: 0.0699335	best: 0.0699335 (10200)	total: 1m 22s	remaining: 9d 7h 36m 1s
10500:	learn: 0.0550798	test: 0.0698370	best: 0.0698351 (10494)	total: 1m 24s	remaining: 9d 7h 26m 20s
10800:	learn: 0.0547972	test: 0.0697380	best: 0.0697370 (10797)	total: 1m 26s	remaining: 9d 7h 14m 38s
11100:	learn: 0.0545394	test: 0.0696595	best: 0.0696569 (11084)	total: 1m 29s	remaining: 9d 7h 15m 12s
11400:	learn: 0.0542913	test: 0.0695650	best: 0.0695650 (11400)	total: 1m 31s	remaining: 9d 7h 15m 46s
11700:	learn: 0.0540412	test: 0.0694840	best: 0.0694840 (11700)	total: 1m 34s	remaining: 9d 7h 8m 33s
12000:	learn: 0.0538007	test: 0.0694073	best: 0.0694073 (12000)	total: 1m 36s	remaining: 9d 7h 1m 5s
12300:	learn: 0.0535594	test: 0.0693344	best: 0.0693344 (12300)	total: 1m 38s	remaining: 9d 6h 56m 4s
12600:	learn: 0.0533470	test: 0.0692792	best: 0.0692792 (12600)	total: 1m 41s	remaining: 9d 6h 47m 58s
12900:	learn: 0.0531265	test: 0.0692060	best: 0.0692032 (12885)	total: 1m 43s	remaining: 9d 6h 47m 3s
13200:	learn: 0.0529268	test: 0.0691564	best: 0.0691564 (13200)	total: 1m 45s	remaining: 9d 6h 45m 20s
13500:	learn: 0.0527207	test: 0.0690820	best: 0.0690819 (13499)	total: 1m 48s	remaining: 9d 7h 5m 33s
13800:	learn: 0.0525190	test: 0.0690205	best: 0.0690205 (13800)	total: 1m 50s	remaining: 9d 6h 57m 9s
14100:	learn: 0.0523422	test: 0.0689743	best: 0.0689743 (14100)	total: 1m 53s	remaining: 9d 6h 46m 14s
14400:	learn: 0.0521650	test: 0.0689190	best: 0.0689190 (14400)	total: 1m 55s	remaining: 9d 6h 45m 49s
14700:	learn: 0.0519936	test: 0.0688777	best: 0.0688770 (14698)	total: 1m 57s	remaining: 9d 6h 36m 34s
15000:	learn: 0.0518130	test: 0.0688236	best: 0.0688230 (14999)	total: 2m	remaining: 9d 6h 28m 23s
15300:	learn: 0.0516398	test: 0.0687665	best: 0.0687665 (15300)	total: 2m 2s	remaining: 9d 6h 19m 51s
15600:	learn: 0.0514791	test: 0.0687305	best: 0.0687305 (15600)	total: 2m 4s	remaining: 9d 6h 9m 58s
15900:	learn: 0.0513159	test: 0.0686880	best: 0.0686866 (15886)	total: 2m 7s	remaining: 9d 6h 2m 3s
16200:	learn: 0.0511559	test: 0.0686548	best: 0.0686548 (16200)	total: 2m 9s	remaining: 9d 5h 59m 23s
16500:	learn: 0.0510039	test: 0.0686184	best: 0.0686184 (16500)	total: 2m 11s	remaining: 9d 5h 56m 9s
16800:	learn: 0.0508544	test: 0.0685791	best: 0.0685788 (16794)	total: 2m 14s	remaining: 9d 5h 50m 38s
17100:	learn: 0.0507124	test: 0.0685423	best: 0.0685423 (17100)	total: 2m 16s	remaining: 9d 5h 53m 44s
17400:	learn: 0.0505688	test: 0.0685062	best: 0.0685061 (17399)	total: 2m 19s	remaining: 9d 5h 57m 35s
17700:	learn: 0.0504290	test: 0.0684737	best: 0.0684737 (17699)	total: 2m 21s	remaining: 9d 6h 1m 29s
18000:	learn: 0.0502803	test: 0.0684443	best: 0.0684432 (17993)	total: 2m 24s	remaining: 9d 6h 25m 55s
18300:	learn: 0.0501481	test: 0.0684061	best: 0.0684061 (18300)	total: 2m 26s	remaining: 9d 6h 37m 52s
18600:	learn: 0.0500108	test: 0.0683714	best: 0.0683713 (18594)	total: 2m 29s	remaining: 9d 6h 46m 41s
18900:	learn: 0.0498832	test: 0.0683396	best: 0.0683396 (18900)	total: 2m 31s	remaining: 9d 6h 43m 37s
19200:	learn: 0.0497604	test: 0.0683143	best: 0.0683143 (19200)	total: 2m 33s	remaining: 9d 6h 36m 30s
19500:	learn: 0.0496316	test: 0.0682918	best: 0.0682918 (19500)	total: 2m 36s	remaining: 9d 6h 41m 1s
19800:	learn: 0.0495133	test: 0.0682678	best: 0.0682678 (19800)	total: 2m 38s	remaining: 9d 6h 30m 36s
20100:	learn: 0.0493882	test: 0.0682356	best: 0.0682356 (20100)	total: 2m 41s	remaining: 9d 6h 29m 12s
20400:	learn: 0.0492796	test: 0.0682184	best: 0.0682176 (20397)	total: 2m 43s	remaining: 9d 6h 23m 25s
20700:	learn: 0.0491625	test: 0.0681963	best: 0.0681944 (20692)	total: 2m 45s	remaining: 9d 6h 28m 36s
21000:	learn: 0.0490450	test: 0.0681692	best: 0.0681689 (20990)	total: 2m 48s	remaining: 9d 6h 35m 5s
21300:	learn: 0.0489352	test: 0.0681504	best: 0.0681503 (21299)	total: 2m 50s	remaining: 9d 6h 37m 20s
21600:	learn: 0.0488248	test: 0.0681180	best: 0.0681170 (21597)	total: 2m 53s	remaining: 9d 6h 40m 25s
21900:	learn: 0.0487110	test: 0.0681000	best: 0.0680998 (21898)	total: 2m 55s	remaining: 9d 6h 45m 37s
22200:	learn: 0.0486076	test: 0.0680860	best: 0.0680854 (22183)	total: 2m 58s	remaining: 9d 7h 55s
22500:	learn: 0.0485061	test: 0.0680636	best: 0.0680618 (22489)	total: 3m	remaining: 9d 6h 55m 17s
22800:	learn: 0.0484029	test: 0.0680406	best: 0.0680404 (22797)	total: 3m 3s	remaining: 9d 6h 55m 54s
23100:	learn: 0.0482969	test: 0.0680075	best: 0.0680072 (23098)	total: 3m 5s	remaining: 9d 6h 55m 41s
23400:	learn: 0.0482040	test: 0.0679889	best: 0.0679886 (23399)	total: 3m 7s	remaining: 9d 6h 51m 38s
23700:	learn: 0.0481026	test: 0.0679638	best: 0.0679626 (23683)	total: 3m 10s	remaining: 9d 6h 51m 34s
24000:	learn: 0.0480107	test: 0.0679388	best: 0.0679388 (24000)	total: 3m 12s	remaining: 9d 6h 57m 42s
24300:	learn: 0.0479075	test: 0.0679077	best: 0.0679069 (24282)	total: 3m 15s	remaining: 9d 6h 57m 35s
24600:	learn: 0.0478089	test: 0.0678826	best: 0.0678812 (24585)	total: 3m 17s	remaining: 9d 6h 56m 33s
24900:	learn: 0.0477221	test: 0.0678570	best: 0.0678564 (24888)	total: 3m 19s	remaining: 9d 6h 51m 32s
25200:	learn: 0.0476368	test: 0.0678393	best: 0.0678390 (25182)	total: 3m 22s	remaining: 9d 6h 53m 23s
25500:	learn: 0.0475441	test: 0.0678185	best: 0.0678185 (25489)	total: 3m 24s	remaining: 9d 7h 3m 50s
25800:	learn: 0.0474532	test: 0.0677958	best: 0.0677958 (25800)	total: 3m 27s	remaining: 9d 7h 4m 34s
26100:	learn: 0.0473631	test: 0.0677797	best: 0.0677797 (26100)	total: 3m 29s	remaining: 9d 7h 4m 59s
26400:	learn: 0.0472854	test: 0.0677643	best: 0.0677643 (26400)	total: 3m 32s	remaining: 9d 7h 4m 35s
26700:	learn: 0.0471959	test: 0.0677455	best: 0.0677454 (26695)	total: 3m 34s	remaining: 9d 6h 57m 24s
27000:	learn: 0.0471176	test: 0.0677269	best: 0.0677266 (26997)	total: 3m 36s	remaining: 9d 6h 52m 15s
27300:	learn: 0.0470345	test: 0.0677060	best: 0.0677060 (27300)	total: 3m 39s	remaining: 9d 6h 46m 49s
27600:	learn: 0.0469606	test: 0.0676947	best: 0.0676945 (27594)	total: 3m 41s	remaining: 9d 6h 41m 23s
27900:	learn: 0.0468815	test: 0.0676792	best: 0.0676784 (27897)	total: 3m 43s	remaining: 9d 6h 38m 28s
28200:	learn: 0.0468049	test: 0.0676650	best: 0.0676648 (28192)	total: 3m 46s	remaining: 9d 6h 45m 16s
28500:	learn: 0.0467320	test: 0.0676525	best: 0.0676523 (28498)	total: 3m 48s	remaining: 9d 6h 40m 21s
28800:	learn: 0.0466639	test: 0.0676448	best: 0.0676448 (28800)	total: 3m 50s	remaining: 9d 6h 33m 55s
29100:	learn: 0.0465888	test: 0.0676250	best: 0.0676250 (29100)	total: 3m 53s	remaining: 9d 6h 30m 54s
29400:	learn: 0.0465134	test: 0.0676151	best: 0.0676150 (29393)	total: 3m 55s	remaining: 9d 6h 25m 32s
29700:	learn: 0.0464422	test: 0.0675913	best: 0.0675904 (29689)	total: 3m 57s	remaining: 9d 6h 20m 40s
30000:	learn: 0.0463746	test: 0.0675785	best: 0.0675785 (30000)	total: 4m	remaining: 9d 6h 18m 33s
30300:	learn: 0.0463032	test: 0.0675633	best: 0.0675632 (30299)	total: 4m 2s	remaining: 9d 6h 16m 1s
30600:	learn: 0.0462284	test: 0.0675517	best: 0.0675506 (30572)	total: 4m 4s	remaining: 9d 6h 12m 8s
30900:	learn: 0.0461690	test: 0.0675439	best: 0.0675439 (30900)	total: 4m 7s	remaining: 9d 6h 12m 53s
31200:	learn: 0.0461064	test: 0.0675289	best: 0.0675286 (31194)	total: 4m 9s	remaining: 9d 6h 5m 38s
31500:	learn: 0.0460429	test: 0.0675103	best: 0.0675097 (31497)	total: 4m 11s	remaining: 9d 5h 58m 15s
31800:	learn: 0.0459794	test: 0.0674914	best: 0.0674909 (31792)	total: 4m 14s	remaining: 9d 5h 52m 41s
32100:	learn: 0.0459059	test: 0.0674830	best: 0.0674828 (32094)	total: 4m 16s	remaining: 9d 5h 52m 52s
32400:	learn: 0.0458427	test: 0.0674705	best: 0.0674704 (32399)	total: 4m 18s	remaining: 9d 5h 47m 51s
32700:	learn: 0.0457844	test: 0.0674627	best: 0.0674611 (32684)	total: 4m 21s	remaining: 9d 5h 43m 18s
33000:	learn: 0.0457187	test: 0.0674528	best: 0.0674528 (32997)	total: 4m 23s	remaining: 9d 5h 40m 17s
33300:	learn: 0.0456485	test: 0.0674423	best: 0.0674410 (33289)	total: 4m 25s	remaining: 9d 5h 36m 39s
33600:	learn: 0.0455841	test: 0.0674281	best: 0.0674271 (33594)	total: 4m 28s	remaining: 9d 5h 34m 47s
33900:	learn: 0.0455257	test: 0.0674231	best: 0.0674231 (33900)	total: 4m 30s	remaining: 9d 5h 32m 14s
34200:	learn: 0.0454680	test: 0.0674149	best: 0.0674149 (34200)	total: 4m 32s	remaining: 9d 5h 29m 2s
34500:	learn: 0.0454067	test: 0.0674131	best: 0.0674124 (34224)	total: 4m 35s	remaining: 9d 5h 24m 44s
34800:	learn: 0.0453469	test: 0.0673971	best: 0.0673971 (34781)	total: 4m 37s	remaining: 9d 5h 20m 4s
35100:	learn: 0.0452896	test: 0.0673921	best: 0.0673869 (35059)	total: 4m 39s	remaining: 9d 5h 17m 17s
35400:	learn: 0.0452343	test: 0.0673838	best: 0.0673828 (35375)	total: 4m 42s	remaining: 9d 5h 18m 1s
35700:	learn: 0.0451730	test: 0.0673711	best: 0.0673708 (35683)	total: 4m 44s	remaining: 9d 5h 17m 16s
36000:	learn: 0.0451174	test: 0.0673649	best: 0.0673635 (35906)	total: 4m 46s	remaining: 9d 5h 15m 4s
36300:	learn: 0.0450633	test: 0.0673558	best: 0.0673558 (36300)	total: 4m 49s	remaining: 9d 5h 12m 36s
36600:	learn: 0.0450038	test: 0.0673447	best: 0.0673445 (36596)	total: 4m 51s	remaining: 9d 5h 8m 42s
36900:	learn: 0.0449435	test: 0.0673284	best: 0.0673281 (36887)	total: 4m 53s	remaining: 9d 5h 5m 18s
37200:	learn: 0.0448824	test: 0.0673171	best: 0.0673165 (37186)	total: 4m 56s	remaining: 9d 5h 4m 51s
37500:	learn: 0.0448230	test: 0.0673004	best: 0.0673001 (37482)	total: 4m 58s	remaining: 9d 5h 1m 5s
37800:	learn: 0.0447676	test: 0.0672934	best: 0.0672922 (37785)	total: 5m	remaining: 9d 4h 58m 4s
38100:	learn: 0.0447086	test: 0.0672862	best: 0.0672854 (38081)	total: 5m 3s	remaining: 9d 4h 56m 28s
38400:	learn: 0.0446517	test: 0.0672764	best: 0.0672757 (38390)	total: 5m 5s	remaining: 9d 4h 54m 25s
38700:	learn: 0.0445972	test: 0.0672648	best: 0.0672647 (38699)	total: 5m 7s	remaining: 9d 4h 51m 28s
39000:	learn: 0.0445391	test: 0.0672544	best: 0.0672543 (38989)	total: 5m 10s	remaining: 9d 4h 49m 39s
39300:	learn: 0.0444904	test: 0.0672533	best: 0.0672498 (39242)	total: 5m 12s	remaining: 9d 4h 52m 22s
39600:	learn: 0.0444418	test: 0.0672503	best: 0.0672488 (39574)	total: 5m 15s	remaining: 9d 4h 54m 34s
39900:	learn: 0.0443927	test: 0.0672430	best: 0.0672413 (39846)	total: 5m 17s	remaining: 9d 4h 53m 13s
40200:	learn: 0.0443430	test: 0.0672351	best: 0.0672351 (40200)	total: 5m 19s	remaining: 9d 4h 49m 31s
40500:	learn: 0.0442961	test: 0.0672312	best: 0.0672299 (40475)	total: 5m 22s	remaining: 9d 4h 48m 20s
40800:	learn: 0.0442512	test: 0.0672292	best: 0.0672270 (40685)	total: 5m 24s	remaining: 9d 4h 46m 8s
41100:	learn: 0.0442057	test: 0.0672266	best: 0.0672246 (41086)	total: 5m 26s	remaining: 9d 4h 42m 37s
41400:	learn: 0.0441584	test: 0.0672176	best: 0.0672166 (41379)	total: 5m 29s	remaining: 9d 4h 44m 46s
41700:	learn: 0.0441062	test: 0.0672156	best: 0.0672154 (41697)	total: 5m 31s	remaining: 9d 4h 44m 25s
42000:	learn: 0.0440579	test: 0.0672150	best: 0.0672137 (41836)	total: 5m 34s	remaining: 9d 4h 49m 18s
42300:	learn: 0.0440083	test: 0.0672125	best: 0.0672125 (42300)	total: 5m 36s	remaining: 9d 4h 50m 32s
42600:	learn: 0.0439584	test: 0.0672034	best: 0.0672034 (42599)	total: 5m 38s	remaining: 9d 4h 53m 55s
42900:	learn: 0.0439055	test: 0.0671904	best: 0.0671903 (42899)	total: 5m 41s	remaining: 9d 4h 57m 22s
43200:	learn: 0.0438608	test: 0.0671853	best: 0.0671851 (43195)	total: 5m 43s	remaining: 9d 5h 2m 37s
43500:	learn: 0.0438106	test: 0.0671776	best: 0.0671761 (43462)	total: 5m 46s	remaining: 9d 5h 1m 3s
43800:	learn: 0.0437606	test: 0.0671651	best: 0.0671646 (43772)	total: 5m 48s	remaining: 9d 4h 59m 11s
44100:	learn: 0.0437158	test: 0.0671600	best: 0.0671597 (43952)	total: 5m 50s	remaining: 9d 4h 56m 43s
44400:	learn: 0.0436710	test: 0.0671527	best: 0.0671522 (44354)	total: 5m 53s	remaining: 9d 4h 59m 15s
44700:	learn: 0.0436208	test: 0.0671486	best: 0.0671486 (44699)	total: 5m 55s	remaining: 9d 5h 31s
45000:	learn: 0.0435768	test: 0.0671452	best: 0.0671404 (44902)	total: 5m 58s	remaining: 9d 5h 10s
45300:	learn: 0.0435328	test: 0.0671398	best: 0.0671391 (45216)	total: 6m	remaining: 9d 4h 57m 8s
45600:	learn: 0.0434934	test: 0.0671357	best: 0.0671356 (45498)	total: 6m 2s	remaining: 9d 4h 53m 23s
45900:	learn: 0.0434471	test: 0.0671248	best: 0.0671248 (45895)	total: 6m 5s	remaining: 9d 4h 50m 1s
46200:	learn: 0.0434026	test: 0.0671145	best: 0.0671145 (46200)	total: 6m 7s	remaining: 9d 4h 55m 57s
46500:	learn: 0.0433597	test: 0.0671054	best: 0.0671050 (46499)	total: 6m 10s	remaining: 9d 4h 57m 56s
46800:	learn: 0.0433172	test: 0.0671041	best: 0.0671039 (46771)	total: 6m 12s	remaining: 9d 4h 56m 24s
47100:	learn: 0.0432762	test: 0.0671030	best: 0.0671023 (46887)	total: 6m 14s	remaining: 9d 4h 57m 8s
47400:	learn: 0.0432375	test: 0.0670921	best: 0.0670919 (47392)	total: 6m 17s	remaining: 9d 4h 57m 33s
47700:	learn: 0.0431921	test: 0.0670823	best: 0.0670822 (47697)	total: 6m 19s	remaining: 9d 4h 56m 32s
48000:	learn: 0.0431505	test: 0.0670791	best: 0.0670789 (47985)	total: 6m 21s	remaining: 9d 4h 54m 38s
48300:	learn: 0.0431083	test: 0.0670745	best: 0.0670745 (48299)	total: 6m 24s	remaining: 9d 4h 53m 7s
48600:	learn: 0.0430687	test: 0.0670670	best: 0.0670669 (48583)	total: 6m 26s	remaining: 9d 4h 54m 31s
48900:	learn: 0.0430316	test: 0.0670576	best: 0.0670545 (48868)	total: 6m 29s	remaining: 9d 4h 55m 31s
49200:	learn: 0.0429912	test: 0.0670445	best: 0.0670445 (49200)	total: 6m 31s	remaining: 9d 4h 56m 16s
49500:	learn: 0.0429521	test: 0.0670404	best: 0.0670400 (49375)	total: 6m 33s	remaining: 9d 4h 55m 23s
49800:	learn: 0.0429163	test: 0.0670316	best: 0.0670313 (49792)	total: 6m 36s	remaining: 9d 4h 54m 3s
50100:	learn: 0.0428781	test: 0.0670275	best: 0.0670271 (50095)	total: 6m 38s	remaining: 9d 4h 52m 6s
50400:	learn: 0.0428444	test: 0.0670212	best: 0.0670197 (50335)	total: 6m 40s	remaining: 9d 4h 52m 40s
50700:	learn: 0.0428089	test: 0.0670119	best: 0.0670112 (50681)	total: 6m 43s	remaining: 9d 4h 52m 31s
51000:	learn: 0.0427641	test: 0.0670033	best: 0.0670032 (50900)	total: 6m 45s	remaining: 9d 4h 54m 7s
51300:	learn: 0.0427184	test: 0.0669938	best: 0.0669936 (51298)	total: 6m 48s	remaining: 9d 4h 54m 39s
51600:	learn: 0.0426819	test: 0.0669876	best: 0.0669875 (51582)	total: 6m 50s	remaining: 9d 4h 54m 40s
51900:	learn: 0.0426432	test: 0.0669868	best: 0.0669848 (51820)	total: 6m 53s	remaining: 9d 5h 32s
52200:	learn: 0.0426030	test: 0.0669837	best: 0.0669826 (52186)	total: 6m 55s	remaining: 9d 4h 59m 32s
52500:	learn: 0.0425663	test: 0.0669780	best: 0.0669775 (52485)	total: 6m 57s	remaining: 9d 4h 59m 44s
52800:	learn: 0.0425287	test: 0.0669755	best: 0.0669744 (52736)	total: 7m	remaining: 9d 4h 58m 15s
53100:	learn: 0.0424912	test: 0.0669711	best: 0.0669711 (53100)	total: 7m 2s	remaining: 9d 4h 56m 49s
53400:	learn: 0.0424527	test: 0.0669673	best: 0.0669668 (53386)	total: 7m 4s	remaining: 9d 4h 57m 18s
53700:	learn: 0.0424145	test: 0.0669615	best: 0.0669607 (53673)	total: 7m 7s	remaining: 9d 4h 55m 57s
54000:	learn: 0.0423790	test: 0.0669605	best: 0.0669592 (53967)	total: 7m 9s	remaining: 9d 4h 55m 4s
54300:	learn: 0.0423427	test: 0.0669503	best: 0.0669503 (54300)	total: 7m 12s	remaining: 9d 4h 55m 16s
54600:	learn: 0.0423059	test: 0.0669476	best: 0.0669463 (54510)	total: 7m 14s	remaining: 9d 4h 55m 55s
54900:	learn: 0.0422691	test: 0.0669462	best: 0.0669436 (54810)	total: 7m 16s	remaining: 9d 4h 56m 29s
55200:	learn: 0.0422343	test: 0.0669401	best: 0.0669390 (55129)	total: 7m 19s	remaining: 9d 4h 57m 30s
55500:	learn: 0.0421946	test: 0.0669370	best: 0.0669351 (55445)	total: 7m 21s	remaining: 9d 4h 56m 19s
55800:	learn: 0.0421577	test: 0.0669370	best: 0.0669341 (55601)	total: 7m 24s	remaining: 9d 4h 57m 35s
56100:	learn: 0.0421241	test: 0.0669347	best: 0.0669330 (56014)	total: 7m 26s	remaining: 9d 4h 56m 34s
56400:	learn: 0.0420896	test: 0.0669239	best: 0.0669237 (56388)	total: 7m 28s	remaining: 9d 4h 57m 34s
56700:	learn: 0.0420529	test: 0.0669141	best: 0.0669139 (56699)	total: 7m 31s	remaining: 9d 4h 56m 7s
57000:	learn: 0.0420119	test: 0.0669139	best: 0.0669114 (56765)	total: 7m 33s	remaining: 9d 4h 55m 43s
57300:	learn: 0.0419762	test: 0.0669050	best: 0.0669045 (57298)	total: 7m 36s	remaining: 9d 4h 58m 18s
57600:	learn: 0.0419432	test: 0.0668998	best: 0.0668986 (57570)	total: 7m 38s	remaining: 9d 4h 56m 13s
57900:	learn: 0.0419083	test: 0.0668931	best: 0.0668914 (57862)	total: 7m 41s	remaining: 9d 5h 2m 5s
58200:	learn: 0.0418750	test: 0.0668965	best: 0.0668914 (57862)	total: 7m 43s	remaining: 9d 5h 4m 14s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.06689138676
bestIteration = 57862

Shrink model to first 57863 iterations.
fold n°7
0:	learn: 0.5698982	test: 0.5665882	best: 0.5665882 (0)	total: 9.69ms	remaining: 11d 5h 9m 43s
300:	learn: 0.1328021	test: 0.1401012	best: 0.1401012 (300)	total: 2.47s	remaining: 9d 12h 3m 18s
600:	learn: 0.0977909	test: 0.1021142	best: 0.1021142 (600)	total: 4.81s	remaining: 9d 6h 25m 50s
900:	learn: 0.0888775	test: 0.0935286	best: 0.0935286 (900)	total: 7.2s	remaining: 9d 6h 3m 47s
1200:	learn: 0.0835714	test: 0.0887312	best: 0.0887312 (1200)	total: 9.53s	remaining: 9d 4h 21m 32s
1500:	learn: 0.0796357	test: 0.0854708	best: 0.0854708 (1500)	total: 12s	remaining: 9d 5h 11m 19s
1800:	learn: 0.0767459	test: 0.0831124	best: 0.0831124 (1800)	total: 14.3s	remaining: 9d 5h 6m 59s
2100:	learn: 0.0743448	test: 0.0812901	best: 0.0812901 (2100)	total: 16.8s	remaining: 9d 6h 18m 43s
2400:	learn: 0.0723789	test: 0.0798617	best: 0.0798617 (2400)	total: 19.2s	remaining: 9d 6h 32m 24s
2700:	learn: 0.0707241	test: 0.0787244	best: 0.0787244 (2700)	total: 21.6s	remaining: 9d 6h 33m 18s
3000:	learn: 0.0692935	test: 0.0777444	best: 0.0777444 (3000)	total: 24s	remaining: 9d 5h 54m 11s
3300:	learn: 0.0680433	test: 0.0769591	best: 0.0769591 (3300)	total: 26.3s	remaining: 9d 5h 31m 36s
3600:	learn: 0.0669265	test: 0.0762872	best: 0.0762872 (3600)	total: 28.6s	remaining: 9d 4h 56m 22s
3900:	learn: 0.0659459	test: 0.0756698	best: 0.0756698 (3900)	total: 31s	remaining: 9d 5h 3m 23s
4200:	learn: 0.0650330	test: 0.0750995	best: 0.0750995 (4200)	total: 33.5s	remaining: 9d 5h 28m 59s
4500:	learn: 0.0641922	test: 0.0746156	best: 0.0746156 (4500)	total: 35.9s	remaining: 9d 5h 48m 45s
4800:	learn: 0.0634540	test: 0.0742288	best: 0.0742288 (4800)	total: 38.3s	remaining: 9d 5h 49m 13s
5100:	learn: 0.0627542	test: 0.0738427	best: 0.0738427 (5100)	total: 40.8s	remaining: 9d 6h 5m 57s
5400:	learn: 0.0621199	test: 0.0735253	best: 0.0735253 (5400)	total: 43.3s	remaining: 9d 6h 46m 52s
5700:	learn: 0.0615256	test: 0.0732110	best: 0.0732110 (5700)	total: 45.9s	remaining: 9d 7h 25m 30s
6000:	learn: 0.0609561	test: 0.0729463	best: 0.0729463 (6000)	total: 48.4s	remaining: 9d 7h 48m 2s
6300:	learn: 0.0604201	test: 0.0726911	best: 0.0726911 (6300)	total: 50.8s	remaining: 9d 7h 53m 41s
6600:	learn: 0.0599079	test: 0.0724504	best: 0.0724504 (6600)	total: 53.3s	remaining: 9d 8h 7m 10s
6900:	learn: 0.0594298	test: 0.0722695	best: 0.0722692 (6899)	total: 55.8s	remaining: 9d 8h 26m 1s
7200:	learn: 0.0589719	test: 0.0720777	best: 0.0720777 (7200)	total: 58.2s	remaining: 9d 8h 29m 59s
7500:	learn: 0.0585318	test: 0.0719160	best: 0.0719158 (7499)	total: 1m	remaining: 9d 8h 40m 6s
7800:	learn: 0.0581127	test: 0.0717335	best: 0.0717335 (7800)	total: 1m 3s	remaining: 9d 8h 49m 2s
8100:	learn: 0.0577308	test: 0.0715603	best: 0.0715598 (8099)	total: 1m 5s	remaining: 9d 9h 4m 24s
8400:	learn: 0.0573506	test: 0.0713988	best: 0.0713988 (8400)	total: 1m 8s	remaining: 9d 9h 4m 55s
8700:	learn: 0.0569923	test: 0.0712606	best: 0.0712606 (8700)	total: 1m 10s	remaining: 9d 8h 58m 42s
9000:	learn: 0.0566657	test: 0.0711403	best: 0.0711403 (9000)	total: 1m 12s	remaining: 9d 8h 47m 28s
9300:	learn: 0.0563342	test: 0.0709924	best: 0.0709924 (9300)	total: 1m 15s	remaining: 9d 8h 38m 34s
9600:	learn: 0.0560005	test: 0.0708494	best: 0.0708494 (9600)	total: 1m 17s	remaining: 9d 8h 32m 35s
9900:	learn: 0.0556953	test: 0.0707243	best: 0.0707243 (9900)	total: 1m 19s	remaining: 9d 8h 24m 7s
10200:	learn: 0.0553999	test: 0.0705952	best: 0.0705952 (10200)	total: 1m 22s	remaining: 9d 8h 10m
10500:	learn: 0.0551076	test: 0.0704918	best: 0.0704918 (10500)	total: 1m 24s	remaining: 9d 8h 5m
10800:	learn: 0.0548317	test: 0.0703906	best: 0.0703898 (10798)	total: 1m 27s	remaining: 9d 7h 54m 25s
11100:	learn: 0.0545669	test: 0.0702915	best: 0.0702915 (11100)	total: 1m 29s	remaining: 9d 7h 40m 28s
11400:	learn: 0.0543124	test: 0.0702115	best: 0.0702115 (11400)	total: 1m 31s	remaining: 9d 7h 26m 28s
11700:	learn: 0.0540682	test: 0.0701251	best: 0.0701251 (11700)	total: 1m 34s	remaining: 9d 7h 15m 3s
12000:	learn: 0.0538357	test: 0.0700397	best: 0.0700397 (11999)	total: 1m 36s	remaining: 9d 7h 18m 54s
12300:	learn: 0.0536010	test: 0.0699619	best: 0.0699619 (12300)	total: 1m 38s	remaining: 9d 7h 20m 44s
12600:	learn: 0.0533674	test: 0.0698884	best: 0.0698882 (12598)	total: 1m 41s	remaining: 9d 7h 13m 8s
12900:	learn: 0.0531435	test: 0.0698068	best: 0.0698063 (12898)	total: 1m 43s	remaining: 9d 7h 7m 58s
13200:	learn: 0.0529177	test: 0.0697298	best: 0.0697298 (13200)	total: 1m 46s	remaining: 9d 7h 17m 8s
13500:	learn: 0.0527252	test: 0.0696726	best: 0.0696721 (13496)	total: 1m 48s	remaining: 9d 7h 20m 53s
13800:	learn: 0.0525400	test: 0.0696189	best: 0.0696189 (13799)	total: 1m 51s	remaining: 9d 7h 29m 56s
14100:	learn: 0.0523481	test: 0.0695574	best: 0.0695562 (14094)	total: 1m 53s	remaining: 9d 7h 34m 36s
14400:	learn: 0.0521488	test: 0.0694917	best: 0.0694917 (14400)	total: 1m 55s	remaining: 9d 7h 39m 9s
14700:	learn: 0.0519764	test: 0.0694395	best: 0.0694395 (14700)	total: 1m 58s	remaining: 9d 7h 35m 6s
15000:	learn: 0.0518054	test: 0.0693818	best: 0.0693814 (14994)	total: 2m	remaining: 9d 7h 36m 27s
15300:	learn: 0.0516471	test: 0.0693373	best: 0.0693373 (15300)	total: 2m 3s	remaining: 9d 7h 44m 47s
15600:	learn: 0.0514830	test: 0.0692806	best: 0.0692805 (15599)	total: 2m 5s	remaining: 9d 7h 44m 17s
15900:	learn: 0.0513238	test: 0.0692260	best: 0.0692260 (15897)	total: 2m 8s	remaining: 9d 7h 40m 4s
16200:	learn: 0.0511793	test: 0.0691860	best: 0.0691859 (16189)	total: 2m 10s	remaining: 9d 7h 38m
16500:	learn: 0.0510225	test: 0.0691449	best: 0.0691449 (16500)	total: 2m 12s	remaining: 9d 7h 45m 3s
16800:	learn: 0.0508704	test: 0.0690978	best: 0.0690964 (16794)	total: 2m 15s	remaining: 9d 7h 44m 57s
17100:	learn: 0.0507360	test: 0.0690483	best: 0.0690482 (17097)	total: 2m 17s	remaining: 9d 7h 43m 9s
17400:	learn: 0.0505923	test: 0.0690074	best: 0.0690069 (17396)	total: 2m 20s	remaining: 9d 7h 48m 49s
17700:	learn: 0.0504494	test: 0.0689624	best: 0.0689622 (17698)	total: 2m 22s	remaining: 9d 7h 47m 33s
18000:	learn: 0.0503201	test: 0.0689131	best: 0.0689131 (18000)	total: 2m 25s	remaining: 9d 7h 44m 16s
18300:	learn: 0.0501916	test: 0.0688768	best: 0.0688761 (18297)	total: 2m 27s	remaining: 9d 7h 44m 3s
18600:	learn: 0.0500604	test: 0.0688458	best: 0.0688449 (18596)	total: 2m 29s	remaining: 9d 7h 39m 26s
18900:	learn: 0.0499309	test: 0.0688010	best: 0.0688010 (18900)	total: 2m 32s	remaining: 9d 7h 45m 41s
19200:	learn: 0.0498062	test: 0.0687531	best: 0.0687529 (19198)	total: 2m 34s	remaining: 9d 7h 46m 5s
19500:	learn: 0.0496869	test: 0.0687183	best: 0.0687183 (19500)	total: 2m 37s	remaining: 9d 7h 36m 5s
19800:	learn: 0.0495679	test: 0.0686861	best: 0.0686861 (19800)	total: 2m 39s	remaining: 9d 7h 40m 2s
20100:	learn: 0.0494474	test: 0.0686586	best: 0.0686586 (20100)	total: 2m 41s	remaining: 9d 7h 39m 43s
20400:	learn: 0.0493306	test: 0.0686342	best: 0.0686338 (20395)	total: 2m 44s	remaining: 9d 7h 32m 21s
20700:	learn: 0.0492233	test: 0.0686052	best: 0.0686052 (20700)	total: 2m 46s	remaining: 9d 7h 26m 30s
21000:	learn: 0.0491221	test: 0.0685704	best: 0.0685701 (20998)	total: 2m 48s	remaining: 9d 7h 20m 53s
21300:	learn: 0.0490139	test: 0.0685468	best: 0.0685467 (21299)	total: 2m 51s	remaining: 9d 7h 16m 20s
21600:	learn: 0.0489101	test: 0.0685298	best: 0.0685285 (21590)	total: 2m 53s	remaining: 9d 7h 15m 9s
21900:	learn: 0.0488105	test: 0.0685054	best: 0.0685037 (21887)	total: 2m 56s	remaining: 9d 7h 12m 29s
22200:	learn: 0.0487127	test: 0.0684807	best: 0.0684807 (22200)	total: 2m 58s	remaining: 9d 7h 13m 40s
22500:	learn: 0.0486293	test: 0.0684655	best: 0.0684632 (22469)	total: 3m	remaining: 9d 7h 4m 43s
22800:	learn: 0.0485316	test: 0.0684470	best: 0.0684467 (22798)	total: 3m 3s	remaining: 9d 6h 58m 7s
23100:	learn: 0.0484396	test: 0.0684221	best: 0.0684221 (23100)	total: 3m 5s	remaining: 9d 6h 49m 45s
23400:	learn: 0.0483394	test: 0.0684035	best: 0.0684035 (23400)	total: 3m 7s	remaining: 9d 6h 41m 25s
23700:	learn: 0.0482485	test: 0.0683894	best: 0.0683892 (23658)	total: 3m 9s	remaining: 9d 6h 33m 46s
24000:	learn: 0.0481598	test: 0.0683729	best: 0.0683729 (24000)	total: 3m 12s	remaining: 9d 6h 32m 5s
24300:	learn: 0.0480745	test: 0.0683649	best: 0.0683624 (24238)	total: 3m 14s	remaining: 9d 6h 27m 5s
24600:	learn: 0.0479915	test: 0.0683511	best: 0.0683510 (24582)	total: 3m 16s	remaining: 9d 6h 18m 26s
24900:	learn: 0.0479130	test: 0.0683413	best: 0.0683413 (24900)	total: 3m 19s	remaining: 9d 6h 10m 33s
25200:	learn: 0.0478261	test: 0.0683194	best: 0.0683190 (25199)	total: 3m 21s	remaining: 9d 6h 5m 32s
25500:	learn: 0.0477364	test: 0.0682945	best: 0.0682940 (25451)	total: 3m 23s	remaining: 9d 6h 7m 59s
25800:	learn: 0.0476475	test: 0.0682752	best: 0.0682752 (25800)	total: 3m 26s	remaining: 9d 6h 6m 49s
26100:	learn: 0.0475606	test: 0.0682546	best: 0.0682546 (26100)	total: 3m 28s	remaining: 9d 6h 1m 57s
26400:	learn: 0.0474799	test: 0.0682385	best: 0.0682383 (26399)	total: 3m 31s	remaining: 9d 5h 58m 53s
26700:	learn: 0.0473919	test: 0.0682164	best: 0.0682154 (26663)	total: 3m 33s	remaining: 9d 5h 58m 22s
27000:	learn: 0.0473091	test: 0.0682042	best: 0.0682041 (26999)	total: 3m 35s	remaining: 9d 5h 57m
27300:	learn: 0.0472194	test: 0.0681841	best: 0.0681839 (27299)	total: 3m 38s	remaining: 9d 5h 54m 7s
27600:	learn: 0.0471346	test: 0.0681659	best: 0.0681650 (27584)	total: 3m 40s	remaining: 9d 5h 54m 31s
27900:	learn: 0.0470582	test: 0.0681477	best: 0.0681471 (27898)	total: 3m 43s	remaining: 9d 6h
28200:	learn: 0.0469919	test: 0.0681350	best: 0.0681350 (28200)	total: 3m 45s	remaining: 9d 5h 58m 48s
28500:	learn: 0.0469175	test: 0.0681115	best: 0.0681115 (28500)	total: 3m 47s	remaining: 9d 5h 53m 31s
28800:	learn: 0.0468339	test: 0.0680947	best: 0.0680947 (28800)	total: 3m 50s	remaining: 9d 6h 1m 51s
29100:	learn: 0.0467589	test: 0.0680772	best: 0.0680756 (29071)	total: 3m 52s	remaining: 9d 6h 41s
29400:	learn: 0.0466872	test: 0.0680649	best: 0.0680644 (29393)	total: 3m 55s	remaining: 9d 5h 59m 39s
29700:	learn: 0.0466174	test: 0.0680528	best: 0.0680528 (29700)	total: 3m 57s	remaining: 9d 5h 58m 15s
30000:	learn: 0.0465434	test: 0.0680249	best: 0.0680249 (30000)	total: 3m 59s	remaining: 9d 5h 55m 12s
30300:	learn: 0.0464782	test: 0.0680161	best: 0.0680161 (30300)	total: 4m 2s	remaining: 9d 5h 51m 36s
30600:	learn: 0.0464094	test: 0.0680025	best: 0.0680021 (30590)	total: 4m 4s	remaining: 9d 5h 47m 46s
30900:	learn: 0.0463367	test: 0.0679859	best: 0.0679857 (30875)	total: 4m 6s	remaining: 9d 5h 49m 13s
31200:	learn: 0.0462732	test: 0.0679726	best: 0.0679723 (31193)	total: 4m 9s	remaining: 9d 5h 54m 11s
31500:	learn: 0.0462022	test: 0.0679529	best: 0.0679525 (31499)	total: 4m 11s	remaining: 9d 5h 55m 4s
31800:	learn: 0.0461353	test: 0.0679379	best: 0.0679379 (31800)	total: 4m 14s	remaining: 9d 5h 54m 59s
32100:	learn: 0.0460696	test: 0.0679238	best: 0.0679238 (32100)	total: 4m 16s	remaining: 9d 5h 54m 58s
32400:	learn: 0.0460054	test: 0.0679107	best: 0.0679107 (32400)	total: 4m 18s	remaining: 9d 5h 55m 50s
32700:	learn: 0.0459445	test: 0.0678990	best: 0.0678986 (32632)	total: 4m 21s	remaining: 9d 5h 53m
33000:	learn: 0.0458774	test: 0.0678852	best: 0.0678848 (32997)	total: 4m 23s	remaining: 9d 5h 49m 53s
33300:	learn: 0.0458171	test: 0.0678743	best: 0.0678737 (33291)	total: 4m 26s	remaining: 9d 5h 49m 12s
33600:	learn: 0.0457518	test: 0.0678639	best: 0.0678634 (33586)	total: 4m 28s	remaining: 9d 5h 48m 38s
33900:	learn: 0.0456925	test: 0.0678528	best: 0.0678520 (33878)	total: 4m 30s	remaining: 9d 5h 48m
34200:	learn: 0.0456309	test: 0.0678420	best: 0.0678420 (34200)	total: 4m 33s	remaining: 9d 5h 48m 25s
34500:	learn: 0.0455729	test: 0.0678278	best: 0.0678278 (34500)	total: 4m 35s	remaining: 9d 5h 49m 25s
34800:	learn: 0.0455247	test: 0.0678138	best: 0.0678136 (34799)	total: 4m 37s	remaining: 9d 5h 45m 15s
35100:	learn: 0.0454610	test: 0.0677995	best: 0.0677986 (35063)	total: 4m 40s	remaining: 9d 5h 44m 28s
35400:	learn: 0.0454063	test: 0.0677931	best: 0.0677930 (35395)	total: 4m 42s	remaining: 9d 5h 44m 23s
35700:	learn: 0.0453456	test: 0.0677742	best: 0.0677740 (35692)	total: 4m 45s	remaining: 9d 5h 45m 56s
36000:	learn: 0.0452867	test: 0.0677698	best: 0.0677694 (35971)	total: 4m 47s	remaining: 9d 5h 50m 57s
36300:	learn: 0.0452269	test: 0.0677520	best: 0.0677520 (36300)	total: 4m 50s	remaining: 9d 5h 54m 20s
36600:	learn: 0.0451701	test: 0.0677382	best: 0.0677382 (36599)	total: 4m 52s	remaining: 9d 5h 51m 37s
36900:	learn: 0.0451117	test: 0.0677266	best: 0.0677266 (36900)	total: 4m 54s	remaining: 9d 5h 49m 7s
37200:	learn: 0.0450568	test: 0.0677074	best: 0.0677071 (37196)	total: 4m 57s	remaining: 9d 5h 47m 8s
37500:	learn: 0.0450038	test: 0.0676861	best: 0.0676857 (37495)	total: 4m 59s	remaining: 9d 5h 44m 40s
37800:	learn: 0.0449531	test: 0.0676829	best: 0.0676825 (37640)	total: 5m 1s	remaining: 9d 5h 47m 18s
38100:	learn: 0.0448962	test: 0.0676722	best: 0.0676709 (38066)	total: 5m 4s	remaining: 9d 5h 44m 24s
38400:	learn: 0.0448438	test: 0.0676705	best: 0.0676700 (38394)	total: 5m 6s	remaining: 9d 5h 44m 40s
38700:	learn: 0.0447911	test: 0.0676601	best: 0.0676593 (38692)	total: 5m 9s	remaining: 9d 5h 47m 10s
39000:	learn: 0.0447409	test: 0.0676483	best: 0.0676474 (38993)	total: 5m 11s	remaining: 9d 5h 51m 45s
39300:	learn: 0.0446868	test: 0.0676402	best: 0.0676395 (39277)	total: 5m 14s	remaining: 9d 5h 55m 51s
39600:	learn: 0.0446251	test: 0.0676339	best: 0.0676338 (39598)	total: 5m 16s	remaining: 9d 5h 56m 43s
39900:	learn: 0.0445772	test: 0.0676202	best: 0.0676201 (39879)	total: 5m 18s	remaining: 9d 5h 53m 57s
40200:	learn: 0.0445273	test: 0.0676073	best: 0.0676066 (40167)	total: 5m 21s	remaining: 9d 5h 58m 38s
40500:	learn: 0.0444806	test: 0.0676014	best: 0.0676009 (40480)	total: 5m 23s	remaining: 9d 6h 1m 58s
40800:	learn: 0.0444299	test: 0.0675861	best: 0.0675861 (40800)	total: 5m 26s	remaining: 9d 6h 1m 8s
41100:	learn: 0.0443850	test: 0.0675742	best: 0.0675737 (41090)	total: 5m 28s	remaining: 9d 5h 56m 14s
41400:	learn: 0.0443384	test: 0.0675630	best: 0.0675623 (41378)	total: 5m 30s	remaining: 9d 5h 52m 35s
41700:	learn: 0.0442897	test: 0.0675537	best: 0.0675534 (41630)	total: 5m 33s	remaining: 9d 5h 50m 38s
42000:	learn: 0.0442410	test: 0.0675500	best: 0.0675493 (41996)	total: 5m 35s	remaining: 9d 5h 47m 20s
42300:	learn: 0.0441920	test: 0.0675410	best: 0.0675410 (42300)	total: 5m 37s	remaining: 9d 5h 45m 29s
42600:	learn: 0.0441476	test: 0.0675208	best: 0.0675208 (42600)	total: 5m 40s	remaining: 9d 5h 43m 9s
42900:	learn: 0.0441010	test: 0.0675180	best: 0.0675179 (42897)	total: 5m 42s	remaining: 9d 5h 43m 8s
43200:	learn: 0.0440529	test: 0.0675049	best: 0.0675044 (43171)	total: 5m 44s	remaining: 9d 5h 41m 35s
43500:	learn: 0.0440051	test: 0.0674956	best: 0.0674955 (43496)	total: 5m 47s	remaining: 9d 5h 45m 27s
43800:	learn: 0.0439617	test: 0.0674897	best: 0.0674891 (43751)	total: 5m 49s	remaining: 9d 5h 47m 45s
44100:	learn: 0.0439114	test: 0.0674822	best: 0.0674816 (43994)	total: 5m 52s	remaining: 9d 5h 51m 18s
44400:	learn: 0.0438639	test: 0.0674722	best: 0.0674722 (44400)	total: 5m 54s	remaining: 9d 5h 54m 26s
44700:	learn: 0.0438207	test: 0.0674667	best: 0.0674665 (44698)	total: 5m 57s	remaining: 9d 5h 52m 46s
45000:	learn: 0.0437771	test: 0.0674637	best: 0.0674621 (44912)	total: 5m 59s	remaining: 9d 5h 52m 8s
45300:	learn: 0.0437337	test: 0.0674565	best: 0.0674553 (45216)	total: 6m 2s	remaining: 9d 5h 54m 59s
45600:	learn: 0.0436908	test: 0.0674487	best: 0.0674487 (45600)	total: 6m 4s	remaining: 9d 5h 56m 25s
45900:	learn: 0.0436535	test: 0.0674426	best: 0.0674413 (45882)	total: 6m 6s	remaining: 9d 5h 58m 58s
46200:	learn: 0.0436083	test: 0.0674298	best: 0.0674292 (46194)	total: 6m 9s	remaining: 9d 6h 3m 35s
46500:	learn: 0.0435673	test: 0.0674227	best: 0.0674218 (46492)	total: 6m 11s	remaining: 9d 6h 16s
46800:	learn: 0.0435283	test: 0.0674161	best: 0.0674152 (46785)	total: 6m 14s	remaining: 9d 5h 57m 43s
47100:	learn: 0.0434875	test: 0.0674096	best: 0.0674091 (47087)	total: 6m 16s	remaining: 9d 5h 55m 27s
47400:	learn: 0.0434434	test: 0.0674022	best: 0.0674009 (47318)	total: 6m 18s	remaining: 9d 5h 52m 49s
47700:	learn: 0.0433998	test: 0.0673928	best: 0.0673927 (47698)	total: 6m 21s	remaining: 9d 5h 51m 35s
48000:	learn: 0.0433499	test: 0.0673855	best: 0.0673849 (47969)	total: 6m 23s	remaining: 9d 5h 53m 13s
48300:	learn: 0.0432978	test: 0.0673756	best: 0.0673756 (48300)	total: 6m 26s	remaining: 9d 5h 55m 33s
48600:	learn: 0.0432533	test: 0.0673708	best: 0.0673687 (48535)	total: 6m 28s	remaining: 9d 5h 56m 5s
48900:	learn: 0.0432104	test: 0.0673660	best: 0.0673660 (48875)	total: 6m 30s	remaining: 9d 5h 57m 51s
49200:	learn: 0.0431699	test: 0.0673581	best: 0.0673579 (49197)	total: 6m 33s	remaining: 9d 6h 2m 26s
49500:	learn: 0.0431302	test: 0.0673521	best: 0.0673511 (49461)	total: 6m 35s	remaining: 9d 5h 59m 59s
49800:	learn: 0.0430898	test: 0.0673432	best: 0.0673432 (49794)	total: 6m 38s	remaining: 9d 5h 59m 31s
50100:	learn: 0.0430470	test: 0.0673326	best: 0.0673323 (50097)	total: 6m 40s	remaining: 9d 6h 4m 41s
50400:	learn: 0.0430011	test: 0.0673251	best: 0.0673249 (50381)	total: 6m 43s	remaining: 9d 6h 4m
50700:	learn: 0.0429600	test: 0.0673148	best: 0.0673148 (50699)	total: 6m 45s	remaining: 9d 6h 1m 20s
51000:	learn: 0.0429221	test: 0.0673065	best: 0.0673065 (51000)	total: 6m 47s	remaining: 9d 6h 3m 37s
51300:	learn: 0.0428839	test: 0.0673012	best: 0.0673009 (51296)	total: 6m 50s	remaining: 9d 6h 4m 31s
51600:	learn: 0.0428456	test: 0.0672971	best: 0.0672955 (51568)	total: 6m 52s	remaining: 9d 6h 45s
51900:	learn: 0.0428100	test: 0.0672919	best: 0.0672912 (51882)	total: 6m 55s	remaining: 9d 6h 6m 42s
52200:	learn: 0.0427731	test: 0.0672881	best: 0.0672861 (52067)	total: 6m 57s	remaining: 9d 6h 13m 59s
52500:	learn: 0.0427351	test: 0.0672851	best: 0.0672810 (52342)	total: 7m	remaining: 9d 6h 17m 25s
52800:	learn: 0.0427012	test: 0.0672786	best: 0.0672772 (52730)	total: 7m 2s	remaining: 9d 6h 18m 37s
53100:	learn: 0.0426682	test: 0.0672758	best: 0.0672741 (52939)	total: 7m 5s	remaining: 9d 6h 18m 25s
53400:	learn: 0.0426297	test: 0.0672678	best: 0.0672653 (53338)	total: 7m 7s	remaining: 9d 6h 22m 5s
53700:	learn: 0.0425910	test: 0.0672611	best: 0.0672608 (53551)	total: 7m 10s	remaining: 9d 6h 24m 9s
54000:	learn: 0.0425580	test: 0.0672583	best: 0.0672582 (53993)	total: 7m 12s	remaining: 9d 6h 22m 9s
54300:	learn: 0.0425246	test: 0.0672486	best: 0.0672477 (54283)	total: 7m 15s	remaining: 9d 6h 31m 57s
54600:	learn: 0.0424900	test: 0.0672422	best: 0.0672418 (54597)	total: 7m 17s	remaining: 9d 6h 41m 40s
54900:	learn: 0.0424604	test: 0.0672367	best: 0.0672367 (54900)	total: 7m 20s	remaining: 9d 6h 44m 6s
55200:	learn: 0.0424270	test: 0.0672382	best: 0.0672332 (55077)	total: 7m 23s	remaining: 9d 6h 58m 52s
55500:	learn: 0.0423909	test: 0.0672292	best: 0.0672286 (55498)	total: 7m 26s	remaining: 9d 7h 8m 50s
55800:	learn: 0.0423551	test: 0.0672284	best: 0.0672277 (55515)	total: 7m 28s	remaining: 9d 7h 15m 48s
56100:	learn: 0.0423212	test: 0.0672203	best: 0.0672203 (56096)	total: 7m 31s	remaining: 9d 7h 19m 12s
56400:	learn: 0.0422832	test: 0.0672110	best: 0.0672105 (56378)	total: 7m 33s	remaining: 9d 7h 26m 3s
56700:	learn: 0.0422476	test: 0.0672076	best: 0.0672065 (56661)	total: 7m 36s	remaining: 9d 7h 22m 12s
57000:	learn: 0.0422144	test: 0.0671979	best: 0.0671972 (56938)	total: 7m 38s	remaining: 9d 7h 18m 56s
57300:	learn: 0.0421856	test: 0.0671916	best: 0.0671916 (57300)	total: 7m 40s	remaining: 9d 7h 14m 56s
57600:	learn: 0.0421556	test: 0.0671914	best: 0.0671887 (57563)	total: 7m 43s	remaining: 9d 7h 12m 32s
57900:	learn: 0.0421228	test: 0.0671831	best: 0.0671831 (57899)	total: 7m 45s	remaining: 9d 7h 14m 57s
58200:	learn: 0.0420888	test: 0.0671769	best: 0.0671768 (58145)	total: 7m 47s	remaining: 9d 7h 11m 8s
58500:	learn: 0.0420554	test: 0.0671725	best: 0.0671721 (58440)	total: 7m 50s	remaining: 9d 7h 7m 26s
58800:	learn: 0.0420183	test: 0.0671716	best: 0.0671707 (58782)	total: 7m 52s	remaining: 9d 7h 4m 28s
59100:	learn: 0.0419825	test: 0.0671717	best: 0.0671676 (58966)	total: 7m 54s	remaining: 9d 7h 34s
59400:	learn: 0.0419520	test: 0.0671678	best: 0.0671668 (59374)	total: 7m 57s	remaining: 9d 6h 56m 16s
59700:	learn: 0.0419148	test: 0.0671632	best: 0.0671632 (59695)	total: 7m 59s	remaining: 9d 6h 52m 24s
60000:	learn: 0.0418811	test: 0.0671554	best: 0.0671548 (59982)	total: 8m 1s	remaining: 9d 6h 48m 35s
60300:	learn: 0.0418501	test: 0.0671519	best: 0.0671519 (60292)	total: 8m 3s	remaining: 9d 6h 44m 58s
60600:	learn: 0.0418210	test: 0.0671524	best: 0.0671502 (60376)	total: 8m 6s	remaining: 9d 6h 41m 16s
60900:	learn: 0.0417909	test: 0.0671533	best: 0.0671502 (60376)	total: 8m 8s	remaining: 9d 6h 37m 31s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.06715024823
bestIteration = 60376

Shrink model to first 60377 iterations.
fold n°8
0:	learn: 0.5707843	test: 0.5600669	best: 0.5600669 (0)	total: 12.7ms	remaining: 14d 15h 38m 16s
300:	learn: 0.1341192	test: 0.1291990	best: 0.1291990 (300)	total: 2.51s	remaining: 9d 15h 51m 5s
600:	learn: 0.0981515	test: 0.0967717	best: 0.0967717 (600)	total: 4.83s	remaining: 9d 7h 4m 38s
900:	learn: 0.0893054	test: 0.0898507	best: 0.0898507 (900)	total: 7.4s	remaining: 9d 12h 3m 9s
1200:	learn: 0.0839485	test: 0.0857252	best: 0.0857252 (1200)	total: 9.93s	remaining: 9d 13h 35m 7s
1500:	learn: 0.0799206	test: 0.0826255	best: 0.0826255 (1500)	total: 13s	remaining: 9d 23h 52m 49s
1800:	learn: 0.0768426	test: 0.0802790	best: 0.0802790 (1800)	total: 15.7s	remaining: 10d 2h 31m 36s
2100:	learn: 0.0744974	test: 0.0785893	best: 0.0785893 (2100)	total: 18.7s	remaining: 10d 7h 3m 45s
2400:	learn: 0.0726083	test: 0.0773151	best: 0.0773147 (2398)	total: 21.5s	remaining: 10d 8h 39m 10s
2700:	learn: 0.0710023	test: 0.0762626	best: 0.0762626 (2700)	total: 24.4s	remaining: 10d 11h 11m 15s
3000:	learn: 0.0695806	test: 0.0753693	best: 0.0753693 (3000)	total: 27s	remaining: 10d 9h 27m 27s
3300:	learn: 0.0683006	test: 0.0745884	best: 0.0745884 (3300)	total: 29.4s	remaining: 10d 7h 26m 21s
3600:	learn: 0.0671841	test: 0.0739425	best: 0.0739425 (3600)	total: 31.9s	remaining: 10d 5h 51m 20s
3900:	learn: 0.0661785	test: 0.0733674	best: 0.0733674 (3900)	total: 34.2s	remaining: 10d 3h 48m 51s
4200:	learn: 0.0652579	test: 0.0729244	best: 0.0729235 (4199)	total: 36.6s	remaining: 10d 1h 57m 32s
4500:	learn: 0.0643958	test: 0.0724967	best: 0.0724961 (4499)	total: 38.9s	remaining: 10d 11m 53s
4800:	learn: 0.0636432	test: 0.0721147	best: 0.0721147 (4800)	total: 41.3s	remaining: 9d 23h 45s
5100:	learn: 0.0629179	test: 0.0717812	best: 0.0717812 (5100)	total: 43.6s	remaining: 9d 21h 40m 35s
5400:	learn: 0.0622619	test: 0.0714696	best: 0.0714696 (5400)	total: 46s	remaining: 9d 20h 49m 24s
5700:	learn: 0.0616579	test: 0.0712047	best: 0.0712044 (5699)	total: 48.4s	remaining: 9d 19h 45m 9s
6000:	learn: 0.0610867	test: 0.0709288	best: 0.0709284 (5999)	total: 50.8s	remaining: 9d 19h 12m 28s
6300:	learn: 0.0605589	test: 0.0707152	best: 0.0707131 (6296)	total: 53.2s	remaining: 9d 18h 19m 49s
6600:	learn: 0.0600532	test: 0.0704790	best: 0.0704790 (6600)	total: 55.6s	remaining: 9d 17h 53m 41s
6900:	learn: 0.0595861	test: 0.0702936	best: 0.0702936 (6900)	total: 58s	remaining: 9d 17h 18m 46s
7200:	learn: 0.0591255	test: 0.0700995	best: 0.0700995 (7200)	total: 1m	remaining: 9d 17h 1m 13s
7500:	learn: 0.0586850	test: 0.0699297	best: 0.0699297 (7500)	total: 1m 2s	remaining: 9d 16h 32m 7s
7800:	learn: 0.0582740	test: 0.0697548	best: 0.0697548 (7800)	total: 1m 5s	remaining: 9d 15h 53m 28s
8100:	learn: 0.0578895	test: 0.0696152	best: 0.0696149 (8099)	total: 1m 7s	remaining: 9d 15h 16m 24s
8400:	learn: 0.0575139	test: 0.0694851	best: 0.0694851 (8400)	total: 1m 9s	remaining: 9d 14h 42m 20s
8700:	learn: 0.0571445	test: 0.0693599	best: 0.0693586 (8699)	total: 1m 12s	remaining: 9d 14h 24m 24s
9000:	learn: 0.0568167	test: 0.0692304	best: 0.0692304 (9000)	total: 1m 14s	remaining: 9d 14h 5m 17s
9300:	learn: 0.0565002	test: 0.0691290	best: 0.0691290 (9297)	total: 1m 16s	remaining: 9d 13h 40m 26s
9600:	learn: 0.0561852	test: 0.0690095	best: 0.0690094 (9599)	total: 1m 19s	remaining: 9d 13h 22m 40s
9900:	learn: 0.0558923	test: 0.0689016	best: 0.0689016 (9900)	total: 1m 21s	remaining: 9d 12h 56m 13s
10200:	learn: 0.0556027	test: 0.0688011	best: 0.0688007 (10199)	total: 1m 23s	remaining: 9d 12h 36m 12s
10500:	learn: 0.0553322	test: 0.0687008	best: 0.0687008 (10500)	total: 1m 26s	remaining: 9d 12h 32m 55s
10800:	learn: 0.0550772	test: 0.0686183	best: 0.0686183 (10800)	total: 1m 28s	remaining: 9d 12h 13m 42s
11100:	learn: 0.0548279	test: 0.0685418	best: 0.0685418 (11100)	total: 1m 31s	remaining: 9d 12h 13m 34s
11400:	learn: 0.0545734	test: 0.0684538	best: 0.0684538 (11400)	total: 1m 33s	remaining: 9d 12h 6m 56s
11700:	learn: 0.0543321	test: 0.0683780	best: 0.0683778 (11699)	total: 1m 35s	remaining: 9d 11h 49m 33s
12000:	learn: 0.0541139	test: 0.0683253	best: 0.0683253 (12000)	total: 1m 38s	remaining: 9d 11h 25m 50s
12300:	learn: 0.0538845	test: 0.0682452	best: 0.0682452 (12300)	total: 1m 40s	remaining: 9d 11h 6m 7s
12600:	learn: 0.0536639	test: 0.0681655	best: 0.0681655 (12599)	total: 1m 42s	remaining: 9d 10h 45m 36s
12900:	learn: 0.0534291	test: 0.0680736	best: 0.0680735 (12896)	total: 1m 45s	remaining: 9d 10h 44m 30s
13200:	learn: 0.0532274	test: 0.0680042	best: 0.0680040 (13197)	total: 1m 47s	remaining: 9d 10h 31m 13s
13500:	learn: 0.0530342	test: 0.0679531	best: 0.0679531 (13500)	total: 1m 50s	remaining: 9d 10h 30m 16s
13800:	learn: 0.0528365	test: 0.0678802	best: 0.0678798 (13795)	total: 1m 52s	remaining: 9d 10h 15m 8s
14100:	learn: 0.0526437	test: 0.0678224	best: 0.0678224 (14100)	total: 1m 54s	remaining: 9d 10h 1m 5s
14400:	learn: 0.0524607	test: 0.0677676	best: 0.0677672 (14397)	total: 1m 57s	remaining: 9d 9h 44m 55s
14700:	learn: 0.0522783	test: 0.0677073	best: 0.0677070 (14699)	total: 1m 59s	remaining: 9d 9h 28m 35s
15000:	learn: 0.0520987	test: 0.0676514	best: 0.0676509 (14998)	total: 2m 1s	remaining: 9d 9h 15m 38s
15300:	learn: 0.0519328	test: 0.0676016	best: 0.0676001 (15288)	total: 2m 3s	remaining: 9d 9h 4m 16s
15600:	learn: 0.0517603	test: 0.0675460	best: 0.0675459 (15597)	total: 2m 6s	remaining: 9d 8h 49m 50s
15900:	learn: 0.0516007	test: 0.0674993	best: 0.0674991 (15899)	total: 2m 8s	remaining: 9d 8h 55m 44s
16200:	learn: 0.0514411	test: 0.0674443	best: 0.0674443 (16200)	total: 2m 11s	remaining: 9d 8h 47m 57s
16500:	learn: 0.0512846	test: 0.0673977	best: 0.0673977 (16500)	total: 2m 13s	remaining: 9d 8h 40m 15s
16800:	learn: 0.0511367	test: 0.0673536	best: 0.0673522 (16787)	total: 2m 15s	remaining: 9d 8h 32m 22s
17100:	learn: 0.0509947	test: 0.0673107	best: 0.0673099 (17081)	total: 2m 18s	remaining: 9d 8h 22m 12s
17400:	learn: 0.0508523	test: 0.0672724	best: 0.0672718 (17395)	total: 2m 20s	remaining: 9d 8h 14m 2s
17700:	learn: 0.0507211	test: 0.0672225	best: 0.0672225 (17700)	total: 2m 22s	remaining: 9d 8h 2m 3s
18000:	learn: 0.0505883	test: 0.0671946	best: 0.0671946 (18000)	total: 2m 25s	remaining: 9d 7h 53m 37s
18300:	learn: 0.0504599	test: 0.0671587	best: 0.0671581 (18293)	total: 2m 27s	remaining: 9d 7h 47m 16s
18600:	learn: 0.0503290	test: 0.0671309	best: 0.0671291 (18581)	total: 2m 29s	remaining: 9d 7h 45m 43s
18900:	learn: 0.0502045	test: 0.0670972	best: 0.0670971 (18899)	total: 2m 32s	remaining: 9d 7h 49m 5s
19200:	learn: 0.0500875	test: 0.0670621	best: 0.0670621 (19200)	total: 2m 34s	remaining: 9d 8h 5m 15s
19500:	learn: 0.0499554	test: 0.0670234	best: 0.0670234 (19500)	total: 2m 37s	remaining: 9d 8h 50s
19800:	learn: 0.0498277	test: 0.0670004	best: 0.0669996 (19794)	total: 2m 39s	remaining: 9d 8h 2m 24s
20100:	learn: 0.0497084	test: 0.0669733	best: 0.0669730 (20099)	total: 2m 42s	remaining: 9d 8h 1m 4s
20400:	learn: 0.0495934	test: 0.0669386	best: 0.0669377 (20394)	total: 2m 44s	remaining: 9d 7h 54m 7s
20700:	learn: 0.0494755	test: 0.0669070	best: 0.0669070 (20700)	total: 2m 46s	remaining: 9d 8h 32s
21000:	learn: 0.0493662	test: 0.0668786	best: 0.0668786 (21000)	total: 2m 49s	remaining: 9d 8h 1m 32s
21300:	learn: 0.0492610	test: 0.0668586	best: 0.0668581 (21269)	total: 2m 51s	remaining: 9d 7h 55m 14s
21600:	learn: 0.0491576	test: 0.0668340	best: 0.0668339 (21595)	total: 2m 54s	remaining: 9d 7h 49m 6s
21900:	learn: 0.0490538	test: 0.0668193	best: 0.0668193 (21900)	total: 2m 56s	remaining: 9d 7h 36m 51s
22200:	learn: 0.0489486	test: 0.0667930	best: 0.0667930 (22199)	total: 2m 58s	remaining: 9d 7h 29m 39s
22500:	learn: 0.0488517	test: 0.0667634	best: 0.0667634 (22500)	total: 3m	remaining: 9d 7h 20m 9s
22800:	learn: 0.0487527	test: 0.0667396	best: 0.0667391 (22798)	total: 3m 3s	remaining: 9d 7h 11m 8s
23100:	learn: 0.0486438	test: 0.0667161	best: 0.0667161 (23100)	total: 3m 5s	remaining: 9d 7h 1m 5s
23400:	learn: 0.0485439	test: 0.0666903	best: 0.0666892 (23384)	total: 3m 7s	remaining: 9d 6h 57m 37s
23700:	learn: 0.0484472	test: 0.0666668	best: 0.0666643 (23694)	total: 3m 10s	remaining: 9d 6h 50m 9s
24000:	learn: 0.0483542	test: 0.0666404	best: 0.0666404 (23999)	total: 3m 12s	remaining: 9d 6h 43m 56s
24300:	learn: 0.0482642	test: 0.0666167	best: 0.0666167 (24300)	total: 3m 14s	remaining: 9d 6h 34m 16s
24600:	learn: 0.0481683	test: 0.0665930	best: 0.0665930 (24600)	total: 3m 17s	remaining: 9d 6h 31m 35s
24900:	learn: 0.0480778	test: 0.0665772	best: 0.0665767 (24893)	total: 3m 19s	remaining: 9d 6h 23m 56s
25200:	learn: 0.0479902	test: 0.0665492	best: 0.0665486 (25193)	total: 3m 21s	remaining: 9d 6h 16m 27s
25500:	learn: 0.0479043	test: 0.0665245	best: 0.0665234 (25496)	total: 3m 23s	remaining: 9d 6h 7m 41s
25800:	learn: 0.0478190	test: 0.0665065	best: 0.0665058 (25788)	total: 3m 26s	remaining: 9d 5h 58m 24s
26100:	learn: 0.0477375	test: 0.0664935	best: 0.0664922 (26005)	total: 3m 28s	remaining: 9d 5h 50m 43s
26400:	learn: 0.0476525	test: 0.0664635	best: 0.0664635 (26400)	total: 3m 30s	remaining: 9d 5h 56m 37s
26700:	learn: 0.0475770	test: 0.0664467	best: 0.0664463 (26675)	total: 3m 33s	remaining: 9d 5h 50m 1s
27000:	learn: 0.0475005	test: 0.0664255	best: 0.0664251 (26999)	total: 3m 35s	remaining: 9d 5h 41m
27300:	learn: 0.0474269	test: 0.0664073	best: 0.0664071 (27284)	total: 3m 37s	remaining: 9d 5h 34m 44s
27600:	learn: 0.0473498	test: 0.0663908	best: 0.0663907 (27560)	total: 3m 40s	remaining: 9d 5h 41m 20s
27900:	learn: 0.0472752	test: 0.0663783	best: 0.0663783 (27900)	total: 3m 42s	remaining: 9d 5h 55m 12s
28200:	learn: 0.0472043	test: 0.0663587	best: 0.0663587 (28200)	total: 3m 45s	remaining: 9d 6h 1m 7s
28500:	learn: 0.0471296	test: 0.0663424	best: 0.0663424 (28500)	total: 3m 48s	remaining: 9d 6h 14m 54s
28800:	learn: 0.0470483	test: 0.0663205	best: 0.0663205 (28799)	total: 3m 50s	remaining: 9d 6h 28m 13s
29100:	learn: 0.0469764	test: 0.0663048	best: 0.0663048 (29100)	total: 3m 53s	remaining: 9d 6h 36m 49s
29400:	learn: 0.0469002	test: 0.0662792	best: 0.0662767 (29370)	total: 3m 55s	remaining: 9d 6h 35m 36s
29700:	learn: 0.0468282	test: 0.0662681	best: 0.0662681 (29690)	total: 3m 58s	remaining: 9d 6h 40m 14s
30000:	learn: 0.0467566	test: 0.0662457	best: 0.0662453 (29995)	total: 4m	remaining: 9d 6h 45m 39s
30300:	learn: 0.0466888	test: 0.0662263	best: 0.0662258 (30280)	total: 4m 3s	remaining: 9d 6h 49m 23s
30600:	learn: 0.0466293	test: 0.0662226	best: 0.0662219 (30363)	total: 4m 5s	remaining: 9d 6h 52m 34s
30900:	learn: 0.0465589	test: 0.0662004	best: 0.0662001 (30892)	total: 4m 8s	remaining: 9d 6h 58m 30s
31200:	learn: 0.0464955	test: 0.0661917	best: 0.0661917 (31200)	total: 4m 10s	remaining: 9d 7h 10m 26s
31500:	learn: 0.0464278	test: 0.0661733	best: 0.0661732 (31495)	total: 4m 13s	remaining: 9d 7h 16m 17s
31800:	learn: 0.0463741	test: 0.0661631	best: 0.0661631 (31800)	total: 4m 15s	remaining: 9d 7h 13m 35s
32100:	learn: 0.0463137	test: 0.0661545	best: 0.0661514 (32047)	total: 4m 18s	remaining: 9d 7h 17m 33s
32400:	learn: 0.0462537	test: 0.0661432	best: 0.0661431 (32399)	total: 4m 20s	remaining: 9d 7h 19m 2s
32700:	learn: 0.0461966	test: 0.0661250	best: 0.0661228 (32686)	total: 4m 22s	remaining: 9d 7h 13m 31s
33000:	learn: 0.0461388	test: 0.0661089	best: 0.0661074 (32973)	total: 4m 25s	remaining: 9d 7h 9m 24s
33300:	learn: 0.0460777	test: 0.0660912	best: 0.0660911 (33299)	total: 4m 27s	remaining: 9d 7h 6m 50s
33600:	learn: 0.0460136	test: 0.0660832	best: 0.0660823 (33554)	total: 4m 29s	remaining: 9d 7h 4m 40s
33900:	learn: 0.0459542	test: 0.0660714	best: 0.0660701 (33861)	total: 4m 32s	remaining: 9d 7h 1m 24s
34200:	learn: 0.0458901	test: 0.0660590	best: 0.0660572 (34128)	total: 4m 34s	remaining: 9d 6h 58m 58s
34500:	learn: 0.0458329	test: 0.0660484	best: 0.0660477 (34487)	total: 4m 36s	remaining: 9d 6h 54m 37s
34800:	learn: 0.0457838	test: 0.0660361	best: 0.0660349 (34783)	total: 4m 39s	remaining: 9d 6h 53m 25s
35100:	learn: 0.0457257	test: 0.0660193	best: 0.0660176 (35081)	total: 4m 41s	remaining: 9d 6h 49m 41s
35400:	learn: 0.0456658	test: 0.0660055	best: 0.0660055 (35400)	total: 4m 44s	remaining: 9d 6h 47m 4s
35700:	learn: 0.0456069	test: 0.0659936	best: 0.0659933 (35699)	total: 4m 46s	remaining: 9d 6h 51m 25s
36000:	learn: 0.0455394	test: 0.0659756	best: 0.0659743 (35984)	total: 4m 49s	remaining: 9d 6h 57m 27s
36300:	learn: 0.0454758	test: 0.0659646	best: 0.0659637 (36228)	total: 4m 51s	remaining: 9d 6h 59m 58s
36600:	learn: 0.0454100	test: 0.0659526	best: 0.0659519 (36592)	total: 4m 53s	remaining: 9d 6h 58m 25s
36900:	learn: 0.0453449	test: 0.0659378	best: 0.0659370 (36874)	total: 4m 56s	remaining: 9d 7h 18s
37200:	learn: 0.0452941	test: 0.0659287	best: 0.0659279 (37186)	total: 4m 58s	remaining: 9d 7h 7m 20s
37500:	learn: 0.0452415	test: 0.0659236	best: 0.0659224 (37408)	total: 5m 1s	remaining: 9d 7h 20m 55s
37800:	learn: 0.0451869	test: 0.0658967	best: 0.0658967 (37799)	total: 5m 4s	remaining: 9d 7h 30m 26s
38100:	learn: 0.0451381	test: 0.0658962	best: 0.0658920 (38049)	total: 5m 6s	remaining: 9d 7h 27m 49s
38400:	learn: 0.0450844	test: 0.0658794	best: 0.0658793 (38397)	total: 5m 8s	remaining: 9d 7h 22m 46s
38700:	learn: 0.0450278	test: 0.0658698	best: 0.0658698 (38700)	total: 5m 11s	remaining: 9d 7h 19m 5s
39000:	learn: 0.0449739	test: 0.0658634	best: 0.0658605 (38874)	total: 5m 13s	remaining: 9d 7h 13m 42s
39300:	learn: 0.0449229	test: 0.0658561	best: 0.0658544 (39212)	total: 5m 15s	remaining: 9d 7h 9m 42s
39600:	learn: 0.0448699	test: 0.0658462	best: 0.0658461 (39597)	total: 5m 18s	remaining: 9d 7h 4m 57s
39900:	learn: 0.0448271	test: 0.0658404	best: 0.0658398 (39885)	total: 5m 20s	remaining: 9d 7h 26s
40200:	learn: 0.0447769	test: 0.0658303	best: 0.0658299 (40199)	total: 5m 22s	remaining: 9d 6h 56m 7s
40500:	learn: 0.0447237	test: 0.0658257	best: 0.0658227 (40318)	total: 5m 25s	remaining: 9d 7h 6m 31s
40800:	learn: 0.0446728	test: 0.0658115	best: 0.0658115 (40800)	total: 5m 28s	remaining: 9d 7h 15m 43s
41100:	learn: 0.0446194	test: 0.0657995	best: 0.0657995 (41100)	total: 5m 30s	remaining: 9d 7h 28m 41s
41400:	learn: 0.0445709	test: 0.0657931	best: 0.0657917 (41364)	total: 5m 33s	remaining: 9d 7h 31m 2s
41700:	learn: 0.0445204	test: 0.0657791	best: 0.0657785 (41685)	total: 5m 35s	remaining: 9d 7h 38m 32s
42000:	learn: 0.0444709	test: 0.0657636	best: 0.0657629 (41990)	total: 5m 38s	remaining: 9d 7h 37m 5s
42300:	learn: 0.0444179	test: 0.0657522	best: 0.0657522 (42300)	total: 5m 40s	remaining: 9d 7h 40m 30s
42600:	learn: 0.0443707	test: 0.0657390	best: 0.0657386 (42588)	total: 5m 43s	remaining: 9d 7h 37m 12s
42900:	learn: 0.0443211	test: 0.0657373	best: 0.0657356 (42741)	total: 5m 45s	remaining: 9d 7h 36m 23s
43200:	learn: 0.0442714	test: 0.0657231	best: 0.0657231 (43200)	total: 5m 47s	remaining: 9d 7h 32m 8s
43500:	learn: 0.0442192	test: 0.0657057	best: 0.0657057 (43500)	total: 5m 50s	remaining: 9d 7h 29m 18s
43800:	learn: 0.0441709	test: 0.0656925	best: 0.0656919 (43732)	total: 5m 52s	remaining: 9d 7h 26m 17s
44100:	learn: 0.0441288	test: 0.0656862	best: 0.0656845 (44090)	total: 5m 54s	remaining: 9d 7h 25m 57s
44400:	learn: 0.0440811	test: 0.0656772	best: 0.0656771 (44378)	total: 5m 57s	remaining: 9d 7h 22m 1s
44700:	learn: 0.0440338	test: 0.0656708	best: 0.0656704 (44691)	total: 5m 59s	remaining: 9d 7h 20m 52s
45000:	learn: 0.0439893	test: 0.0656637	best: 0.0656632 (44974)	total: 6m 1s	remaining: 9d 7h 16m 11s
45300:	learn: 0.0439441	test: 0.0656417	best: 0.0656411 (45285)	total: 6m 4s	remaining: 9d 7h 19m 34s
45600:	learn: 0.0438974	test: 0.0656247	best: 0.0656247 (45600)	total: 6m 6s	remaining: 9d 7h 18m 4s
45900:	learn: 0.0438554	test: 0.0656192	best: 0.0656183 (45877)	total: 6m 9s	remaining: 9d 7h 21m 42s
46200:	learn: 0.0438060	test: 0.0656144	best: 0.0656127 (46151)	total: 6m 11s	remaining: 9d 7h 17m 16s
46500:	learn: 0.0437649	test: 0.0656127	best: 0.0656122 (46350)	total: 6m 13s	remaining: 9d 7h 17m 49s
46800:	learn: 0.0437181	test: 0.0656020	best: 0.0656019 (46799)	total: 6m 16s	remaining: 9d 7h 16m 38s
47100:	learn: 0.0436721	test: 0.0655982	best: 0.0655978 (47044)	total: 6m 18s	remaining: 9d 7h 13m 51s
47400:	learn: 0.0436266	test: 0.0655932	best: 0.0655926 (47390)	total: 6m 21s	remaining: 9d 7h 17m 8s
47700:	learn: 0.0435830	test: 0.0655866	best: 0.0655863 (47698)	total: 6m 23s	remaining: 9d 7h 18m 4s
48000:	learn: 0.0435412	test: 0.0655803	best: 0.0655790 (47953)	total: 6m 26s	remaining: 9d 7h 18m 46s
48300:	learn: 0.0434953	test: 0.0655794	best: 0.0655775 (48173)	total: 6m 28s	remaining: 9d 7h 18m 1s
48600:	learn: 0.0434535	test: 0.0655670	best: 0.0655662 (48595)	total: 6m 30s	remaining: 9d 7h 21m 38s
48900:	learn: 0.0434147	test: 0.0655629	best: 0.0655617 (48811)	total: 6m 33s	remaining: 9d 7h 21m 29s
49200:	learn: 0.0433747	test: 0.0655605	best: 0.0655595 (49179)	total: 6m 35s	remaining: 9d 7h 23m 26s
49500:	learn: 0.0433342	test: 0.0655507	best: 0.0655492 (49480)	total: 6m 38s	remaining: 9d 7h 25m 10s
49800:	learn: 0.0432949	test: 0.0655449	best: 0.0655446 (49791)	total: 6m 40s	remaining: 9d 7h 27m 51s
50100:	learn: 0.0432537	test: 0.0655394	best: 0.0655376 (50051)	total: 6m 43s	remaining: 9d 7h 24m 11s
50400:	learn: 0.0432151	test: 0.0655331	best: 0.0655331 (50399)	total: 6m 45s	remaining: 9d 7h 22m 11s
50700:	learn: 0.0431737	test: 0.0655325	best: 0.0655300 (50617)	total: 6m 47s	remaining: 9d 7h 21m 55s
51000:	learn: 0.0431323	test: 0.0655291	best: 0.0655260 (50915)	total: 6m 50s	remaining: 9d 7h 21m 8s
51300:	learn: 0.0430892	test: 0.0655259	best: 0.0655240 (51264)	total: 6m 52s	remaining: 9d 7h 19m 44s
51600:	learn: 0.0430465	test: 0.0655215	best: 0.0655210 (51592)	total: 6m 54s	remaining: 9d 7h 16m 28s
51900:	learn: 0.0430086	test: 0.0655142	best: 0.0655138 (51896)	total: 6m 57s	remaining: 9d 7h 13m 22s
52200:	learn: 0.0429738	test: 0.0655076	best: 0.0655071 (52190)	total: 6m 59s	remaining: 9d 7h 10m 43s
52500:	learn: 0.0429357	test: 0.0655025	best: 0.0655023 (52499)	total: 7m 2s	remaining: 9d 7h 11m 15s
52800:	learn: 0.0429008	test: 0.0654991	best: 0.0654991 (52800)	total: 7m 4s	remaining: 9d 7h 11m 39s
53100:	learn: 0.0428649	test: 0.0654930	best: 0.0654921 (53056)	total: 7m 6s	remaining: 9d 7h 8m 30s
53400:	learn: 0.0428296	test: 0.0654885	best: 0.0654884 (53398)	total: 7m 9s	remaining: 9d 7h 8m 28s
53700:	learn: 0.0427906	test: 0.0654846	best: 0.0654828 (53543)	total: 7m 11s	remaining: 9d 7h 6m 31s
54000:	learn: 0.0427483	test: 0.0654804	best: 0.0654798 (53987)	total: 7m 13s	remaining: 9d 7h 5m 26s
54300:	learn: 0.0427075	test: 0.0654729	best: 0.0654729 (54300)	total: 7m 16s	remaining: 9d 7h 4m 33s
54600:	learn: 0.0426697	test: 0.0654630	best: 0.0654628 (54592)	total: 7m 18s	remaining: 9d 7h 4m 23s
54900:	learn: 0.0426349	test: 0.0654575	best: 0.0654559 (54801)	total: 7m 21s	remaining: 9d 7h 2m 52s
55200:	learn: 0.0425972	test: 0.0654495	best: 0.0654495 (55200)	total: 7m 23s	remaining: 9d 7h 59s
55500:	learn: 0.0425592	test: 0.0654439	best: 0.0654439 (55497)	total: 7m 26s	remaining: 9d 7h 6m 35s
55800:	learn: 0.0425210	test: 0.0654383	best: 0.0654369 (55790)	total: 7m 28s	remaining: 9d 7h 7m 10s
56100:	learn: 0.0424870	test: 0.0654293	best: 0.0654286 (56055)	total: 7m 30s	remaining: 9d 7h 4m 15s
56400:	learn: 0.0424484	test: 0.0654289	best: 0.0654262 (56298)	total: 7m 33s	remaining: 9d 7h 5m 14s
56700:	learn: 0.0424124	test: 0.0654244	best: 0.0654239 (56695)	total: 7m 35s	remaining: 9d 7h 2m 27s
57000:	learn: 0.0423752	test: 0.0654156	best: 0.0654150 (56992)	total: 7m 37s	remaining: 9d 7h 1m 41s
57300:	learn: 0.0423411	test: 0.0654089	best: 0.0654079 (57289)	total: 7m 40s	remaining: 9d 6h 59m 58s
57600:	learn: 0.0423040	test: 0.0654023	best: 0.0654021 (57589)	total: 7m 42s	remaining: 9d 7h 4s
57900:	learn: 0.0422680	test: 0.0653925	best: 0.0653915 (57839)	total: 7m 45s	remaining: 9d 7h 3m 52s
58200:	learn: 0.0422267	test: 0.0653906	best: 0.0653899 (58134)	total: 7m 47s	remaining: 9d 7h 8m 37s
58500:	learn: 0.0421942	test: 0.0653837	best: 0.0653834 (58480)	total: 7m 50s	remaining: 9d 7h 12m 21s
58800:	learn: 0.0421577	test: 0.0653779	best: 0.0653779 (58800)	total: 7m 52s	remaining: 9d 7h 16m 9s
59100:	learn: 0.0421282	test: 0.0653703	best: 0.0653698 (59084)	total: 7m 55s	remaining: 9d 7h 19m 52s
59400:	learn: 0.0420904	test: 0.0653723	best: 0.0653696 (59178)	total: 7m 58s	remaining: 9d 7h 24m 16s
59700:	learn: 0.0420585	test: 0.0653648	best: 0.0653641 (59699)	total: 8m	remaining: 9d 7h 26m 52s
60000:	learn: 0.0420268	test: 0.0653665	best: 0.0653618 (59815)	total: 8m 3s	remaining: 9d 7h 30m 35s
60300:	learn: 0.0419929	test: 0.0653619	best: 0.0653609 (60275)	total: 8m 5s	remaining: 9d 7h 34m 16s
60600:	learn: 0.0419649	test: 0.0653550	best: 0.0653546 (60595)	total: 8m 8s	remaining: 9d 7h 37m 53s
60900:	learn: 0.0419339	test: 0.0653476	best: 0.0653473 (60889)	total: 8m 10s	remaining: 9d 7h 41m 32s
61200:	learn: 0.0419017	test: 0.0653419	best: 0.0653419 (61200)	total: 8m 13s	remaining: 9d 7h 46m 1s
61500:	learn: 0.0418711	test: 0.0653433	best: 0.0653418 (61201)	total: 8m 15s	remaining: 9d 7h 48m 59s
61800:	learn: 0.0418414	test: 0.0653419	best: 0.0653402 (61685)	total: 8m 18s	remaining: 9d 7h 53m 33s
62100:	learn: 0.0418146	test: 0.0653355	best: 0.0653355 (62100)	total: 8m 20s	remaining: 9d 7h 57m 17s
62400:	learn: 0.0417838	test: 0.0653289	best: 0.0653289 (62400)	total: 8m 23s	remaining: 9d 8h 12m 42s
62700:	learn: 0.0417547	test: 0.0653295	best: 0.0653258 (62542)	total: 8m 26s	remaining: 9d 8h 16m 59s
63000:	learn: 0.0417205	test: 0.0653214	best: 0.0653211 (62920)	total: 8m 29s	remaining: 9d 8h 21m 1s
63300:	learn: 0.0416931	test: 0.0653143	best: 0.0653143 (63300)	total: 8m 31s	remaining: 9d 8h 26m 31s
63600:	learn: 0.0416635	test: 0.0653155	best: 0.0653137 (63400)	total: 8m 34s	remaining: 9d 8h 31m 21s
63900:	learn: 0.0416332	test: 0.0653104	best: 0.0653098 (63891)	total: 8m 36s	remaining: 9d 8h 34m 39s
64200:	learn: 0.0416036	test: 0.0653067	best: 0.0653057 (64180)	total: 8m 39s	remaining: 9d 8h 38m 21s
64500:	learn: 0.0415732	test: 0.0653028	best: 0.0653018 (64373)	total: 8m 42s	remaining: 9d 8h 41m 1s
64800:	learn: 0.0415458	test: 0.0652982	best: 0.0652982 (64800)	total: 8m 44s	remaining: 9d 8h 44m 14s
65100:	learn: 0.0415186	test: 0.0652942	best: 0.0652941 (65061)	total: 8m 47s	remaining: 9d 8h 48m 17s
65400:	learn: 0.0414921	test: 0.0652862	best: 0.0652862 (65399)	total: 8m 49s	remaining: 9d 8h 52m 40s
65700:	learn: 0.0414613	test: 0.0652860	best: 0.0652842 (65514)	total: 8m 52s	remaining: 9d 8h 55m 36s
66000:	learn: 0.0414272	test: 0.0652794	best: 0.0652794 (65978)	total: 8m 54s	remaining: 9d 8h 58m 17s
66300:	learn: 0.0413964	test: 0.0652799	best: 0.0652772 (66150)	total: 8m 57s	remaining: 9d 9h 1m 58s
66600:	learn: 0.0413672	test: 0.0652767	best: 0.0652763 (66593)	total: 8m 59s	remaining: 9d 9h 4m 16s
66900:	learn: 0.0413398	test: 0.0652773	best: 0.0652763 (66593)	total: 9m 2s	remaining: 9d 9h 6m 43s
67200:	learn: 0.0413112	test: 0.0652701	best: 0.0652689 (67165)	total: 9m 5s	remaining: 9d 9h 9m 12s
67500:	learn: 0.0412851	test: 0.0652662	best: 0.0652662 (67500)	total: 9m 7s	remaining: 9d 9h 12m 28s
67800:	learn: 0.0412562	test: 0.0652612	best: 0.0652612 (67800)	total: 9m 10s	remaining: 9d 9h 14m 45s
68100:	learn: 0.0412305	test: 0.0652567	best: 0.0652542 (68037)	total: 9m 12s	remaining: 9d 9h 17m 29s
68400:	learn: 0.0412020	test: 0.0652522	best: 0.0652515 (68387)	total: 9m 15s	remaining: 9d 9h 21m 21s
68700:	learn: 0.0411765	test: 0.0652482	best: 0.0652481 (68692)	total: 9m 17s	remaining: 9d 9h 23m 43s
69000:	learn: 0.0411492	test: 0.0652374	best: 0.0652373 (68984)	total: 9m 20s	remaining: 9d 9h 26m 8s
69300:	learn: 0.0411235	test: 0.0652300	best: 0.0652296 (69289)	total: 9m 23s	remaining: 9d 9h 34m 34s
69600:	learn: 0.0410959	test: 0.0652260	best: 0.0652243 (69493)	total: 9m 26s	remaining: 9d 9h 47m 16s
69900:	learn: 0.0410663	test: 0.0652246	best: 0.0652240 (69829)	total: 9m 29s	remaining: 9d 9h 58m 11s
70200:	learn: 0.0410419	test: 0.0652207	best: 0.0652197 (70122)	total: 9m 31s	remaining: 9d 10h 8m 12s
70500:	learn: 0.0410147	test: 0.0652173	best: 0.0652173 (70484)	total: 9m 34s	remaining: 9d 10h 16m 17s
70800:	learn: 0.0409883	test: 0.0652134	best: 0.0652134 (70799)	total: 9m 37s	remaining: 9d 10h 24m 15s
71100:	learn: 0.0409602	test: 0.0652112	best: 0.0652103 (70841)	total: 9m 40s	remaining: 9d 10h 37m 50s
71400:	learn: 0.0409323	test: 0.0652074	best: 0.0652054 (71316)	total: 9m 43s	remaining: 9d 10h 50m 21s
71700:	learn: 0.0409079	test: 0.0652039	best: 0.0652037 (71697)	total: 9m 46s	remaining: 9d 10h 52m 34s
72000:	learn: 0.0408806	test: 0.0651992	best: 0.0651988 (71981)	total: 9m 48s	remaining: 9d 10h 57m 48s
72300:	learn: 0.0408522	test: 0.0651929	best: 0.0651927 (72293)	total: 9m 51s	remaining: 9d 11h 2m 51s
72600:	learn: 0.0408290	test: 0.0651881	best: 0.0651874 (72456)	total: 9m 54s	remaining: 9d 11h 7m 53s
72900:	learn: 0.0408038	test: 0.0651853	best: 0.0651853 (72900)	total: 9m 56s	remaining: 9d 11h 12m 42s
73200:	learn: 0.0407769	test: 0.0651789	best: 0.0651789 (73200)	total: 9m 59s	remaining: 9d 11h 17m 43s
73500:	learn: 0.0407504	test: 0.0651779	best: 0.0651755 (73374)	total: 10m 2s	remaining: 9d 11h 22m 21s
73800:	learn: 0.0407236	test: 0.0651740	best: 0.0651723 (73766)	total: 10m 4s	remaining: 9d 11h 27m 10s
74100:	learn: 0.0406954	test: 0.0651730	best: 0.0651722 (74080)	total: 10m 7s	remaining: 9d 11h 34m 16s
74400:	learn: 0.0406727	test: 0.0651681	best: 0.0651672 (74377)	total: 10m 10s	remaining: 9d 11h 46m 20s
74700:	learn: 0.0406457	test: 0.0651668	best: 0.0651663 (74524)	total: 10m 13s	remaining: 9d 11h 52m 44s
75000:	learn: 0.0406224	test: 0.0651585	best: 0.0651584 (74988)	total: 10m 15s	remaining: 9d 11h 57m 6s
75300:	learn: 0.0405976	test: 0.0651620	best: 0.0651576 (75200)	total: 10m 18s	remaining: 9d 12h 1m 31s
75600:	learn: 0.0405729	test: 0.0651558	best: 0.0651558 (75600)	total: 10m 21s	remaining: 9d 12h 5m 17s
75900:	learn: 0.0405484	test: 0.0651570	best: 0.0651532 (75718)	total: 10m 23s	remaining: 9d 12h 8m 45s
76200:	learn: 0.0405262	test: 0.0651503	best: 0.0651501 (76196)	total: 10m 26s	remaining: 9d 12h 10m 5s
76500:	learn: 0.0404986	test: 0.0651457	best: 0.0651452 (76463)	total: 10m 29s	remaining: 9d 12h 16m 14s
76800:	learn: 0.0404745	test: 0.0651410	best: 0.0651408 (76786)	total: 10m 31s	remaining: 9d 12h 19m 26s
77100:	learn: 0.0404466	test: 0.0651350	best: 0.0651350 (77100)	total: 10m 34s	remaining: 9d 12h 22m 46s
77400:	learn: 0.0404203	test: 0.0651358	best: 0.0651342 (77240)	total: 10m 37s	remaining: 9d 12h 37m 22s
77700:	learn: 0.0403949	test: 0.0651336	best: 0.0651319 (77565)	total: 10m 40s	remaining: 9d 12h 46m 31s
78000:	learn: 0.0403695	test: 0.0651315	best: 0.0651311 (77839)	total: 10m 43s	remaining: 9d 12h 51m
78300:	learn: 0.0403413	test: 0.0651242	best: 0.0651239 (78289)	total: 10m 45s	remaining: 9d 12h 52m 45s
78600:	learn: 0.0403164	test: 0.0651230	best: 0.0651226 (78596)	total: 10m 48s	remaining: 9d 12h 55m 39s
78900:	learn: 0.0402926	test: 0.0651236	best: 0.0651220 (78742)	total: 10m 51s	remaining: 9d 13h 1m 29s
79200:	learn: 0.0402689	test: 0.0651180	best: 0.0651180 (79198)	total: 10m 53s	remaining: 9d 13h 2m 37s
79500:	learn: 0.0402437	test: 0.0651178	best: 0.0651144 (79346)	total: 10m 56s	remaining: 9d 13h 5m 11s
79800:	learn: 0.0402168	test: 0.0651115	best: 0.0651108 (79796)	total: 10m 58s	remaining: 9d 13h 11m 42s
80100:	learn: 0.0401918	test: 0.0651082	best: 0.0651081 (80077)	total: 11m 2s	remaining: 9d 13h 27m 6s
80400:	learn: 0.0401689	test: 0.0651079	best: 0.0651056 (80321)	total: 11m 5s	remaining: 9d 13h 33m 58s
80700:	learn: 0.0401392	test: 0.0650993	best: 0.0650992 (80692)	total: 11m 8s	remaining: 9d 13h 49m 25s
81000:	learn: 0.0401172	test: 0.0650983	best: 0.0650970 (80950)	total: 11m 11s	remaining: 9d 13h 58m 14s
81300:	learn: 0.0400918	test: 0.0650975	best: 0.0650952 (81161)	total: 11m 13s	remaining: 9d 14h 10s
81600:	learn: 0.0400687	test: 0.0650937	best: 0.0650932 (81497)	total: 11m 16s	remaining: 9d 14h 43s
81900:	learn: 0.0400460	test: 0.0650933	best: 0.0650932 (81497)	total: 11m 18s	remaining: 9d 14h 1m 49s
82200:	learn: 0.0400216	test: 0.0650887	best: 0.0650878 (82191)	total: 11m 21s	remaining: 9d 14h 2m 47s
82500:	learn: 0.0399993	test: 0.0650888	best: 0.0650878 (82191)	total: 11m 23s	remaining: 9d 14h 3m 39s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.06508783039
bestIteration = 82191

Shrink model to first 82192 iterations.
fold n°9
0:	learn: 0.5687895	test: 0.5771717	best: 0.5771717 (0)	total: 9.72ms	remaining: 11d 6h 42s
300:	learn: 0.1335962	test: 0.1394201	best: 0.1394201 (300)	total: 2.69s	remaining: 10d 8h 31m 25s
600:	learn: 0.0977086	test: 0.1026402	best: 0.1026402 (600)	total: 5.15s	remaining: 9d 22h 7m 51s
900:	learn: 0.0889036	test: 0.0947333	best: 0.0947333 (900)	total: 7.5s	remaining: 9d 15h 18m 51s
1200:	learn: 0.0836978	test: 0.0899365	best: 0.0899365 (1200)	total: 9.83s	remaining: 9d 11h 20m 24s
1500:	learn: 0.0797896	test: 0.0865995	best: 0.0865995 (1500)	total: 12.1s	remaining: 9d 8h 30m 30s
1800:	learn: 0.0767554	test: 0.0840922	best: 0.0840922 (1800)	total: 14.4s	remaining: 9d 6h 46m 43s
2100:	learn: 0.0744016	test: 0.0822817	best: 0.0822817 (2100)	total: 16.7s	remaining: 9d 5h 26m 1s
2400:	learn: 0.0725138	test: 0.0808818	best: 0.0808818 (2400)	total: 19.1s	remaining: 9d 4h 51m 1s
2700:	learn: 0.0708685	test: 0.0796987	best: 0.0796987 (2700)	total: 21.4s	remaining: 9d 4h 15m 43s
3000:	learn: 0.0694016	test: 0.0786814	best: 0.0786814 (3000)	total: 23.7s	remaining: 9d 3h 46m 1s
3300:	learn: 0.0681365	test: 0.0779098	best: 0.0779098 (3300)	total: 26s	remaining: 9d 3h 10m 14s
3600:	learn: 0.0670045	test: 0.0772281	best: 0.0772281 (3600)	total: 28.4s	remaining: 9d 3h 1m 34s
3900:	learn: 0.0660124	test: 0.0766650	best: 0.0766650 (3900)	total: 30.8s	remaining: 9d 2h 59m 35s
4200:	learn: 0.0651137	test: 0.0761770	best: 0.0761770 (4200)	total: 33.1s	remaining: 9d 2h 43m 54s
4500:	learn: 0.0642689	test: 0.0757521	best: 0.0757521 (4500)	total: 35.4s	remaining: 9d 2h 23m 59s
4800:	learn: 0.0634644	test: 0.0753646	best: 0.0753646 (4800)	total: 37.7s	remaining: 9d 2h 21m 58s
5100:	learn: 0.0627714	test: 0.0750186	best: 0.0750186 (5100)	total: 40.1s	remaining: 9d 2h 8m 26s
5400:	learn: 0.0621134	test: 0.0747484	best: 0.0747484 (5400)	total: 42.4s	remaining: 9d 1h 53m 56s
5700:	learn: 0.0614899	test: 0.0744392	best: 0.0744392 (5700)	total: 44.7s	remaining: 9d 1h 44m 22s
6000:	learn: 0.0609045	test: 0.0741637	best: 0.0741637 (6000)	total: 47.1s	remaining: 9d 1h 47m 31s
6300:	learn: 0.0603440	test: 0.0738846	best: 0.0738846 (6300)	total: 49.4s	remaining: 9d 1h 39m 21s
6600:	learn: 0.0598264	test: 0.0736519	best: 0.0736516 (6599)	total: 51.7s	remaining: 9d 1h 30m 4s
6900:	learn: 0.0593501	test: 0.0734293	best: 0.0734293 (6900)	total: 54s	remaining: 9d 1h 26m 47s
7200:	learn: 0.0589060	test: 0.0732477	best: 0.0732475 (7187)	total: 56.3s	remaining: 9d 1h 14m 42s
7500:	learn: 0.0584817	test: 0.0730637	best: 0.0730637 (7500)	total: 58.7s	remaining: 9d 1h 25m 45s
7800:	learn: 0.0580810	test: 0.0728836	best: 0.0728832 (7799)	total: 1m 1s	remaining: 9d 1h 16m 40s
8100:	learn: 0.0577008	test: 0.0727160	best: 0.0727160 (8100)	total: 1m 3s	remaining: 9d 1h 9m 33s
8400:	learn: 0.0573307	test: 0.0725671	best: 0.0725671 (8400)	total: 1m 5s	remaining: 9d 1h 1m 16s
8700:	learn: 0.0569662	test: 0.0724223	best: 0.0724223 (8700)	total: 1m 7s	remaining: 9d 55m 37s
9000:	learn: 0.0566228	test: 0.0722995	best: 0.0722995 (9000)	total: 1m 10s	remaining: 9d 1h 11m 35s
9300:	learn: 0.0562961	test: 0.0721515	best: 0.0721514 (9299)	total: 1m 12s	remaining: 9d 1h 31m 6s
9600:	learn: 0.0559940	test: 0.0720378	best: 0.0720377 (9599)	total: 1m 15s	remaining: 9d 1h 43m 34s
9900:	learn: 0.0556968	test: 0.0719087	best: 0.0719087 (9900)	total: 1m 17s	remaining: 9d 2h 1m 58s
10200:	learn: 0.0554160	test: 0.0717880	best: 0.0717880 (10200)	total: 1m 20s	remaining: 9d 2h 8m 48s
10500:	learn: 0.0551496	test: 0.0717080	best: 0.0717080 (10500)	total: 1m 22s	remaining: 9d 2h 16m 33s
10800:	learn: 0.0548855	test: 0.0716067	best: 0.0716067 (10800)	total: 1m 24s	remaining: 9d 2h 16m 6s
11100:	learn: 0.0546256	test: 0.0715157	best: 0.0715157 (11100)	total: 1m 27s	remaining: 9d 2h 14m 11s
11400:	learn: 0.0543839	test: 0.0714345	best: 0.0714337 (11397)	total: 1m 29s	remaining: 9d 2h 43m 14s
11700:	learn: 0.0541301	test: 0.0713441	best: 0.0713441 (11700)	total: 1m 32s	remaining: 9d 2h 59m 18s
12000:	learn: 0.0539040	test: 0.0712596	best: 0.0712596 (12000)	total: 1m 34s	remaining: 9d 3h 6m 56s
12300:	learn: 0.0536857	test: 0.0711777	best: 0.0711777 (12300)	total: 1m 37s	remaining: 9d 3h 6m 12s
12600:	learn: 0.0534694	test: 0.0711064	best: 0.0711064 (12600)	total: 1m 39s	remaining: 9d 3h 2m 44s
12900:	learn: 0.0532578	test: 0.0710301	best: 0.0710301 (12899)	total: 1m 41s	remaining: 9d 2h 53m 10s
13200:	learn: 0.0530473	test: 0.0709495	best: 0.0709493 (13196)	total: 1m 43s	remaining: 9d 2h 48m 13s
13500:	learn: 0.0528416	test: 0.0708788	best: 0.0708788 (13500)	total: 1m 46s	remaining: 9d 2h 48m 45s
13800:	learn: 0.0526468	test: 0.0708050	best: 0.0708050 (13799)	total: 1m 48s	remaining: 9d 2h 59m 5s
14100:	learn: 0.0524508	test: 0.0707235	best: 0.0707226 (14097)	total: 1m 51s	remaining: 9d 3h 29m 46s
14400:	learn: 0.0522817	test: 0.0706743	best: 0.0706739 (14399)	total: 1m 53s	remaining: 9d 3h 31m 56s
14700:	learn: 0.0521055	test: 0.0706154	best: 0.0706150 (14697)	total: 1m 56s	remaining: 9d 3h 31m 41s
15000:	learn: 0.0519276	test: 0.0705668	best: 0.0705668 (15000)	total: 1m 58s	remaining: 9d 3h 46m 24s
15300:	learn: 0.0517551	test: 0.0705070	best: 0.0705069 (15298)	total: 2m 1s	remaining: 9d 3h 44m 4s
15600:	learn: 0.0515960	test: 0.0704702	best: 0.0704697 (15575)	total: 2m 3s	remaining: 9d 3h 55m 19s
15900:	learn: 0.0514283	test: 0.0704084	best: 0.0704084 (15897)	total: 2m 5s	remaining: 9d 4h 3m 15s
16200:	learn: 0.0512641	test: 0.0703621	best: 0.0703618 (16199)	total: 2m 8s	remaining: 9d 3h 57m 48s
16500:	learn: 0.0511087	test: 0.0703115	best: 0.0703114 (16498)	total: 2m 10s	remaining: 9d 3h 55m 50s
16800:	learn: 0.0509611	test: 0.0702668	best: 0.0702668 (16800)	total: 2m 13s	remaining: 9d 3h 57m 34s
17100:	learn: 0.0508151	test: 0.0702237	best: 0.0702232 (17096)	total: 2m 15s	remaining: 9d 4h 3m 24s
17400:	learn: 0.0506649	test: 0.0701812	best: 0.0701808 (17399)	total: 2m 17s	remaining: 9d 3h 59m 47s
17700:	learn: 0.0505245	test: 0.0701504	best: 0.0701495 (17696)	total: 2m 20s	remaining: 9d 4h 54s
18000:	learn: 0.0503882	test: 0.0701111	best: 0.0701111 (18000)	total: 2m 22s	remaining: 9d 3h 59m 27s
18300:	learn: 0.0502495	test: 0.0700761	best: 0.0700756 (18291)	total: 2m 24s	remaining: 9d 3h 50m 22s
18600:	learn: 0.0501208	test: 0.0700367	best: 0.0700363 (18568)	total: 2m 27s	remaining: 9d 3h 49m 7s
18900:	learn: 0.0499841	test: 0.0699944	best: 0.0699940 (18896)	total: 2m 29s	remaining: 9d 3h 41m 11s
19200:	learn: 0.0498619	test: 0.0699433	best: 0.0699433 (19200)	total: 2m 31s	remaining: 9d 3h 38m 20s
19500:	learn: 0.0497393	test: 0.0699007	best: 0.0699005 (19497)	total: 2m 34s	remaining: 9d 3h 34m 5s
19800:	learn: 0.0496168	test: 0.0698652	best: 0.0698652 (19800)	total: 2m 36s	remaining: 9d 3h 39m 30s
20100:	learn: 0.0495038	test: 0.0698312	best: 0.0698312 (20087)	total: 2m 38s	remaining: 9d 3h 39m 16s
20400:	learn: 0.0493893	test: 0.0697941	best: 0.0697936 (20398)	total: 2m 41s	remaining: 9d 3h 34m 22s
20700:	learn: 0.0492801	test: 0.0697673	best: 0.0697666 (20638)	total: 2m 43s	remaining: 9d 3h 32m 57s
21000:	learn: 0.0491677	test: 0.0697355	best: 0.0697350 (20996)	total: 2m 45s	remaining: 9d 3h 29m 6s
21300:	learn: 0.0490580	test: 0.0696972	best: 0.0696972 (21300)	total: 2m 48s	remaining: 9d 3h 30m 40s
21600:	learn: 0.0489505	test: 0.0696746	best: 0.0696746 (21598)	total: 2m 50s	remaining: 9d 3h 29m 4s
21900:	learn: 0.0488333	test: 0.0696412	best: 0.0696412 (21899)	total: 2m 53s	remaining: 9d 3h 31m 44s
22200:	learn: 0.0487243	test: 0.0696205	best: 0.0696195 (22187)	total: 2m 55s	remaining: 9d 3h 33m 12s
22500:	learn: 0.0486263	test: 0.0695931	best: 0.0695931 (22500)	total: 2m 57s	remaining: 9d 3h 27m 52s
22800:	learn: 0.0485252	test: 0.0695706	best: 0.0695701 (22791)	total: 3m	remaining: 9d 3h 29m 12s
23100:	learn: 0.0484263	test: 0.0695508	best: 0.0695497 (23089)	total: 3m 2s	remaining: 9d 3h 32m 31s
23400:	learn: 0.0483332	test: 0.0695238	best: 0.0695236 (23399)	total: 3m 4s	remaining: 9d 3h 29m 13s
23700:	learn: 0.0482441	test: 0.0695102	best: 0.0695085 (23689)	total: 3m 7s	remaining: 9d 3h 27m 3s
24000:	learn: 0.0481453	test: 0.0694939	best: 0.0694933 (23994)	total: 3m 9s	remaining: 9d 3h 28m 46s
24300:	learn: 0.0480565	test: 0.0694671	best: 0.0694657 (24283)	total: 3m 12s	remaining: 9d 3h 28m 50s
24600:	learn: 0.0479633	test: 0.0694421	best: 0.0694409 (24586)	total: 3m 14s	remaining: 9d 3h 26m 42s
24900:	learn: 0.0478644	test: 0.0694232	best: 0.0694230 (24898)	total: 3m 16s	remaining: 9d 3h 28m 37s
25200:	learn: 0.0477723	test: 0.0693892	best: 0.0693892 (25200)	total: 3m 19s	remaining: 9d 3h 25m 7s
25500:	learn: 0.0476833	test: 0.0693625	best: 0.0693625 (25499)	total: 3m 21s	remaining: 9d 3h 26m 19s
25800:	learn: 0.0476011	test: 0.0693394	best: 0.0693394 (25800)	total: 3m 23s	remaining: 9d 3h 27m 18s
26100:	learn: 0.0475158	test: 0.0693235	best: 0.0693234 (26084)	total: 3m 26s	remaining: 9d 3h 30m 57s
26400:	learn: 0.0474319	test: 0.0693039	best: 0.0693038 (26398)	total: 3m 28s	remaining: 9d 3h 33m 45s
26700:	learn: 0.0473540	test: 0.0692918	best: 0.0692918 (26700)	total: 3m 31s	remaining: 9d 3h 31m 56s
27000:	learn: 0.0472740	test: 0.0692738	best: 0.0692737 (26987)	total: 3m 33s	remaining: 9d 3h 30m 31s
27300:	learn: 0.0471947	test: 0.0692520	best: 0.0692520 (27300)	total: 3m 35s	remaining: 9d 3h 30m 44s
27600:	learn: 0.0471165	test: 0.0692322	best: 0.0692308 (27592)	total: 3m 38s	remaining: 9d 3h 32m 58s
27900:	learn: 0.0470354	test: 0.0692108	best: 0.0692102 (27878)	total: 3m 40s	remaining: 9d 3h 36m 39s
28200:	learn: 0.0469613	test: 0.0691884	best: 0.0691883 (28198)	total: 3m 43s	remaining: 9d 3h 40m 17s
28500:	learn: 0.0468886	test: 0.0691671	best: 0.0691669 (28499)	total: 3m 45s	remaining: 9d 3h 41m 29s
28800:	learn: 0.0468233	test: 0.0691510	best: 0.0691506 (28797)	total: 3m 48s	remaining: 9d 3h 54m 22s
29100:	learn: 0.0467535	test: 0.0691388	best: 0.0691386 (29087)	total: 3m 50s	remaining: 9d 3h 54m 7s
29400:	learn: 0.0466843	test: 0.0691287	best: 0.0691269 (29287)	total: 3m 52s	remaining: 9d 3h 55m 24s
29700:	learn: 0.0466161	test: 0.0691167	best: 0.0691163 (29691)	total: 3m 55s	remaining: 9d 3h 58m 36s
30000:	learn: 0.0465470	test: 0.0690947	best: 0.0690947 (30000)	total: 3m 57s	remaining: 9d 3h 57m 55s
30300:	learn: 0.0464861	test: 0.0690831	best: 0.0690825 (30296)	total: 3m 59s	remaining: 9d 3h 55m 52s
30600:	learn: 0.0464178	test: 0.0690648	best: 0.0690645 (30599)	total: 4m 2s	remaining: 9d 3h 52m 57s
30900:	learn: 0.0463470	test: 0.0690468	best: 0.0690465 (30899)	total: 4m 4s	remaining: 9d 3h 52m 55s
31200:	learn: 0.0462716	test: 0.0690278	best: 0.0690278 (31198)	total: 4m 7s	remaining: 9d 3h 50m 49s
31500:	learn: 0.0462052	test: 0.0690199	best: 0.0690184 (31482)	total: 4m 9s	remaining: 9d 3h 51m 49s
31800:	learn: 0.0461381	test: 0.0690039	best: 0.0690033 (31777)	total: 4m 11s	remaining: 9d 3h 54m 59s
32100:	learn: 0.0460722	test: 0.0689841	best: 0.0689836 (32090)	total: 4m 14s	remaining: 9d 3h 53m 41s
32400:	learn: 0.0460103	test: 0.0689704	best: 0.0689704 (32400)	total: 4m 16s	remaining: 9d 3h 57m 36s
32700:	learn: 0.0459429	test: 0.0689608	best: 0.0689608 (32700)	total: 4m 19s	remaining: 9d 3h 57m 28s
33000:	learn: 0.0458819	test: 0.0689455	best: 0.0689447 (32991)	total: 4m 21s	remaining: 9d 3h 56m 24s
33300:	learn: 0.0458172	test: 0.0689272	best: 0.0689272 (33300)	total: 4m 23s	remaining: 9d 3h 51m 36s
33600:	learn: 0.0457591	test: 0.0689115	best: 0.0689115 (33600)	total: 4m 26s	remaining: 9d 3h 53m 22s
33900:	learn: 0.0457035	test: 0.0688996	best: 0.0688993 (33899)	total: 4m 28s	remaining: 9d 3h 49m 20s
34200:	learn: 0.0456421	test: 0.0688890	best: 0.0688871 (34177)	total: 4m 30s	remaining: 9d 3h 53m 25s
34500:	learn: 0.0455815	test: 0.0688762	best: 0.0688756 (34447)	total: 4m 33s	remaining: 9d 3h 51m 59s
34800:	learn: 0.0455204	test: 0.0688635	best: 0.0688634 (34796)	total: 4m 35s	remaining: 9d 3h 53m 13s
35100:	learn: 0.0454667	test: 0.0688514	best: 0.0688502 (35073)	total: 4m 37s	remaining: 9d 3h 50m 32s
35400:	learn: 0.0454093	test: 0.0688402	best: 0.0688396 (35348)	total: 4m 40s	remaining: 9d 3h 47m 50s
35700:	learn: 0.0453496	test: 0.0688195	best: 0.0688194 (35689)	total: 4m 42s	remaining: 9d 3h 43m 54s
36000:	learn: 0.0452923	test: 0.0688002	best: 0.0688001 (35999)	total: 4m 44s	remaining: 9d 3h 43m 9s
36300:	learn: 0.0452367	test: 0.0687960	best: 0.0687948 (36233)	total: 4m 47s	remaining: 9d 3h 45m 1s
36600:	learn: 0.0451809	test: 0.0687840	best: 0.0687840 (36600)	total: 4m 49s	remaining: 9d 3h 43m 36s
36900:	learn: 0.0451263	test: 0.0687753	best: 0.0687741 (36895)	total: 4m 52s	remaining: 9d 3h 46m 7s
37200:	learn: 0.0450698	test: 0.0687626	best: 0.0687619 (37185)	total: 4m 54s	remaining: 9d 3h 49m 21s
37500:	learn: 0.0450158	test: 0.0687655	best: 0.0687595 (37237)	total: 4m 56s	remaining: 9d 3h 45m 51s
37800:	learn: 0.0449592	test: 0.0687591	best: 0.0687567 (37712)	total: 4m 59s	remaining: 9d 3h 46m 36s
38100:	learn: 0.0449039	test: 0.0687509	best: 0.0687508 (38098)	total: 5m 1s	remaining: 9d 3h 49m 33s
38400:	learn: 0.0448451	test: 0.0687388	best: 0.0687385 (38392)	total: 5m 4s	remaining: 9d 3h 50m 21s
38700:	learn: 0.0447913	test: 0.0687294	best: 0.0687294 (38700)	total: 5m 6s	remaining: 9d 3h 51m 5s
39000:	learn: 0.0447403	test: 0.0687189	best: 0.0687179 (38992)	total: 5m 8s	remaining: 9d 3h 50m 15s
39300:	learn: 0.0446889	test: 0.0687079	best: 0.0687075 (39291)	total: 5m 11s	remaining: 9d 3h 52m 31s
39600:	learn: 0.0446365	test: 0.0687006	best: 0.0687006 (39600)	total: 5m 13s	remaining: 9d 3h 54m 22s
39900:	learn: 0.0445873	test: 0.0686924	best: 0.0686924 (39900)	total: 5m 15s	remaining: 9d 3h 53m 37s
40200:	learn: 0.0445328	test: 0.0686840	best: 0.0686824 (40144)	total: 5m 18s	remaining: 9d 3h 50m 33s
40500:	learn: 0.0444792	test: 0.0686697	best: 0.0686697 (40500)	total: 5m 20s	remaining: 9d 3h 50m 6s
40800:	learn: 0.0444296	test: 0.0686661	best: 0.0686661 (40797)	total: 5m 23s	remaining: 9d 3h 53m 14s
41100:	learn: 0.0443814	test: 0.0686604	best: 0.0686599 (41099)	total: 5m 25s	remaining: 9d 3h 50m 26s
41400:	learn: 0.0443379	test: 0.0686547	best: 0.0686544 (41395)	total: 5m 27s	remaining: 9d 3h 46m 59s
41700:	learn: 0.0442864	test: 0.0686473	best: 0.0686470 (41668)	total: 5m 30s	remaining: 9d 3h 46m 45s
42000:	learn: 0.0442371	test: 0.0686400	best: 0.0686393 (41975)	total: 5m 32s	remaining: 9d 3h 46m 3s
42300:	learn: 0.0441875	test: 0.0686268	best: 0.0686268 (42299)	total: 5m 34s	remaining: 9d 3h 45m 41s
42600:	learn: 0.0441410	test: 0.0686174	best: 0.0686172 (42589)	total: 5m 37s	remaining: 9d 3h 43m 1s
42900:	learn: 0.0440925	test: 0.0686032	best: 0.0686032 (42900)	total: 5m 39s	remaining: 9d 3h 43m 53s
43200:	learn: 0.0440460	test: 0.0685978	best: 0.0685942 (43156)	total: 5m 41s	remaining: 9d 3h 42m 34s
43500:	learn: 0.0439963	test: 0.0685894	best: 0.0685891 (43469)	total: 5m 44s	remaining: 9d 3h 46m 5s
43800:	learn: 0.0439502	test: 0.0685812	best: 0.0685808 (43796)	total: 5m 46s	remaining: 9d 3h 51m 12s
44100:	learn: 0.0438991	test: 0.0685661	best: 0.0685655 (44087)	total: 5m 49s	remaining: 9d 3h 52m 37s
44400:	learn: 0.0438534	test: 0.0685598	best: 0.0685581 (44291)	total: 5m 51s	remaining: 9d 3h 53m 21s
44700:	learn: 0.0438102	test: 0.0685532	best: 0.0685530 (44689)	total: 5m 54s	remaining: 9d 3h 55m 51s
45000:	learn: 0.0437628	test: 0.0685350	best: 0.0685342 (44985)	total: 5m 56s	remaining: 9d 3h 54m 59s
45300:	learn: 0.0437209	test: 0.0685259	best: 0.0685256 (45297)	total: 5m 58s	remaining: 9d 3h 55m 29s
45600:	learn: 0.0436825	test: 0.0685173	best: 0.0685162 (45595)	total: 6m 1s	remaining: 9d 3h 56m 51s
45900:	learn: 0.0436405	test: 0.0685095	best: 0.0685095 (45900)	total: 6m 3s	remaining: 9d 3h 57m 4s
46200:	learn: 0.0435981	test: 0.0684986	best: 0.0684980 (46086)	total: 6m 5s	remaining: 9d 3h 55m 25s
46500:	learn: 0.0435532	test: 0.0684879	best: 0.0684879 (46500)	total: 6m 8s	remaining: 9d 3h 57m 12s
46800:	learn: 0.0435082	test: 0.0684798	best: 0.0684796 (46797)	total: 6m 10s	remaining: 9d 3h 55m 40s
47100:	learn: 0.0434692	test: 0.0684676	best: 0.0684664 (47049)	total: 6m 13s	remaining: 9d 3h 53m 49s
47400:	learn: 0.0434247	test: 0.0684581	best: 0.0684572 (47324)	total: 6m 15s	remaining: 9d 3h 55m 11s
47700:	learn: 0.0433838	test: 0.0684566	best: 0.0684553 (47673)	total: 6m 17s	remaining: 9d 3h 54m 20s
48000:	learn: 0.0433383	test: 0.0684496	best: 0.0684492 (47977)	total: 6m 20s	remaining: 9d 3h 53m 30s
48300:	learn: 0.0432953	test: 0.0684374	best: 0.0684373 (48297)	total: 6m 22s	remaining: 9d 3h 51m 52s
48600:	learn: 0.0432500	test: 0.0684317	best: 0.0684312 (48584)	total: 6m 24s	remaining: 9d 3h 52m 37s
48900:	learn: 0.0432122	test: 0.0684200	best: 0.0684199 (48897)	total: 6m 27s	remaining: 9d 3h 51m 46s
49200:	learn: 0.0431741	test: 0.0684195	best: 0.0684179 (49120)	total: 6m 29s	remaining: 9d 3h 49m 35s
49500:	learn: 0.0431334	test: 0.0684139	best: 0.0684134 (49487)	total: 6m 31s	remaining: 9d 3h 49m 22s
49800:	learn: 0.0430991	test: 0.0684087	best: 0.0684081 (49792)	total: 6m 34s	remaining: 9d 3h 51m 3s
50100:	learn: 0.0430586	test: 0.0684024	best: 0.0684020 (49947)	total: 6m 36s	remaining: 9d 3h 54m 14s
50400:	learn: 0.0430198	test: 0.0684046	best: 0.0683974 (50241)	total: 6m 39s	remaining: 9d 3h 52m 39s
50700:	learn: 0.0429819	test: 0.0683977	best: 0.0683973 (50692)	total: 6m 41s	remaining: 9d 3h 51m 4s
51000:	learn: 0.0429411	test: 0.0683895	best: 0.0683887 (50993)	total: 6m 43s	remaining: 9d 3h 53m 14s
51300:	learn: 0.0429000	test: 0.0683845	best: 0.0683844 (51148)	total: 6m 46s	remaining: 9d 3h 51m 52s
51600:	learn: 0.0428632	test: 0.0683805	best: 0.0683784 (51526)	total: 6m 48s	remaining: 9d 3h 52m 39s
51900:	learn: 0.0428263	test: 0.0683742	best: 0.0683735 (51875)	total: 6m 51s	remaining: 9d 3h 52m 51s
52200:	learn: 0.0427874	test: 0.0683686	best: 0.0683661 (52167)	total: 6m 53s	remaining: 9d 3h 55m 50s
52500:	learn: 0.0427515	test: 0.0683675	best: 0.0683661 (52167)	total: 6m 55s	remaining: 9d 3h 56m 53s
52800:	learn: 0.0427147	test: 0.0683603	best: 0.0683592 (52765)	total: 6m 58s	remaining: 9d 3h 56m 28s
53100:	learn: 0.0426765	test: 0.0683504	best: 0.0683501 (53088)	total: 7m	remaining: 9d 3h 55m 11s
53400:	learn: 0.0426428	test: 0.0683452	best: 0.0683441 (53325)	total: 7m 3s	remaining: 9d 3h 57m 5s
53700:	learn: 0.0426095	test: 0.0683407	best: 0.0683391 (53676)	total: 7m 5s	remaining: 9d 3h 57m 26s
54000:	learn: 0.0425759	test: 0.0683330	best: 0.0683330 (54000)	total: 7m 7s	remaining: 9d 3h 55m 6s
54300:	learn: 0.0425394	test: 0.0683262	best: 0.0683258 (54290)	total: 7m 10s	remaining: 9d 3h 55m 1s
54600:	learn: 0.0425070	test: 0.0683202	best: 0.0683200 (54595)	total: 7m 12s	remaining: 9d 3h 53m 54s
54900:	learn: 0.0424677	test: 0.0683179	best: 0.0683179 (54894)	total: 7m 14s	remaining: 9d 3h 53m 32s
55200:	learn: 0.0424303	test: 0.0683078	best: 0.0683077 (55199)	total: 7m 17s	remaining: 9d 3h 52m 32s
55500:	learn: 0.0423926	test: 0.0683003	best: 0.0683001 (55495)	total: 7m 19s	remaining: 9d 3h 50m 42s
55800:	learn: 0.0423605	test: 0.0682972	best: 0.0682969 (55788)	total: 7m 21s	remaining: 9d 3h 50m 3s
56100:	learn: 0.0423263	test: 0.0682926	best: 0.0682923 (56085)	total: 7m 24s	remaining: 9d 3h 49m 5s
56400:	learn: 0.0422906	test: 0.0682876	best: 0.0682845 (56338)	total: 7m 26s	remaining: 9d 3h 51m 39s
56700:	learn: 0.0422534	test: 0.0682773	best: 0.0682768 (56688)	total: 7m 29s	remaining: 9d 3h 52m 48s
57000:	learn: 0.0422215	test: 0.0682761	best: 0.0682757 (56995)	total: 7m 31s	remaining: 9d 3h 53m 5s
57300:	learn: 0.0421858	test: 0.0682663	best: 0.0682663 (57300)	total: 7m 33s	remaining: 9d 3h 55m 2s
57600:	learn: 0.0421503	test: 0.0682597	best: 0.0682569 (57547)	total: 7m 36s	remaining: 9d 3h 53m 43s
57900:	learn: 0.0421128	test: 0.0682526	best: 0.0682526 (57900)	total: 7m 38s	remaining: 9d 3h 55m 59s
58200:	learn: 0.0420784	test: 0.0682470	best: 0.0682467 (58193)	total: 7m 41s	remaining: 9d 3h 55m 52s
58500:	learn: 0.0420461	test: 0.0682389	best: 0.0682388 (58498)	total: 7m 43s	remaining: 9d 4h 22s
58800:	learn: 0.0420138	test: 0.0682285	best: 0.0682285 (58800)	total: 7m 46s	remaining: 9d 4h 1m 5s
59100:	learn: 0.0419832	test: 0.0682203	best: 0.0682203 (59100)	total: 7m 48s	remaining: 9d 4h 1m
59400:	learn: 0.0419494	test: 0.0682144	best: 0.0682139 (59379)	total: 7m 50s	remaining: 9d 4h 1m 40s
59700:	learn: 0.0419161	test: 0.0682081	best: 0.0682075 (59589)	total: 7m 53s	remaining: 9d 4h 12s
60000:	learn: 0.0418827	test: 0.0682032	best: 0.0682013 (59981)	total: 7m 55s	remaining: 9d 3h 58m 28s
60300:	learn: 0.0418522	test: 0.0681980	best: 0.0681968 (60165)	total: 7m 57s	remaining: 9d 3h 55m 58s
60600:	learn: 0.0418179	test: 0.0681954	best: 0.0681945 (60581)	total: 8m	remaining: 9d 3h 55m 10s
60900:	learn: 0.0417857	test: 0.0681908	best: 0.0681906 (60886)	total: 8m 2s	remaining: 9d 3h 56m 26s
61200:	learn: 0.0417519	test: 0.0681901	best: 0.0681888 (60970)	total: 8m 5s	remaining: 9d 4h 8s
61500:	learn: 0.0417211	test: 0.0681876	best: 0.0681861 (61467)	total: 8m 7s	remaining: 9d 3h 58m 30s
61800:	learn: 0.0416876	test: 0.0681791	best: 0.0681788 (61770)	total: 8m 9s	remaining: 9d 3h 57m 48s
62100:	learn: 0.0416557	test: 0.0681713	best: 0.0681691 (61978)	total: 8m 12s	remaining: 9d 3h 57m 39s
62400:	learn: 0.0416266	test: 0.0681679	best: 0.0681671 (62265)	total: 8m 14s	remaining: 9d 3h 57m 6s
62700:	learn: 0.0415931	test: 0.0681623	best: 0.0681616 (62695)	total: 8m 16s	remaining: 9d 3h 55m 4s
63000:	learn: 0.0415645	test: 0.0681631	best: 0.0681605 (62812)	total: 8m 19s	remaining: 9d 3h 52m 31s
63300:	learn: 0.0415360	test: 0.0681651	best: 0.0681605 (62812)	total: 8m 21s	remaining: 9d 3h 52m 21s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.06816046463
bestIteration = 62812

Shrink model to first 62813 iterations.
fold n°10
0:	learn: 0.5685914	test: 0.5802626	best: 0.5802626 (0)	total: 9.56ms	remaining: 11d 1h 30m 25s
300:	learn: 0.1339609	test: 0.1324153	best: 0.1324153 (300)	total: 2.44s	remaining: 9d 8h 51m 22s
600:	learn: 0.0985123	test: 0.0982730	best: 0.0982730 (600)	total: 4.76s	remaining: 9d 4h 12m 51s
900:	learn: 0.0894845	test: 0.0895411	best: 0.0895411 (900)	total: 7.05s	remaining: 9d 1h 18m 15s
1200:	learn: 0.0840225	test: 0.0849520	best: 0.0849520 (1200)	total: 9.39s	remaining: 9d 1h 13m 35s
1500:	learn: 0.0799191	test: 0.0815854	best: 0.0815854 (1500)	total: 11.8s	remaining: 9d 1h 27m 5s
1800:	learn: 0.0768802	test: 0.0793347	best: 0.0793347 (1800)	total: 14.2s	remaining: 9d 3h 15m 39s
2100:	learn: 0.0744613	test: 0.0777711	best: 0.0777711 (2100)	total: 16.6s	remaining: 9d 3h 27m
2400:	learn: 0.0724709	test: 0.0765041	best: 0.0765041 (2400)	total: 19.1s	remaining: 9d 5h 18m 59s
2700:	learn: 0.0708398	test: 0.0755858	best: 0.0755858 (2700)	total: 21.6s	remaining: 9d 5h 38m 48s
3000:	learn: 0.0693933	test: 0.0747144	best: 0.0747144 (3000)	total: 24s	remaining: 9d 6h 5m 41s
3300:	learn: 0.0681324	test: 0.0740393	best: 0.0740393 (3300)	total: 26.4s	remaining: 9d 6h 34m 26s
3600:	learn: 0.0670216	test: 0.0734778	best: 0.0734778 (3600)	total: 28.9s	remaining: 9d 6h 37m 36s
3900:	learn: 0.0659897	test: 0.0729950	best: 0.0729950 (3900)	total: 31.2s	remaining: 9d 6h 27m 9s
4200:	learn: 0.0650576	test: 0.0725367	best: 0.0725367 (4200)	total: 33.7s	remaining: 9d 6h 40m 33s
4500:	learn: 0.0642153	test: 0.0721182	best: 0.0721182 (4500)	total: 36.1s	remaining: 9d 6h 32m 29s
4800:	learn: 0.0634397	test: 0.0717991	best: 0.0717991 (4800)	total: 38.4s	remaining: 9d 6h 25m 38s
5100:	learn: 0.0627595	test: 0.0715335	best: 0.0715335 (5100)	total: 40.8s	remaining: 9d 6h 7m 20s
5400:	learn: 0.0621061	test: 0.0712942	best: 0.0712941 (5399)	total: 43.2s	remaining: 9d 5h 55m 49s
5700:	learn: 0.0614800	test: 0.0710446	best: 0.0710441 (5699)	total: 45.5s	remaining: 9d 5h 45m 21s
6000:	learn: 0.0608740	test: 0.0708093	best: 0.0708093 (6000)	total: 47.9s	remaining: 9d 5h 42m 34s
6300:	learn: 0.0603236	test: 0.0706034	best: 0.0706021 (6298)	total: 50.3s	remaining: 9d 5h 48m 17s
6600:	learn: 0.0598116	test: 0.0704284	best: 0.0704284 (6600)	total: 52.7s	remaining: 9d 5h 36m 9s
6900:	learn: 0.0593266	test: 0.0702424	best: 0.0702421 (6894)	total: 55s	remaining: 9d 5h 31m 4s
7200:	learn: 0.0588637	test: 0.0700842	best: 0.0700824 (7188)	total: 57.4s	remaining: 9d 5h 16m 58s
7500:	learn: 0.0584182	test: 0.0699470	best: 0.0699467 (7499)	total: 59.7s	remaining: 9d 5h 6m 36s
7800:	learn: 0.0579900	test: 0.0698106	best: 0.0698106 (7800)	total: 1m 2s	remaining: 9d 5h 8m 23s
8100:	learn: 0.0576040	test: 0.0696840	best: 0.0696840 (8100)	total: 1m 4s	remaining: 9d 4h 52m 10s
8400:	learn: 0.0572414	test: 0.0695792	best: 0.0695792 (8400)	total: 1m 6s	remaining: 9d 4h 42m 25s
8700:	learn: 0.0569003	test: 0.0694753	best: 0.0694753 (8700)	total: 1m 9s	remaining: 9d 4h 32m 23s
9000:	learn: 0.0565677	test: 0.0693663	best: 0.0693661 (8998)	total: 1m 11s	remaining: 9d 4h 33m 8s
9300:	learn: 0.0562619	test: 0.0692932	best: 0.0692918 (9293)	total: 1m 14s	remaining: 9d 5h 52s
9600:	learn: 0.0559559	test: 0.0692057	best: 0.0692057 (9600)	total: 1m 16s	remaining: 9d 5h 26m 3s
9900:	learn: 0.0556722	test: 0.0691216	best: 0.0691213 (9899)	total: 1m 19s	remaining: 9d 5h 46m 31s
10200:	learn: 0.0554010	test: 0.0690404	best: 0.0690404 (10200)	total: 1m 21s	remaining: 9d 5h 42m 28s
10500:	learn: 0.0551152	test: 0.0689471	best: 0.0689471 (10500)	total: 1m 23s	remaining: 9d 6h 36s
10800:	learn: 0.0548453	test: 0.0688803	best: 0.0688803 (10800)	total: 1m 26s	remaining: 9d 6h 27m 56s
11100:	learn: 0.0545841	test: 0.0688084	best: 0.0688084 (11100)	total: 1m 29s	remaining: 9d 7h 14m 40s
11400:	learn: 0.0543362	test: 0.0687448	best: 0.0687435 (11390)	total: 1m 31s	remaining: 9d 7h 56m 53s
11700:	learn: 0.0540917	test: 0.0686769	best: 0.0686769 (11696)	total: 1m 34s	remaining: 9d 8h 16m 20s
12000:	learn: 0.0538674	test: 0.0686138	best: 0.0686138 (12000)	total: 1m 36s	remaining: 9d 7h 56m 54s
12300:	learn: 0.0536370	test: 0.0685615	best: 0.0685611 (12299)	total: 1m 39s	remaining: 9d 7h 46m 1s
12600:	learn: 0.0534218	test: 0.0685137	best: 0.0685137 (12600)	total: 1m 41s	remaining: 9d 7h 27m 51s
12900:	learn: 0.0532078	test: 0.0684527	best: 0.0684527 (12900)	total: 1m 43s	remaining: 9d 7h 14m 2s
13200:	learn: 0.0529966	test: 0.0684125	best: 0.0684113 (13192)	total: 1m 45s	remaining: 9d 6h 59m 59s
13500:	learn: 0.0528057	test: 0.0683690	best: 0.0683680 (13487)	total: 1m 48s	remaining: 9d 6h 47m 33s
13800:	learn: 0.0526070	test: 0.0683105	best: 0.0683103 (13798)	total: 1m 50s	remaining: 9d 6h 34m 18s
14100:	learn: 0.0524149	test: 0.0682711	best: 0.0682711 (14100)	total: 1m 52s	remaining: 9d 6h 21m 31s
14400:	learn: 0.0522203	test: 0.0682288	best: 0.0682286 (14399)	total: 1m 55s	remaining: 9d 6h 9m 17s
14700:	learn: 0.0520461	test: 0.0681830	best: 0.0681830 (14698)	total: 1m 57s	remaining: 9d 5h 56m 41s
15000:	learn: 0.0518771	test: 0.0681394	best: 0.0681390 (14995)	total: 1m 59s	remaining: 9d 5h 51m 11s
15300:	learn: 0.0517001	test: 0.0680786	best: 0.0680786 (15300)	total: 2m 2s	remaining: 9d 5h 44m
15600:	learn: 0.0515468	test: 0.0680423	best: 0.0680415 (15598)	total: 2m 4s	remaining: 9d 5h 32m 32s
15900:	learn: 0.0513993	test: 0.0680062	best: 0.0680061 (15899)	total: 2m 6s	remaining: 9d 5h 22m 25s
16200:	learn: 0.0512403	test: 0.0679684	best: 0.0679677 (16192)	total: 2m 9s	remaining: 9d 5h 14m 38s
16500:	learn: 0.0510836	test: 0.0679325	best: 0.0679325 (16500)	total: 2m 11s	remaining: 9d 5h 4m 12s
16800:	learn: 0.0509343	test: 0.0678968	best: 0.0678968 (16800)	total: 2m 13s	remaining: 9d 4h 56m 8s
17100:	learn: 0.0507833	test: 0.0678811	best: 0.0678795 (17069)	total: 2m 15s	remaining: 9d 4h 52m 10s
17400:	learn: 0.0506417	test: 0.0678432	best: 0.0678431 (17399)	total: 2m 18s	remaining: 9d 4h 51m 24s
17700:	learn: 0.0504960	test: 0.0678089	best: 0.0678088 (17698)	total: 2m 20s	remaining: 9d 4h 42m 50s
18000:	learn: 0.0503651	test: 0.0677939	best: 0.0677938 (17994)	total: 2m 22s	remaining: 9d 4h 32m 22s
18300:	learn: 0.0502258	test: 0.0677630	best: 0.0677628 (18298)	total: 2m 25s	remaining: 9d 4h 29m 58s
18600:	learn: 0.0501049	test: 0.0677377	best: 0.0677375 (18599)	total: 2m 27s	remaining: 9d 4h 31m 59s
18900:	learn: 0.0499852	test: 0.0677038	best: 0.0677036 (18876)	total: 2m 30s	remaining: 9d 4h 37m 39s
19200:	learn: 0.0498610	test: 0.0676844	best: 0.0676825 (19155)	total: 2m 32s	remaining: 9d 4h 32m 30s
19500:	learn: 0.0497531	test: 0.0676618	best: 0.0676618 (19500)	total: 2m 34s	remaining: 9d 4h 29m 24s
19800:	learn: 0.0496369	test: 0.0676426	best: 0.0676412 (19783)	total: 2m 37s	remaining: 9d 4h 23m 49s
20100:	learn: 0.0495071	test: 0.0676102	best: 0.0676102 (20100)	total: 2m 39s	remaining: 9d 4h 19m 33s
20400:	learn: 0.0493907	test: 0.0675851	best: 0.0675851 (20400)	total: 2m 41s	remaining: 9d 4h 11m 34s
20700:	learn: 0.0492774	test: 0.0675517	best: 0.0675517 (20700)	total: 2m 44s	remaining: 9d 4h 5m 50s
21000:	learn: 0.0491694	test: 0.0675279	best: 0.0675274 (20969)	total: 2m 46s	remaining: 9d 3h 57m 39s
21300:	learn: 0.0490658	test: 0.0675073	best: 0.0675070 (21294)	total: 2m 48s	remaining: 9d 3h 53m 12s
21600:	learn: 0.0489589	test: 0.0674831	best: 0.0674830 (21597)	total: 2m 50s	remaining: 9d 3h 45m 8s
21900:	learn: 0.0488558	test: 0.0674638	best: 0.0674634 (21896)	total: 2m 53s	remaining: 9d 3h 39m 17s
22200:	learn: 0.0487581	test: 0.0674491	best: 0.0674485 (22178)	total: 2m 55s	remaining: 9d 3h 30m 19s
22500:	learn: 0.0486588	test: 0.0674279	best: 0.0674279 (22500)	total: 2m 57s	remaining: 9d 3h 26m 55s
22800:	learn: 0.0485449	test: 0.0674054	best: 0.0674054 (22800)	total: 3m	remaining: 9d 3h 20m 56s
23100:	learn: 0.0484337	test: 0.0673886	best: 0.0673881 (23096)	total: 3m 2s	remaining: 9d 3h 15m 4s
23400:	learn: 0.0483304	test: 0.0673701	best: 0.0673694 (23384)	total: 3m 4s	remaining: 9d 3h 15m 11s
23700:	learn: 0.0482314	test: 0.0673506	best: 0.0673488 (23675)	total: 3m 7s	remaining: 9d 3h 10m 15s
24000:	learn: 0.0481416	test: 0.0673307	best: 0.0673299 (23978)	total: 3m 9s	remaining: 9d 3h 4m 12s
24300:	learn: 0.0480479	test: 0.0673132	best: 0.0673132 (24300)	total: 3m 11s	remaining: 9d 3h 1m 56s
24600:	learn: 0.0479528	test: 0.0672921	best: 0.0672916 (24598)	total: 3m 13s	remaining: 9d 2h 55m 55s
24900:	learn: 0.0478621	test: 0.0672731	best: 0.0672729 (24898)	total: 3m 16s	remaining: 9d 2h 54m 4s
25200:	learn: 0.0477823	test: 0.0672555	best: 0.0672552 (25197)	total: 3m 18s	remaining: 9d 2h 51m 29s
25500:	learn: 0.0476907	test: 0.0672421	best: 0.0672419 (25469)	total: 3m 20s	remaining: 9d 2h 45m 18s
25800:	learn: 0.0476045	test: 0.0672163	best: 0.0672162 (25798)	total: 3m 23s	remaining: 9d 2h 39m 40s
26100:	learn: 0.0475217	test: 0.0672004	best: 0.0672000 (26083)	total: 3m 25s	remaining: 9d 2h 33m 27s
26400:	learn: 0.0474462	test: 0.0671950	best: 0.0671950 (26398)	total: 3m 27s	remaining: 9d 2h 30m 1s
26700:	learn: 0.0473584	test: 0.0671772	best: 0.0671772 (26700)	total: 3m 29s	remaining: 9d 2h 24m 20s
27000:	learn: 0.0472708	test: 0.0671728	best: 0.0671714 (26992)	total: 3m 32s	remaining: 9d 2h 20m 47s
27300:	learn: 0.0471872	test: 0.0671547	best: 0.0671547 (27300)	total: 3m 34s	remaining: 9d 2h 16m 15s
27600:	learn: 0.0471040	test: 0.0671379	best: 0.0671377 (27599)	total: 3m 36s	remaining: 9d 2h 12m 45s
27900:	learn: 0.0470206	test: 0.0671098	best: 0.0671094 (27894)	total: 3m 39s	remaining: 9d 2h 8m 39s
28200:	learn: 0.0469501	test: 0.0670882	best: 0.0670880 (28197)	total: 3m 41s	remaining: 9d 2h 15m 32s
28500:	learn: 0.0468826	test: 0.0670774	best: 0.0670774 (28500)	total: 3m 43s	remaining: 9d 2h 13m 29s
28800:	learn: 0.0468040	test: 0.0670609	best: 0.0670609 (28800)	total: 3m 46s	remaining: 9d 2h 9m 57s
29100:	learn: 0.0467283	test: 0.0670395	best: 0.0670381 (29077)	total: 3m 48s	remaining: 9d 2h 12m 46s
29400:	learn: 0.0466594	test: 0.0670259	best: 0.0670257 (29397)	total: 3m 50s	remaining: 9d 2h 10m 52s
29700:	learn: 0.0465944	test: 0.0670119	best: 0.0670112 (29695)	total: 3m 53s	remaining: 9d 2h 8m 39s
30000:	learn: 0.0465224	test: 0.0669942	best: 0.0669942 (30000)	total: 3m 55s	remaining: 9d 2h 12m 41s
30300:	learn: 0.0464520	test: 0.0669847	best: 0.0669846 (30296)	total: 3m 58s	remaining: 9d 2h 20m 39s
30600:	learn: 0.0463838	test: 0.0669715	best: 0.0669715 (30600)	total: 4m	remaining: 9d 2h 22m 45s
30900:	learn: 0.0463196	test: 0.0669529	best: 0.0669529 (30900)	total: 4m 3s	remaining: 9d 2h 25m 39s
31200:	learn: 0.0462543	test: 0.0669366	best: 0.0669365 (31199)	total: 4m 5s	remaining: 9d 2h 24m 37s
31500:	learn: 0.0461867	test: 0.0669251	best: 0.0669251 (31494)	total: 4m 7s	remaining: 9d 2h 26m 21s
31800:	learn: 0.0461255	test: 0.0669166	best: 0.0669155 (31760)	total: 4m 10s	remaining: 9d 2h 25m 6s
32100:	learn: 0.0460607	test: 0.0669047	best: 0.0669038 (32059)	total: 4m 12s	remaining: 9d 2h 22m 19s
32400:	learn: 0.0459973	test: 0.0668920	best: 0.0668914 (32397)	total: 4m 14s	remaining: 9d 2h 22m 36s
32700:	learn: 0.0459339	test: 0.0668756	best: 0.0668750 (32688)	total: 4m 17s	remaining: 9d 2h 22m 47s
33000:	learn: 0.0458737	test: 0.0668646	best: 0.0668630 (32960)	total: 4m 19s	remaining: 9d 2h 17m 59s
33300:	learn: 0.0458132	test: 0.0668584	best: 0.0668579 (33288)	total: 4m 21s	remaining: 9d 2h 17m 43s
33600:	learn: 0.0457482	test: 0.0668350	best: 0.0668348 (33596)	total: 4m 24s	remaining: 9d 2h 14m 28s
33900:	learn: 0.0456855	test: 0.0668222	best: 0.0668216 (33894)	total: 4m 26s	remaining: 9d 2h 13m 29s
34200:	learn: 0.0456206	test: 0.0668096	best: 0.0668096 (34197)	total: 4m 28s	remaining: 9d 2h 11m 8s
34500:	learn: 0.0455562	test: 0.0668096	best: 0.0668060 (34396)	total: 4m 31s	remaining: 9d 2h 8m 2s
34800:	learn: 0.0454982	test: 0.0668003	best: 0.0667993 (34725)	total: 4m 33s	remaining: 9d 2h 8m 16s
35100:	learn: 0.0454443	test: 0.0667878	best: 0.0667874 (35097)	total: 4m 35s	remaining: 9d 2h 6m 20s
35400:	learn: 0.0453949	test: 0.0667779	best: 0.0667752 (35270)	total: 4m 38s	remaining: 9d 2h 8m 50s
35700:	learn: 0.0453363	test: 0.0667705	best: 0.0667700 (35664)	total: 4m 40s	remaining: 9d 2h 9m 13s
36000:	learn: 0.0452737	test: 0.0667553	best: 0.0667550 (35970)	total: 4m 42s	remaining: 9d 2h 8m 24s
36300:	learn: 0.0452179	test: 0.0667450	best: 0.0667450 (36257)	total: 4m 45s	remaining: 9d 2h 5m 59s
36600:	learn: 0.0451591	test: 0.0667310	best: 0.0667310 (36600)	total: 4m 47s	remaining: 9d 2h 5m 25s
36900:	learn: 0.0451068	test: 0.0667199	best: 0.0667199 (36900)	total: 4m 49s	remaining: 9d 2h 8m 15s
37200:	learn: 0.0450484	test: 0.0667049	best: 0.0667034 (37173)	total: 4m 52s	remaining: 9d 2h 10m 6s
37500:	learn: 0.0449868	test: 0.0666890	best: 0.0666881 (37494)	total: 4m 54s	remaining: 9d 2h 10m 31s
37800:	learn: 0.0449325	test: 0.0666792	best: 0.0666789 (37797)	total: 4m 57s	remaining: 9d 2h 13m 13s
38100:	learn: 0.0448757	test: 0.0666705	best: 0.0666680 (37987)	total: 4m 59s	remaining: 9d 2h 14m 26s
38400:	learn: 0.0448211	test: 0.0666589	best: 0.0666586 (38397)	total: 5m 1s	remaining: 9d 2h 17m 9s
38700:	learn: 0.0447715	test: 0.0666581	best: 0.0666578 (38696)	total: 5m 4s	remaining: 9d 2h 17m 11s
39000:	learn: 0.0447217	test: 0.0666462	best: 0.0666461 (38999)	total: 5m 6s	remaining: 9d 2h 20m 36s
39300:	learn: 0.0446644	test: 0.0666378	best: 0.0666367 (39236)	total: 5m 9s	remaining: 9d 2h 20m 40s
39600:	learn: 0.0446120	test: 0.0666297	best: 0.0666296 (39597)	total: 5m 11s	remaining: 9d 2h 22m 5s
39900:	learn: 0.0445611	test: 0.0666142	best: 0.0666142 (39900)	total: 5m 13s	remaining: 9d 2h 28m 41s
40200:	learn: 0.0445023	test: 0.0666022	best: 0.0666011 (40160)	total: 5m 16s	remaining: 9d 2h 30m 45s
40500:	learn: 0.0444471	test: 0.0665916	best: 0.0665914 (40498)	total: 5m 18s	remaining: 9d 2h 33m 29s
40800:	learn: 0.0443960	test: 0.0665771	best: 0.0665771 (40800)	total: 5m 21s	remaining: 9d 2h 32m 10s
41100:	learn: 0.0443501	test: 0.0665750	best: 0.0665734 (41030)	total: 5m 23s	remaining: 9d 2h 29m 26s
41400:	learn: 0.0443028	test: 0.0665676	best: 0.0665676 (41400)	total: 5m 25s	remaining: 9d 2h 29m 20s
41700:	learn: 0.0442541	test: 0.0665581	best: 0.0665574 (41682)	total: 5m 28s	remaining: 9d 2h 29m 2s
42000:	learn: 0.0442066	test: 0.0665499	best: 0.0665486 (41970)	total: 5m 30s	remaining: 9d 2h 32m 28s
42300:	learn: 0.0441571	test: 0.0665438	best: 0.0665431 (42283)	total: 5m 32s	remaining: 9d 2h 34m 39s
42600:	learn: 0.0441106	test: 0.0665338	best: 0.0665334 (42597)	total: 5m 35s	remaining: 9d 2h 35m 20s
42900:	learn: 0.0440569	test: 0.0665218	best: 0.0665217 (42897)	total: 5m 37s	remaining: 9d 2h 36m 54s
43200:	learn: 0.0440033	test: 0.0665154	best: 0.0665140 (43157)	total: 5m 40s	remaining: 9d 2h 36m 54s
43500:	learn: 0.0439517	test: 0.0665058	best: 0.0665050 (43474)	total: 5m 42s	remaining: 9d 2h 37m 30s
43800:	learn: 0.0439029	test: 0.0664890	best: 0.0664890 (43800)	total: 5m 44s	remaining: 9d 2h 38m 24s
44100:	learn: 0.0438540	test: 0.0664859	best: 0.0664847 (44085)	total: 5m 47s	remaining: 9d 2h 40m 13s
44400:	learn: 0.0438048	test: 0.0664750	best: 0.0664733 (44371)	total: 5m 49s	remaining: 9d 2h 40m 23s
44700:	learn: 0.0437567	test: 0.0664713	best: 0.0664713 (44700)	total: 5m 52s	remaining: 9d 2h 41m 49s
45000:	learn: 0.0437106	test: 0.0664633	best: 0.0664621 (44967)	total: 5m 54s	remaining: 9d 2h 43m 25s
45300:	learn: 0.0436656	test: 0.0664533	best: 0.0664532 (45299)	total: 5m 56s	remaining: 9d 2h 42m 43s
45600:	learn: 0.0436166	test: 0.0664405	best: 0.0664401 (45567)	total: 5m 59s	remaining: 9d 2h 40m 5s
45900:	learn: 0.0435703	test: 0.0664316	best: 0.0664314 (45883)	total: 6m 1s	remaining: 9d 2h 37m 57s
46200:	learn: 0.0435241	test: 0.0664324	best: 0.0664300 (46178)	total: 6m 3s	remaining: 9d 2h 36m 12s
46500:	learn: 0.0434810	test: 0.0664271	best: 0.0664264 (46494)	total: 6m 6s	remaining: 9d 2h 33m 24s
46800:	learn: 0.0434370	test: 0.0664197	best: 0.0664189 (46764)	total: 6m 8s	remaining: 9d 2h 32m 20s
47100:	learn: 0.0433956	test: 0.0664193	best: 0.0664170 (46897)	total: 6m 10s	remaining: 9d 2h 31m 47s
47400:	learn: 0.0433513	test: 0.0664104	best: 0.0664097 (47374)	total: 6m 13s	remaining: 9d 2h 29m 47s
47700:	learn: 0.0433094	test: 0.0664042	best: 0.0664037 (47598)	total: 6m 15s	remaining: 9d 2h 27m 32s
48000:	learn: 0.0432744	test: 0.0663966	best: 0.0663964 (47995)	total: 6m 17s	remaining: 9d 2h 25m 19s
48300:	learn: 0.0432349	test: 0.0663938	best: 0.0663921 (48248)	total: 6m 19s	remaining: 9d 2h 23m 4s
48600:	learn: 0.0431927	test: 0.0663907	best: 0.0663905 (48597)	total: 6m 22s	remaining: 9d 2h 21m 43s
48900:	learn: 0.0431505	test: 0.0663886	best: 0.0663863 (48832)	total: 6m 24s	remaining: 9d 2h 22m 15s
49200:	learn: 0.0431114	test: 0.0663789	best: 0.0663785 (49198)	total: 6m 26s	remaining: 9d 2h 20m 45s
49500:	learn: 0.0430717	test: 0.0663755	best: 0.0663752 (49491)	total: 6m 29s	remaining: 9d 2h 19m 39s
49800:	learn: 0.0430298	test: 0.0663732	best: 0.0663724 (49780)	total: 6m 31s	remaining: 9d 2h 20m 38s
50100:	learn: 0.0429894	test: 0.0663651	best: 0.0663651 (50099)	total: 6m 33s	remaining: 9d 2h 20m 1s
50400:	learn: 0.0429514	test: 0.0663551	best: 0.0663549 (50361)	total: 6m 36s	remaining: 9d 2h 19m 12s
50700:	learn: 0.0429098	test: 0.0663457	best: 0.0663450 (50689)	total: 6m 38s	remaining: 9d 2h 20m 23s
51000:	learn: 0.0428719	test: 0.0663366	best: 0.0663366 (51000)	total: 6m 41s	remaining: 9d 2h 24m 9s
51300:	learn: 0.0428354	test: 0.0663339	best: 0.0663338 (51286)	total: 6m 43s	remaining: 9d 2h 22m 54s
51600:	learn: 0.0427980	test: 0.0663319	best: 0.0663319 (51600)	total: 6m 45s	remaining: 9d 2h 24m 26s
51900:	learn: 0.0427611	test: 0.0663251	best: 0.0663251 (51900)	total: 6m 48s	remaining: 9d 2h 24m 19s
52200:	learn: 0.0427236	test: 0.0663192	best: 0.0663185 (52185)	total: 6m 50s	remaining: 9d 2h 23m 25s
52500:	learn: 0.0426849	test: 0.0663117	best: 0.0663115 (52493)	total: 6m 53s	remaining: 9d 2h 24m 41s
52800:	learn: 0.0426480	test: 0.0663009	best: 0.0663007 (52735)	total: 6m 55s	remaining: 9d 2h 24m 44s
53100:	learn: 0.0426110	test: 0.0662966	best: 0.0662961 (53065)	total: 6m 58s	remaining: 9d 2h 32m 59s
53400:	learn: 0.0425688	test: 0.0662907	best: 0.0662899 (53333)	total: 7m	remaining: 9d 2h 36m 20s
53700:	learn: 0.0425347	test: 0.0662902	best: 0.0662879 (53594)	total: 7m 2s	remaining: 9d 2h 40m 59s
54000:	learn: 0.0425004	test: 0.0662820	best: 0.0662814 (53947)	total: 7m 5s	remaining: 9d 2h 40m 58s
54300:	learn: 0.0424651	test: 0.0662752	best: 0.0662748 (54279)	total: 7m 7s	remaining: 9d 2h 39m 24s
54600:	learn: 0.0424268	test: 0.0662722	best: 0.0662710 (54582)	total: 7m 10s	remaining: 9d 2h 47m 9s
54900:	learn: 0.0423889	test: 0.0662651	best: 0.0662648 (54847)	total: 7m 12s	remaining: 9d 2h 52m 1s
55200:	learn: 0.0423531	test: 0.0662606	best: 0.0662606 (55200)	total: 7m 15s	remaining: 9d 2h 52m 56s
55500:	learn: 0.0423131	test: 0.0662555	best: 0.0662530 (55427)	total: 7m 17s	remaining: 9d 2h 51m 54s
55800:	learn: 0.0422837	test: 0.0662538	best: 0.0662529 (55616)	total: 7m 19s	remaining: 9d 2h 50m 12s
56100:	learn: 0.0422512	test: 0.0662537	best: 0.0662528 (56027)	total: 7m 22s	remaining: 9d 2h 53m 15s
56400:	learn: 0.0422156	test: 0.0662487	best: 0.0662473 (56376)	total: 7m 24s	remaining: 9d 2h 58m 2s
56700:	learn: 0.0421786	test: 0.0662410	best: 0.0662407 (56658)	total: 7m 27s	remaining: 9d 2h 58m 34s
57000:	learn: 0.0421463	test: 0.0662359	best: 0.0662339 (56954)	total: 7m 29s	remaining: 9d 2h 57m 46s
57300:	learn: 0.0421145	test: 0.0662251	best: 0.0662233 (57203)	total: 7m 31s	remaining: 9d 2h 56m 25s
57600:	learn: 0.0420768	test: 0.0662213	best: 0.0662197 (57430)	total: 7m 34s	remaining: 9d 2h 55m 11s
57900:	learn: 0.0420436	test: 0.0662126	best: 0.0662121 (57860)	total: 7m 36s	remaining: 9d 2h 55m 55s
58200:	learn: 0.0420101	test: 0.0662141	best: 0.0662108 (58034)	total: 7m 39s	remaining: 9d 2h 58m
58500:	learn: 0.0419761	test: 0.0662055	best: 0.0662049 (58445)	total: 7m 41s	remaining: 9d 2h 58m 47s
58800:	learn: 0.0419449	test: 0.0662008	best: 0.0662002 (58741)	total: 7m 43s	remaining: 9d 3h 45s
59100:	learn: 0.0419119	test: 0.0661910	best: 0.0661910 (59100)	total: 7m 46s	remaining: 9d 2h 59m 14s
59400:	learn: 0.0418786	test: 0.0661849	best: 0.0661847 (59391)	total: 7m 48s	remaining: 9d 3h 2m 42s
59700:	learn: 0.0418505	test: 0.0661797	best: 0.0661796 (59691)	total: 7m 51s	remaining: 9d 3h 2m 56s
60000:	learn: 0.0418186	test: 0.0661699	best: 0.0661697 (59985)	total: 7m 53s	remaining: 9d 3h 2m 8s
60300:	learn: 0.0417839	test: 0.0661620	best: 0.0661617 (60287)	total: 7m 55s	remaining: 9d 3h 1m 46s
60600:	learn: 0.0417484	test: 0.0661546	best: 0.0661539 (60585)	total: 7m 58s	remaining: 9d 3h 2m 54s
60900:	learn: 0.0417157	test: 0.0661478	best: 0.0661463 (60847)	total: 8m	remaining: 9d 3h 3m 59s
61200:	learn: 0.0416792	test: 0.0661409	best: 0.0661401 (61174)	total: 8m 3s	remaining: 9d 3h 5m 32s
61500:	learn: 0.0416474	test: 0.0661384	best: 0.0661375 (61397)	total: 8m 5s	remaining: 9d 3h 6m 1s
61800:	learn: 0.0416168	test: 0.0661374	best: 0.0661367 (61609)	total: 8m 7s	remaining: 9d 3h 7m
62100:	learn: 0.0415873	test: 0.0661360	best: 0.0661340 (61900)	total: 8m 10s	remaining: 9d 3h 8m 46s
62400:	learn: 0.0415607	test: 0.0661242	best: 0.0661242 (62400)	total: 8m 12s	remaining: 9d 3h 10m 1s
62700:	learn: 0.0415284	test: 0.0661149	best: 0.0661148 (62697)	total: 8m 14s	remaining: 9d 3h 8m 53s
63000:	learn: 0.0414923	test: 0.0661089	best: 0.0661087 (62998)	total: 8m 17s	remaining: 9d 3h 8m 5s
63300:	learn: 0.0414607	test: 0.0661027	best: 0.0661027 (63300)	total: 8m 19s	remaining: 9d 3h 7m 5s
63600:	learn: 0.0414320	test: 0.0661014	best: 0.0661008 (63323)	total: 8m 21s	remaining: 9d 3h 5m 40s
63900:	learn: 0.0413985	test: 0.0660937	best: 0.0660932 (63832)	total: 8m 24s	remaining: 9d 3h 4m 49s
64200:	learn: 0.0413653	test: 0.0660843	best: 0.0660843 (64200)	total: 8m 26s	remaining: 9d 3h 6m 50s
64500:	learn: 0.0413318	test: 0.0660839	best: 0.0660823 (64339)	total: 8m 29s	remaining: 9d 3h 6m 41s
64800:	learn: 0.0413032	test: 0.0660834	best: 0.0660810 (64605)	total: 8m 31s	remaining: 9d 3h 5m 36s
65100:	learn: 0.0412748	test: 0.0660804	best: 0.0660796 (65052)	total: 8m 33s	remaining: 9d 3h 6m 19s
65400:	learn: 0.0412439	test: 0.0660767	best: 0.0660767 (65400)	total: 8m 36s	remaining: 9d 3h 8m 19s
65700:	learn: 0.0412153	test: 0.0660702	best: 0.0660701 (65699)	total: 8m 38s	remaining: 9d 3h 9m 19s
66000:	learn: 0.0411862	test: 0.0660636	best: 0.0660635 (65967)	total: 8m 41s	remaining: 9d 3h 10m
66300:	learn: 0.0411549	test: 0.0660587	best: 0.0660585 (66294)	total: 8m 43s	remaining: 9d 3h 12m 17s
66600:	learn: 0.0411275	test: 0.0660548	best: 0.0660535 (66567)	total: 8m 45s	remaining: 9d 3h 12m 14s
66900:	learn: 0.0411009	test: 0.0660501	best: 0.0660498 (66847)	total: 8m 48s	remaining: 9d 3h 12m 57s
67200:	learn: 0.0410731	test: 0.0660486	best: 0.0660486 (67199)	total: 8m 50s	remaining: 9d 3h 13m 49s
67500:	learn: 0.0410434	test: 0.0660474	best: 0.0660444 (67472)	total: 8m 53s	remaining: 9d 3h 18m 27s
67800:	learn: 0.0410116	test: 0.0660431	best: 0.0660430 (67799)	total: 8m 55s	remaining: 9d 3h 19m 52s
68100:	learn: 0.0409855	test: 0.0660404	best: 0.0660386 (67849)	total: 8m 58s	remaining: 9d 3h 23m 7s
68400:	learn: 0.0409613	test: 0.0660400	best: 0.0660386 (67849)	total: 9m	remaining: 9d 3h 26m 40s
Stopped by overfitting detector  (600 iterations wait)

bestTest = 0.06603861821
bestIteration = 67849

Shrink model to first 67850 iterations.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[163]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;catboost score: </span><span class="si">{:&lt;8.8f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">oof_cb</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">Y_data</span><span class="p">))))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>catboost score: 0.94601721
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[164]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Model_Evaluate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">oof_cb</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">Y_data</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[164]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(0.5607757692792152, 0.4739636166903361, 0.09197562036526839)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[165]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#保存cb结果</span>
<span class="n">cb_predict</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predictions_cb</span><span class="p">)),</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">,</span><span class="s1">&#39;price_predict&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[166]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lgb_predict</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">test_carid</span><span class="o">.</span><span class="n">values</span>
<span class="n">lgb_predict</span><span class="p">[</span><span class="s1">&#39;price_predict&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predictions_cb</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[167]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cb_predict</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;E:/Mather Cup/Coding/dataset/cb_predict.xlsx&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#183;XGBoost">&#183;XGBoost<a class="anchor-link" href="#&#183;XGBoost">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[109]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>  <span class="c1"># 交叉验证，网格搜索</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[110]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">n_stimators</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[64]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">],</span>
          <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">],</span>
          <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">]}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">xgb</span><span class="p">,</span>
                    <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_absolute_error&#39;</span><span class="p">,</span>
                    <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_data</span><span class="p">,</span><span class="n">Y_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[13:21:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:21:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:21:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:21:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:21:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:21:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:22:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:22:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[13:22:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[64]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=10,
             estimator=XGBRegressor(base_score=None, booster=None,
                                    colsample_bylevel=None,
                                    colsample_bynode=None,
                                    colsample_bytree=None,
                                    enable_categorical=False, gamma=None,
                                    gpu_id=None, importance_type=None,
                                    interaction_constraints=None,
                                    learning_rate=0.1, max_delta_step=None,
                                    max_depth=8, min_child_weight=None,
                                    missing=nan, monotone_constraints=None,
                                    n_estimators=100, n_jobs=None,
                                    n_stimators=150, num_parallel_tree=None,
                                    predictor=None, random_state=1,
                                    reg_alpha=None, reg_lambda=None,
                                    scale_pos_weight=None, subsample=None,
                                    tree_method=None, validate_parameters=None,
                                    verbosity=None),
             param_grid={&#39;learning_rate&#39;: [0.2], &#39;n_estimators&#39;: [100],
                         &#39;subsample&#39;: [0.5]},
             scoring=&#39;neg_mean_absolute_error&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[66]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">oof_xgb_org</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">## 采用网格搜索进行调优</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#同样采用十者交叉检验进行训练 cv=10</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[111]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">250</span><span class="p">],</span>
          <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.15</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.3</span><span class="p">],</span>
          <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.8</span><span class="p">]</span>
         <span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">xgb</span><span class="p">,</span>
                    <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_absolute_error&#39;</span><span class="p">,</span>
                    <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[18:59:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:00:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:00:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:00:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:00:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:00:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:00:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:01:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:01:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:01:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:01:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:01:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:01:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:01:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:01:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:02:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:02:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:02:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:02:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:02:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:02:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:02:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:03:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:03:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:03:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:03:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:03:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:03:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:04:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:04:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:04:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:04:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:04:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:04:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:05:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:05:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:05:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:05:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:05:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:05:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:06:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:06:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:06:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:06:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:07:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:07:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:07:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:07:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:07:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:08:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:08:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:08:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:08:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:08:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:09:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:09:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:09:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:09:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:10:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:10:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:10:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:10:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:11:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:11:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:11:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:12:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:12:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:12:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:13:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:13:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:13:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:13:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:14:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:14:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:14:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:14:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:14:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:15:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:15:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:15:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:15:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:15:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:16:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:16:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:16:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:47:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:47:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:47:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:47:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:48:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:48:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:48:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:48:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:48:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:48:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:48:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:48:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:49:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:49:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:49:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:49:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:49:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:49:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:49:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:49:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:50:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:50:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:50:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:50:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:50:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:51:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:51:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:51:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:51:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:51:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:51:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:52:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:52:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:52:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:52:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:53:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:53:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:53:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:53:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:54:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:54:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:54:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:54:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:54:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:54:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:55:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:55:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:55:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:55:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:56:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:56:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:56:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:56:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:57:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:57:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:57:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:57:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:58:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:58:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:58:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:58:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:59:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:59:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:59:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:59:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[19:59:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:00:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:00:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:00:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:00:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:00:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:01:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:01:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:01:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:01:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:02:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:02:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:02:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:02:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:02:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:02:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:02:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:03:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:03:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:03:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:03:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:03:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:03:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:04:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:04:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:04:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:04:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:04:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:04:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:04:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:05:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:05:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:05:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:05:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:05:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:06:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:06:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:06:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:06:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:07:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:07:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:07:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:07:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:07:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:07:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:08:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:08:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:08:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:08:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:08:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:09:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:09:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:09:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:09:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:09:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:10:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:10:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:10:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:10:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:10:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:11:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:11:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:11:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:11:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:12:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:12:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:12:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:12:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:12:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:13:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:13:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:13:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:13:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:14:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:14:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:14:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:14:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:14:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:15:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:15:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:15:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:15:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:16:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:16:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:16:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:16:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:17:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:17:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:17:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:17:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:17:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:18:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:18:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:18:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:18:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:18:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:18:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:19:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:19:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:19:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:19:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:19:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:19:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:19:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:19:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:20:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:20:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:20:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:20:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:20:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:20:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:20:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:21:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:21:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:21:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:21:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:21:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:21:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:22:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:22:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:22:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:22:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:22:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:23:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:23:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:23:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:23:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:23:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:23:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:24:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:24:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:24:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:24:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:24:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:25:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:25:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:25:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:25:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:25:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:25:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:26:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:26:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:26:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:26:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:26:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:27:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:27:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:27:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:27:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:27:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:28:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:28:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:28:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:28:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:29:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:29:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:30:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:30:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:30:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:31:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:31:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:31:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:31:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:32:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:32:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:32:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:32:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:32:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:33:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:33:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:33:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:33:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:33:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:34:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:34:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:34:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:34:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:34:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:34:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:34:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:34:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:35:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:35:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:35:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:35:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:35:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:35:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:35:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:36:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:36:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:36:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:36:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:36:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:36:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:36:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:37:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:37:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:37:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:37:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:37:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:37:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:37:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:37:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:38:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:38:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:38:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:38:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:39:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:39:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:39:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:39:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:39:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:39:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:40:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:40:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:40:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:40:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:40:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:41:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:41:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:41:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:41:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:41:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:42:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:42:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:42:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:42:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:42:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:43:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:43:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:43:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:43:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:43:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:44:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:44:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:44:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:44:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:45:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:45:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:45:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:45:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:45:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:46:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:46:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:46:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:46:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:46:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:47:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:47:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:47:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:47:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:48:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:48:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:48:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:48:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:48:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:49:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:49:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:49:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:49:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:49:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:49:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:50:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:50:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:50:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:50:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:50:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:50:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:51:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:51:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:51:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:51:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:51:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:51:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:52:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:52:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:52:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:52:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:52:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:53:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:53:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:53:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:53:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:53:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:53:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:54:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:54:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:54:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:54:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:54:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:54:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:55:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:55:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:55:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:55:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:55:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:56:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:56:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:56:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:56:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:56:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:56:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:57:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:57:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:57:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:57:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:57:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:57:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:58:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:58:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:58:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:58:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:58:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:59:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:59:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:59:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[20:59:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:00:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:00:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:00:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:00:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:01:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:01:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:01:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:01:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:02:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:02:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:02:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:03:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:03:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:03:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:03:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:03:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:04:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:04:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:04:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:05:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:05:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


[21:05:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: 
Parameters: { &#34;n_stimators&#34; } might not be used.

  This could be a false alarm, with some parameters getting used by language bindings but
  then being mistakenly passed down to XGBoost core, or some parameter actually being used
  but getting flagged wrongly here. Please open an issue if you find any such cases.


</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[111]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>GridSearchCV(cv=10,
             estimator=XGBRegressor(base_score=None, booster=None,
                                    colsample_bylevel=None,
                                    colsample_bynode=None,
                                    colsample_bytree=None,
                                    enable_categorical=False, gamma=None,
                                    gpu_id=None, importance_type=None,
                                    interaction_constraints=None,
                                    learning_rate=0.1, max_delta_step=None,
                                    max_depth=8, min_child_weight=None,
                                    missing=nan, monotone_constraints=None,
                                    n_es...bs=None,
                                    n_stimators=150, num_parallel_tree=None,
                                    predictor=None, random_state=1,
                                    reg_alpha=None, reg_lambda=None,
                                    scale_pos_weight=None, subsample=None,
                                    tree_method=None, validate_parameters=None,
                                    verbosity=None),
             param_grid={&#39;learning_rate&#39;: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],
                         &#39;n_estimators&#39;: [150, 200, 250],
                         &#39;subsample&#39;: [0.5, 0.6, 0.8]},
             scoring=&#39;neg_mean_absolute_error&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[112]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;最佳参数为：</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;最佳分数为：</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;最佳模型为：</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>最佳参数为：
 {&#39;learning_rate&#39;: 0.1, &#39;n_estimators&#39;: 250, &#39;subsample&#39;: 0.8}
最佳分数为：
 -0.07048635422197759
最佳模型为：
 XGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1,
             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,
             gamma=0, gpu_id=-1, importance_type=None,
             interaction_constraints=&#39;&#39;, learning_rate=0.1, max_delta_step=0,
             max_depth=8, min_child_weight=1, missing=nan,
             monotone_constraints=&#39;()&#39;, n_estimators=250, n_jobs=8,
             n_stimators=150, num_parallel_tree=1, predictor=&#39;auto&#39;,
             random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,
             subsample=0.8, tree_method=&#39;exact&#39;, validate_parameters=1,
             verbosity=None)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[113]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">oof_xgb_train_final</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[114]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">oof_xgb_test_final</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[115]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Model_Evaluate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">oof_xgb_train_final</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">Y_train</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[115]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(0.7681014401320125, 0.7201595996483398, 0.04013119793329694)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[170]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">oof_xgb_test_final</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[170]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([19.56365  ,  9.762805 ,  2.7364576, ...,  6.9277935,  3.382679 ,
       11.8280735], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[171]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#保存结果</span>
<span class="n">testPrice_predict</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">oof_xgb_test_final</span><span class="p">)),</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">,</span><span class="s1">&#39;price_predict&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[172]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testPrice_predict</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">]</span><span class="o">=</span> <span class="n">test_carid</span><span class="o">.</span><span class="n">values</span>
<span class="n">testPrice_predict</span><span class="p">[</span><span class="s1">&#39;price_predict&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">oof_xgb_test_final</span><span class="p">)</span>
<span class="n">testPrice_predict</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">testPrice_predict</span><span class="p">[</span><span class="s1">&#39;carid&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[173]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#与存在溢价潜力的样本价格预测合并</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[174]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Test_premiun_predict</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;price&#39;</span><span class="p">:</span><span class="s1">&#39;price_predict&#39;</span><span class="p">},</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">testPrice_predict</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">testPrice_predict</span><span class="p">,</span><span class="n">Test_premiun_predict</span><span class="p">],</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[175]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#导出记事本格式文件</span>
<span class="n">testPrice_predict</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;E:/Mather Cup/Coding/dataset/估价模型结果.txt&#39;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[69]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#0.8/0.3 四十多个特征</span>
<span class="c1"># print(&#39;最佳参数为：\n&#39;, model.best_params_)</span>
<span class="c1"># print(&#39;最佳分数为：\n&#39;, model.best_score_)</span>
<span class="c1"># print(&#39;最佳模型为：\n&#39;, model.best_estimator_)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>最佳参数为：
 {&#39;learning_rate&#39;: 0.1, &#39;n_estimators&#39;: 250, &#39;subsample&#39;: 0.8}
最佳分数为：
 -0.07352207064223445
最佳模型为：
 XGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1,
             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,
             gamma=0, gpu_id=-1, importance_type=None,
             interaction_constraints=&#39;&#39;, learning_rate=0.1, max_delta_step=0,
             max_depth=8, min_child_weight=1, missing=nan,
             monotone_constraints=&#39;()&#39;, n_estimators=250, n_jobs=8,
             n_stimators=150, num_parallel_tree=1, predictor=&#39;auto&#39;,
             random_state=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,
             subsample=0.8, tree_method=&#39;exact&#39;, validate_parameters=1,
             verbosity=None)
</pre>
</div>
</div>

</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
